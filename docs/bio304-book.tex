\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Biology 304: Biological Data Analysis},
            pdfauthor={Paul M. Magwene},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Biology 304: Biological Data Analysis}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Paul M. Magwene}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2018-12-06}


\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

\hypertarget{how-to-use-these-lecture-notes}{%
\section{How to use these lecture
notes}\label{how-to-use-these-lecture-notes}}

In this and future materials to be posted on the course website you'll
encounter blocks of R code. \emph{Your natural intuition will be to cut
and paste commands or code blocks into the R interpretter to save
yourself the typing.} \textbf{DO NOT DO THIS!!}

In each of the examples below, I provide example input, but I don't show
you the output. It's your job to type in these examples at the R
console, evaluate what you typed, and to look at and think critically
about the output. \textbf{You will make mistakes and generate errors!}
Part of learning any new skill is making mistakes, figuring out where
you went wrong, and correcting those mistakes. In the process of fixing
those errors, you'll learn more about how R works, and how to avoid such
errors, or correct bugs in your own code in the future. If you cut and
paste the examples into the R interpretter the code will run, but you
will learn less than if you input the code yourself and you'll be less
capable of apply the concepts in new situations.

The R interpretter, like all programming languages, is very exacting. A
mispelled variable or function name, a stray period, or an unbalanced
parenthesis will raise an error and finding the sources of such errors
can sometimes be tedious and frustrating. Persist! If you read your code
critically, think about what your doing, and seek help when needed
(teaching team, R help, Google, etc) you'll eventually get better at
debugging your code. But keep in mind that like most new skills,
learning to write and debug your code efficiently takes time and
experience.

\hypertarget{data-story-women-and-children-first-on-the-titanic}{%
\chapter{Data story: Women and children first on the
Titanic?}\label{data-story-women-and-children-first-on-the-titanic}}

This introductory chapter illustrates some of the tools and concepts
you'll learn in this class, such as visualization, data restructuring,
and model building. By the end of this course, you should be able to
carry out similar analyses and make well reasoned interpreation of those
analyses for a variety of complex biological data.

\hypertarget{background}{%
\section{Background}\label{background}}

On April 10, 1912 the RMS Titanic left Southhampton, England headed for
New York. Aboard were 2,435 passengers and 892 crew members. Five days
later, about 20 minutes before midnight, the Titanic hit an iceberg in
the frigid waters about 375 miles south of New Foundland. Within
approximately two and a half hours the ship had split apart and sunk,
leaving just over 700 survivors.

\begin{figure}
\centering
\includegraphics{./figures/fig-titanic.png}
\caption{The Titanic}
\end{figure}

\hypertarget{dataset}{%
\section{Dataset}\label{dataset}}

The \texttt{titanic\_data.csv} file (available on the
\href{https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/titanic_data.csv}{course
git repository}) containers information on 1309 passengers from aboard
the Titanic (CSV stands for Comma-Separated-Values, a simple plain text
format for storing spreadhsheet data). Variables in this data set
include gender, age, ticketed class, the passenger's destitation,
whether they survived, etc. We'll use this data set to explore some of
the demographics of the passengers who were aboard the ship, and how
their relationship to whether a passenger survived or not. For a
detailed description of this data set, see
\href{http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3info.txt}{this
link}.

We'll use this data to explore whether the saying ``Women and children
first!'' applied on the Titanic.

\hypertarget{libraries}{%
\section{Libraries}\label{libraries}}

First we'll load some R libraries (packages) that contain useful
functions that will make our analyses quicker and more efficient. We'll
discuss the functions that these libraries provide, and how to use
libraries in general, in greater detail in a future lecture.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{library}\NormalTok{(readr)}
\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{library}\NormalTok{(tidyr)}
\KeywordTok{library}\NormalTok{(forcats)}
\end{Highlighting}
\end{Shaded}

\hypertarget{read-data}{%
\section{Read data}\label{read-data}}

We start by reading in the data from the CSV file.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"~/Downloads/titanic_data.csv"}\NormalTok{)}
\CommentTok{#> Parsed with column specification:}
\CommentTok{#> cols(}
\CommentTok{#>   pclass = col_integer(),}
\CommentTok{#>   survived = col_integer(),}
\CommentTok{#>   name = col_character(),}
\CommentTok{#>   sex = col_character(),}
\CommentTok{#>   age = col_double(),}
\CommentTok{#>   sibsp = col_integer(),}
\CommentTok{#>   parch = col_integer(),}
\CommentTok{#>   ticket = col_character(),}
\CommentTok{#>   fare = col_double(),}
\CommentTok{#>   cabin = col_character(),}
\CommentTok{#>   embarked = col_character(),}
\CommentTok{#>   boat = col_character(),}
\CommentTok{#>   body = col_integer(),}
\CommentTok{#>   home.dest = col_character()}
\CommentTok{#> )}
\end{Highlighting}
\end{Shaded}

The function \texttt{read\_csv} does exactly what it advertises -- reads
a data set from a CSV file and returns it as an object we can compute
on. In this case we assigned the variable name \texttt{titanic} to our
data set. Simple enough!

\hypertarget{whats-in-the-data}{%
\section{What's in the data?}\label{whats-in-the-data}}

The function \texttt{read\_csv} returns a table, where the columns
represent the variables of interest (e.g.~sex, age, etc) and the rows
represent individuals or observations. Let's take a look at the first
few rows of the data set using the \texttt{head()} function (can you
guess the name of the corresponding function for looking at the last few
rows?):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(titanic)}
\CommentTok{#> # A tibble: 6 x 14}
\CommentTok{#>   pclass survived name  sex       age sibsp parch ticket   fare cabin}
\CommentTok{#>    <int>    <int> <chr> <chr>   <dbl> <int> <int> <chr>   <dbl> <chr>}
\CommentTok{#> 1      1        1 Alle~ fema~ 29          0     0 24160  211.3  B5   }
\CommentTok{#> 2      1        1 Alli~ male   0.9167     1     2 113781 151.6  C22 ~}
\CommentTok{#> 3      1        0 Alli~ fema~  2          1     2 113781 151.6  C22 ~}
\CommentTok{#> 4      1        0 Alli~ male  30          1     2 113781 151.6  C22 ~}
\CommentTok{#> 5      1        0 Alli~ fema~ 25          1     2 113781 151.6  C22 ~}
\CommentTok{#> 6      1        1 Ande~ male  48          0     0 19952   26.55 E12  }
\CommentTok{#> # ... with 4 more variables: embarked <chr>, boat <chr>, body <int>,}
\CommentTok{#> #   home.dest <chr>}
\end{Highlighting}
\end{Shaded}

If we simply wanted the dimensions of the data we could do:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(titanic)}
\CommentTok{#> [1] 1309   14}
\end{Highlighting}
\end{Shaded}

whereas, if we wanted to get a list of the column names in the data we
could do:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(titanic)}
\CommentTok{#>  [1] "pclass"    "survived"  "name"      "sex"       "age"      }
\CommentTok{#>  [6] "sibsp"     "parch"     "ticket"    "fare"      "cabin"    }
\CommentTok{#> [11] "embarked"  "boat"      "body"      "home.dest"}
\end{Highlighting}
\end{Shaded}

\hypertarget{simple-data-wrangling}{%
\subsection{Simple data wrangling}\label{simple-data-wrangling}}

Two variables of interest to us are \texttt{pclass} (``passenger
class'') and \texttt{survived}. These are categorical variables encoded
as numbers. Before exploring the data we're going to create derived
``factor'' variables from these, which will make our analyses more
convenient. I'm also going to recode the ``survived'' information as the
classes ``died'' and ``lived''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(titanic, }
                  \DataTypeTok{passenger.class =} \KeywordTok{fct_recode}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(pclass),}
                                               \StringTok{"1st"}\NormalTok{ =}\StringTok{ "1"}\NormalTok{, }\StringTok{"2nd"}\NormalTok{ =}\StringTok{ "2"}\NormalTok{, }\StringTok{"3rd"}\NormalTok{ =}\StringTok{ "3"}\NormalTok{),}
                  \DataTypeTok{survival =} \KeywordTok{fct_recode}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(survived), }
                                        \StringTok{"died"}\NormalTok{ =}\StringTok{ "0"}\NormalTok{, }\StringTok{"lived"}\NormalTok{ =}\StringTok{ "1"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Having added to new variables to our data set, the dimensions and column
names have changed:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(titanic)}
\CommentTok{#> [1] 1309   16}
\end{Highlighting}
\end{Shaded}

and

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(titanic)}
\CommentTok{#>  [1] "pclass"          "survived"        "name"           }
\CommentTok{#>  [4] "sex"             "age"             "sibsp"          }
\CommentTok{#>  [7] "parch"           "ticket"          "fare"           }
\CommentTok{#> [10] "cabin"           "embarked"        "boat"           }
\CommentTok{#> [13] "body"            "home.dest"       "passenger.class"}
\CommentTok{#> [16] "survival"}
\end{Highlighting}
\end{Shaded}

Note that there are now 16 columns in our data, the original 14 plus our
two new derived variables \texttt{passenger.class} and
\texttt{survival}.

\hypertarget{categorizing-passengers}{%
\section{Categorizing passengers}\label{categorizing-passengers}}

Let's start by exploring various aspects of the 1309 passengers in our
data set.

First, let's look at the gender breakdown:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(titanic, sex)}
\CommentTok{#> # A tibble: 2 x 2}
\CommentTok{#>   sex        n}
\CommentTok{#>   <chr>  <int>}
\CommentTok{#> 1 female   466}
\CommentTok{#> 2 male     843}
\end{Highlighting}
\end{Shaded}

We could also represent this data as a bar graph (though a simple table
is more efficient in this case):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sex, }\DataTypeTok{fill =}\NormalTok{ sex))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-10-1.pdf}

Both our table and bar graph tell us that there are almost twice as many
men in our data set as women.

\hypertarget{how-many-people-survived}{%
\subsection{How many people survived?}\label{how-many-people-survived}}

Now let's look at survival information:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(titanic, survival)}
\CommentTok{#> # A tibble: 2 x 2}
\CommentTok{#>   survival     n}
\CommentTok{#>   <fct>    <int>}
\CommentTok{#> 1 died       809}
\CommentTok{#> 2 lived      500}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ survival))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-12-1.pdf}

We see that more that in the data we have at hand, roughly 60\% (809 of
1309) of the passengers died.

\hypertarget{women-first}{%
\subsection{Women first?}\label{women-first}}

We can take our simple explorations a step further, by considering the
counts of passengers with respect to multiple variables. Let's look at
the relationship between gender and survival:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(titanic, sex, survival) }
\CommentTok{#> # A tibble: 4 x 3}
\CommentTok{#>   sex    survival     n}
\CommentTok{#>   <chr>  <fct>    <int>}
\CommentTok{#> 1 female died       127}
\CommentTok{#> 2 female lived      339}
\CommentTok{#> 3 male   died       682}
\CommentTok{#> 4 male   lived      161}
\end{Highlighting}
\end{Shaded}

\hypertarget{contingency-tables}{%
\subsubsection{Contingency tables}\label{contingency-tables}}

When looking at counts of multiple variables simultaneously, a more
traditional representation than the one above is a ``contingency
table''. The cells in a contingency table give the counts of individuals
with respect to combinations of variables (e.g. \# of women who
survived, \# of women who died, etc). Here's the same data on sex and
survival represented as a contingency table:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(titanic, sex, survival) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{spread}\NormalTok{(survival, n)}
\CommentTok{#> # A tibble: 2 x 3}
\CommentTok{#>   sex     died lived}
\CommentTok{#>   <chr>  <int> <int>}
\CommentTok{#> 1 female   127   339}
\CommentTok{#> 2 male     682   161}
\end{Highlighting}
\end{Shaded}

In the code above the symbol \texttt{\%\textgreater{}\%} can be read as
``pipe'' or ``send''. The pipe operator inserts the object before the
pipe as the first argument to the function after the pipe. Here we're
piping the output of the \texttt{count} function as the input into the
\texttt{spread} function. We'll see in later lectures that piping
objects makes for very powerful workflows when we do more sophisticated
analyses.

We can also create a bar plot to represent the contingency table:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(sex, }\DataTypeTok{fill =}\NormalTok{ survival))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-15-1.pdf}

Here we're already starting to see an interesting pattern -- there were
nearly twice as many men on the Titanic as women, but proportionally and
in absolute numbers more women survived.

\hypertarget{a-bar-plot-using-proportions-rather-than-counts}{%
\subsection{A bar plot using proportions rather than
counts}\label{a-bar-plot-using-proportions-rather-than-counts}}

Sometimes it's useful to look at proportions rather than absolute
numbers. Here's a figure that allows us to visually assess the different
proportions of men and women passengers who survived:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(sex, }\DataTypeTok{fill =}\NormalTok{ survival), }\DataTypeTok{position =} \StringTok{"fill"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-16-1.pdf}

\hypertarget{mosaic-plots}{%
\subsection{Mosaic plots}\label{mosaic-plots}}

A slightly more sophisticated version of a bar plot is called a ``mosaic
plot''. A mosaic plot is similar to a proportional bar plot but the
width of the bars also varies, indicating the relative numbers of
observations in each class. To create a mosaic plot we need to import
the \texttt{geom\_mosaic} function from a library called ggmosaic.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggmosaic)}

\KeywordTok{ggplot}\NormalTok{(titanic) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_mosaic}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{product}\NormalTok{(sex), }\DataTypeTok{fill =}\NormalTok{ survival)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Sex"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Proportion surviving"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-17-1.pdf}

As you can see, the mosaic plot emphasizes both that there were more men
than women on the Titanic, as well as the fact that a greater fraction
of women survived. This seems like strong evidence for the first part of
the phrase ``Women and children first''.

\hypertarget{passenger-ages}{%
\section{Passenger ages}\label{passenger-ages}}

Now let's create a visualiztion to get a handle on the ages of
passengers on the Titanic. A histogram is a common way to visualize the
distribution of a continuous variable. Creating a histogram is a simple
modification of our earlier examples where we created bar plots.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ age), }\DataTypeTok{bins =} \DecValTok{35}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-18-1.pdf}

The histogram provides a quick visual representation of the frequency of
different age groups. It appears that the the most common (modal) value
of age is a little over 20 years old. We can explicitly calculate the
mean and median age as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{age, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{#> [1] 29.88113}
\KeywordTok{median}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{age, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{#> [1] 28}
\end{Highlighting}
\end{Shaded}

Note that we have to explicitly tell the mean and median functions to
drop any missing (NA) values. Alternately, we could have use pipes to
calculate the mean and median as so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(age)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\KeywordTok{mean}\NormalTok{(age), }\KeywordTok{median}\NormalTok{(age))}
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>   `mean(age)` `median(age)`}
\CommentTok{#>         <dbl>         <dbl>}
\CommentTok{#> 1       29.88            28}
\end{Highlighting}
\end{Shaded}

\hypertarget{how-does-age-relate-to-survival}{%
\section{How does age relate to
survival?}\label{how-does-age-relate-to-survival}}

Now we turn to the question of how age relates to the probability of
survival. Age is a continuous variable, while survival is a binary
variable.

\hypertarget{strip-charts}{%
\subsection{Strip charts}\label{strip-charts}}

We'll start by creating ``strip charts'' that plot age on the y-axis,
and survival on the x-axis. First we filter out individuals for which we
have no age data, then we use a pipe to send the filtered data to the
ggplot function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(age)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(survival, age), }\DataTypeTok{width =} \FloatTok{0.1}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-21-1.pdf}

Recall that sex was an important variable in our earlier assessment of
the data. Let's create a second strip plot that takes into account both
age and sex.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(age)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(survival, age, }\DataTypeTok{color =}\NormalTok{ sex), }\DataTypeTok{width =} \FloatTok{0.1}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{sex)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-22-1.pdf}

\hypertarget{box-plots}{%
\subsection{Box plots}\label{box-plots}}

Another way to look at the data is to use a summary figure called a
``box plot''. First the simple boxplot, relating age and survival:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(age)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(survival, age))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-23-1.pdf}

A box plot depicts information about the median value (thick central
line), the first and third quartiles (lower 25\% value, upper 75\%
value) and outliers. From this simple boxplot, it doesn't look like
there is a great difference in the age distribution of passengers who
lived vs died.

Now we look at box plott for age-by-survival, conditioned on sex.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(age)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(survival, age, }\DataTypeTok{fill =}\NormalTok{ sex)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{sex)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-24-1.pdf}

Here we start to see a more interesting pattern. When comparing male
passengers, the median age of survivors appears to be a little younger
than those who died. However, when comparing female passengers the
opposite pattern seems to be at play.

\hypertarget{fitting-a-model-relating-survival-to-age-and-sex}{%
\subsection{Fitting a model relating survival to age and
sex}\label{fitting-a-model-relating-survival-to-age-and-sex}}

We can get more sophisticated by fitting a formal model to our data.
Here we use a technique called logistic regression to model the
probability of survival as a function of age, broken down for female and
male passengers separately.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(age)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ age, }\DataTypeTok{y =}\NormalTok{ survived, }\DataTypeTok{color =}\NormalTok{ sex)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{height =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.35}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"glm"}\NormalTok{, }\DataTypeTok{method.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{family=}\StringTok{"binomial"}\NormalTok{))  }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{sex) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Age"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Probability of survival"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-25-1.pdf}

The logistic regression model fit here, seems to support the trend we
saw in the box plots. When breaking the data down by sex we find that
there is a decreasing probability of survival as age increases for male
passengers, but the opposite trend for female passengers. This is pretty
interesting -- ``children first'' seemed to hold for men but not for
women.

\hypertarget{how-does-class-affect-survival}{%
\section{How does class affect
survival?}\label{how-does-class-affect-survival}}

A passenger's ticket class (a proxy for socioeconomic status) is another
interesting variable to consider in conjunction with sex and survival.

First, let's consider class on its own.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(titanic, passenger.class)}
\CommentTok{#> # A tibble: 3 x 2}
\CommentTok{#>   passenger.class     n}
\CommentTok{#>   <fct>           <int>}
\CommentTok{#> 1 1st               323}
\CommentTok{#> 2 2nd               277}
\CommentTok{#> 3 3rd               709}
\end{Highlighting}
\end{Shaded}

And as a bar graph:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ passenger.class))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-27-1.pdf}

Both our table and bar graph tell us that the largest number of
passengers (in the available data) were travelling on third-class
tickets. The numbers of first- and second-class ticketed passengers are
fairly similar.

\hypertarget{combining-sex-and-class}{%
\subsection{Combining Sex and Class}\label{combining-sex-and-class}}

Here is a bar plot that takes into account sex, class, and survival by
representing passenger class as a ``facet'' variable -- we create
different subplots for each class grouping.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(sex, }\DataTypeTok{fill =}\NormalTok{ survival), }\DataTypeTok{position =} \StringTok{"fill"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{passenger.class) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{y =} \StringTok{"Portion Died/Lived"}\NormalTok{, }\DataTypeTok{title =} \StringTok{"Titanic Survival by Sex and Class"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-28-1.pdf}

\hypertarget{extending-the-logistic-regression-model-to-consider-class-age-sex-and-survival}{%
\subsection{Extending the logistic regression model to consider class,
age, sex, and
survival}\label{extending-the-logistic-regression-model-to-consider-class-age-sex-and-survival}}

As a final example, let generate a visualization and model to jointly
consider how sex, age, and class affected survival on the Titanic. Here
we treat both sex and passenger class as faceting variables, fitting six
different logistic regression models (all combinations of the three
classes and two sexes).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(age)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ age, }\DataTypeTok{y =}\NormalTok{ survived, }\DataTypeTok{color =}\NormalTok{ sex)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{height =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.35}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"glm"}\NormalTok{, }\DataTypeTok{method.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{family=}\StringTok{"binomial"}\NormalTok{))  }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_grid}\NormalTok{(passenger.class}\OperatorTok{~}\NormalTok{sex) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Age"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Probability of survival"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-29-1.pdf}

By conditioning on both sex and ticketing class, we gain even more
insights into the data and our assesments of relationships between
variables can change.

For female passengers, ticketed class appears to have a strong influence
on the relationship between age and survival. We see that almost all of
the female first-class passengers survived, and the relationship between
age and survival is thus flat. The second class female passengers are
fairly similar, though with a slight decrease in the probability of
survival among the oldest passengers. It's not until we get to the third
class passengers that we see a strong indication of the ``children
first'' relationship playing out in terms of survival.

For the male passengers, the ``children first'' model seems to fit
across classes, but note the generally lower probability of survival
across ages when comparing first and third class passengers.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

We've only scratched the surface of the possible explorations we could
undertake of this intersting data set. However, this introductory ``data
story'' illustrates many of the tools and ideas we'll encounter in this
class. You'll be undertaking even more complex data explorations on your
own by the end of the semester!

\hypertarget{getting-started-with-r}{%
\chapter{Getting Started with R}\label{getting-started-with-r}}

\hypertarget{what-is-r}{%
\section{What is R?}\label{what-is-r}}

R is a statistical computing environment and programming language. It is
free, open source, and has a large and active community of developers
and users. There are many different R packages (libraries) available for
conducting a wide variety of different analyses, for everything from
genome sequence data to geospatial information.

\hypertarget{what-is-rstudio}{%
\section{What is RStudio?}\label{what-is-rstudio}}

RStudio (\url{http://www.rstudio.com/}) is an open source integrated
development environment (IDE) that provides a nicer graphical interface
to R than does the default R GUI.

The figure below illustrates the RStudio interface, in its default
configuration. For the exercises in this chapter you'll be primarily
entering commands in the ``console'' window. We'll review key parts of
the RStudio interface in greater detail in class.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./figures/fig-rstudio-panes-labeled} 

}

\caption{RStudio window with the panes labeled}\label{fig:unnamed-chunk-30}
\end{figure}

\hypertarget{entering-commands-in-the-console}{%
\section{Entering commands in the
console}\label{entering-commands-in-the-console}}

You can type commands directly in the console. When you hit Return
(Enter) on your keyboard the text you typed is evaluated by the R
interpreter. This means that the R program reads your commands, makes
sure there are no syntax errors, and then carries out any commands that
were specified.

Try evaluating the following arithmetic commands in the console:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{10} \OperatorTok{+}\StringTok{ }\DecValTok{5}
\DecValTok{10} \OperatorTok{-}\StringTok{ }\DecValTok{5}
\DecValTok{10} \OperatorTok{/}\StringTok{ }\DecValTok{5}
\DecValTok{10} \OperatorTok{*}\StringTok{ }\DecValTok{5}
\end{Highlighting}
\end{Shaded}

If you type an incomplete command and then hit Return on your keyboard,
the console will show a continuation line marked by a \texttt{+} symbol.
For example enter the incomplete statement \texttt{(10\ +\ 5} and then
hit Enter. You should see something like this.

\begin{verbatim}
> (10 + 5
+
\end{verbatim}

The continuation line tells you that R is waiting for additional input
before it evaluates what you typed. Either complete your command
(e.g.~type the closing parenthesis) and hit Return, or hit the ``Esc''
key to exit the continuation line without evaluating what you typed.

\hypertarget{comments}{%
\section{Comments}\label{comments}}

When working in the R console, or writing R code, the pound symbol
(\texttt{\#}) indicates the start of a comment. Anything after the
\texttt{\#}, up to the end of the current line, is ignored by the R
interpretter.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This line will be ignored}
\DecValTok{5} \OperatorTok{+}\StringTok{ }\DecValTok{4} \CommentTok{# the first part of this line, up to the #, will be evaluated}
\DecValTok{2} \CommentTok{# * 3  + 4 * 5}
\end{Highlighting}
\end{Shaded}

Throughout this course I will often include short explanatory comments
in the code examples.

\hypertarget{using-r-as-a-calculator}{%
\section{Using R as a Calculator}\label{using-r-as-a-calculator}}

The simplest way to use R is as a fancy calculator.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{10} \OperatorTok{+}\StringTok{ }\DecValTok{2} \CommentTok{# addition}
\DecValTok{10} \OperatorTok{-}\StringTok{ }\DecValTok{2} \CommentTok{# subtraction}
\DecValTok{10} \OperatorTok{*}\StringTok{ }\DecValTok{2} \CommentTok{# multiplication}
\DecValTok{10} \OperatorTok{/}\StringTok{ }\DecValTok{2} \CommentTok{# division}
\DecValTok{10} \OperatorTok{^}\StringTok{ }\DecValTok{2} \CommentTok{# exponentiation}
\DecValTok{10} \OperatorTok{**}\StringTok{ }\DecValTok{2} \CommentTok{# alternate exponentiation}
\NormalTok{pi }\OperatorTok{*}\StringTok{ }\FloatTok{2.5}\OperatorTok{^}\DecValTok{2} \CommentTok{# R knows about some constants such as Pi}
\DecValTok{10} \OperatorTok{%%}\StringTok{ }\DecValTok{3} \CommentTok{# modulus operator -- gives remainder after division}
\DecValTok{10} \OperatorTok{%/%}\StringTok{ }\DecValTok{3} \CommentTok{# integer division}
\end{Highlighting}
\end{Shaded}

Be aware that certain operators have precedence over others. For example
multiplication and division have higher precedence than addition and
subtraction. Use parentheses to disambiguate potentially confusing
statements.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{10} \OperatorTok{+}\StringTok{ }\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{4-5}   \CommentTok{# was the output what you expected?}
\NormalTok{(}\DecValTok{10} \OperatorTok{+}\StringTok{ }\DecValTok{2}\NormalTok{)}\OperatorTok{/}\NormalTok{(}\DecValTok{4-5}\NormalTok{) }\CommentTok{# compare the answer to the above}
\end{Highlighting}
\end{Shaded}

Division by zero produces an object that represents infinite numbers.
Infinite values can be either positive or negative

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{/}\DecValTok{0}  \CommentTok{# Inf}
\DecValTok{-1}\OperatorTok{/}\DecValTok{0} \CommentTok{# -Inf}
\end{Highlighting}
\end{Shaded}

Invalid calculations produce a objected called \texttt{NaN} which is
short for ``Not a Number'':

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{0}\OperatorTok{/}\DecValTok{0}  \CommentTok{# invalid calculation}
\end{Highlighting}
\end{Shaded}

\hypertarget{common-mathematical-functions}{%
\subsection{Common mathematical
functions}\label{common-mathematical-functions}}

Many commonly used mathematical functions are built into R. Here are
some examples:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{abs}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{)   }\CommentTok{# absolute value}
\KeywordTok{abs}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\KeywordTok{cos}\NormalTok{(pi}\OperatorTok{/}\DecValTok{3}\NormalTok{) }\CommentTok{# cosine}
\KeywordTok{sin}\NormalTok{(pi}\OperatorTok{/}\DecValTok{3}\NormalTok{) }\CommentTok{# sine}
\KeywordTok{log}\NormalTok{(}\DecValTok{10}\NormalTok{)   }\CommentTok{# natural logarithm}
\KeywordTok{log10}\NormalTok{(}\DecValTok{10}\NormalTok{) }\CommentTok{# log base 10}
\KeywordTok{log2}\NormalTok{(}\DecValTok{10}\NormalTok{) }\CommentTok{# log base 2}
\KeywordTok{exp}\NormalTok{(}\DecValTok{1}\NormalTok{)    }\CommentTok{# exponential function}
\KeywordTok{sqrt}\NormalTok{(}\DecValTok{10}\NormalTok{)  }\CommentTok{# square root}
\DecValTok{10} \OperatorTok{^}\StringTok{ }\FloatTok{0.5}  \CommentTok{# same as square root}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-r-help-system}{%
\section{The R Help System}\label{the-r-help-system}}

R comes with fairly extensive documentation and a simple help system.
You can access HTML versions of the R documentation under the Help tab
in Rstudio. The HTML documentation also includes information on any
packages you've installed. Take a few minutes to browse through the R
HTML documentation. In addition to the HTML documentation there is also
a search box where you can enter a term to search on (see red arrow in
figure below).

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./figures/fig-rstudio-help} 

}

\caption{The RStudio Help tab}\label{fig:unnamed-chunk-38}
\end{figure}

\hypertarget{getting-help-from-the-console}{%
\subsection{Getting help from the
console}\label{getting-help-from-the-console}}

In addition to getting help from the RStudio help tab, you can directly
search for help from the console. The help system can be invoked using
the \texttt{help} function or the \texttt{?} operator.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{help}\NormalTok{(}\StringTok{"log"}\NormalTok{)}
\NormalTok{?log}
\end{Highlighting}
\end{Shaded}

If you are using RStudio, the help results will appear in the ``Help''
tab of the Files/Plots/Packages/Help/Viewer (lower right window by
default).

What if you don't know the name of the function you want? You can use
the \texttt{help.search()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{help.search}\NormalTok{(}\StringTok{"log"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In this case \texttt{help.search("log")} returns all the functions with
the string \texttt{log} in them. For more on \texttt{help.search} type
\texttt{?help.search}.

Other useful help related functions include \texttt{apropos()} and
\texttt{example()}. \texttt{apropos} returns a list of all objects
(including function names) in the current session that match the input
string.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{apropos}\NormalTok{(}\StringTok{"log"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\texttt{example()} provides examples of how a function is used.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{example}\NormalTok{(log)}
\end{Highlighting}
\end{Shaded}

\hypertarget{variable-assignment-in-r}{%
\section{Variable assignment in R}\label{variable-assignment-in-r}}

An important concept in all programming languages is that of ``variable
assignment''. Variable assignment is the act of creating labels that
point to particular data values in a computers memory, which allows us
to apply operations to the labels rather than directly to specific
values. Variable assignment is an important mechanism of abstracting and
generalizing computational operations.

Variable assignment in R is accomplished with the assignment operator,
which is designated as \texttt{\textless{}-} (left arrow, constructed
from a left angular bracket and the minus sign). This is illustrated
below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\DecValTok{10}  \CommentTok{# assign the variable name 'x' the value 10}
\KeywordTok{sin}\NormalTok{(x)   }\CommentTok{# apply the sin function to the value x points to}
\NormalTok{x <-}\StringTok{ }\NormalTok{pi  }\CommentTok{# x now points to a different value}
\KeywordTok{sin}\NormalTok{(x)   }\CommentTok{# the same function call now produces a different result }
\end{Highlighting}
\end{Shaded}

\hypertarget{valid-variable-names}{%
\subsection{Valid variable names}\label{valid-variable-names}}

As described in the
\href{https://stat.ethz.ch/R-manual/R-devel/library/base/html/make.names.html}{R
documentation}, ``A syntactically valid name consists of letters,
numbers and the dot or underline characters and starts with a letter or
the dot not followed by a number. Names such as `.2way' are not valid,
and neither are the
\href{https://stat.ethz.ch/R-manual/R-devel/library/base/html/Reserved.html}{reserved
words}.''

Here are some examples of valid and invalid variable names. Mentally
evaluate these based on the definition above, and then evaluate these in
the R interpetter to confirm your understanding :

\begin{verbatim}
x <- 10
x.prime <- 10
x_prime <- 10
my.long.variable.name <- 10
another_long_variable_name <- 10
_x <- 10
.x <- 10
2.x <- 2 * x
\end{verbatim}

\hypertarget{data-types}{%
\section{Data types}\label{data-types}}

All of our arithmetic examples above produced numerical values. The
default numerical data type in R is called a ``double''. ``double'' is
short for ``double precision floating point value'' which refers to the
numerical precision that R uses when carrying out calculations.

R has a function called \texttt{typeof()} that we can use to get
information about an object's type. Let's illustrate the use of
\texttt{typeof()} and confirm that our numerical calculations return
objects of the ``double'' type:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typeof}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\NormalTok{x <-}\StringTok{ }\FloatTok{10.5}
\KeywordTok{typeof}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\hypertarget{logical-values}{%
\section{Logical values}\label{logical-values}}

When we compare values to each other, our calculations no longer return
``doubles'' but rather \texttt{TRUE} and \texttt{FALSE} values. This is
illustrated below:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{10} \OperatorTok{<}\StringTok{ }\DecValTok{9}  \CommentTok{# is 10 less than 9?}
\DecValTok{10} \OperatorTok{>}\StringTok{ }\DecValTok{9}  \CommentTok{# is 10 greater than 9?}
\DecValTok{10} \OperatorTok{<=}\StringTok{ }\NormalTok{(}\DecValTok{5} \OperatorTok{*}\StringTok{ }\DecValTok{2}\NormalTok{) }\CommentTok{# less than or equal to?}
\DecValTok{10} \OperatorTok{>=}\StringTok{ }\NormalTok{pi }\CommentTok{# greater than or equal to?}
\DecValTok{10} \OperatorTok{==}\StringTok{ }\DecValTok{10} \CommentTok{# equals?}
\DecValTok{10} \OperatorTok{!=}\StringTok{ }\DecValTok{10} \CommentTok{# does not equal?}
\end{Highlighting}
\end{Shaded}

\texttt{TRUE} and \texttt{FALSE} objects are of ``logical'' data type
(known as ``Booleans'' in many other languages, after the mathematician
George Boole).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typeof}\NormalTok{(}\OtherTok{TRUE}\NormalTok{)}
\KeywordTok{typeof}\NormalTok{(}\OtherTok{FALSE}\NormalTok{)}
\NormalTok{x <-}\StringTok{ }\OtherTok{FALSE}
\KeywordTok{typeof}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

When working with numerical data, tests of equality can be tricky. For
example, consider the following two comparisons:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{10} \OperatorTok{==}\StringTok{ }\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{10}\NormalTok{)}\OperatorTok{^}\DecValTok{2}\NormalTok{) }\CommentTok{# Surprised by the result? See below.}
\DecValTok{4} \OperatorTok{==}\StringTok{ }\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{4}\NormalTok{)}\OperatorTok{^}\DecValTok{2}\NormalTok{) }\CommentTok{# Even more confused?}
\end{Highlighting}
\end{Shaded}

Mathematically we know that both \((\sqrt{10})^2 = 10\) and
\((\sqrt{4})^2 = 4\) are true statements. Why does R tell us the first
statement is false? What we're running into here are the limits of
computer precision. A computer can't represent \(\sqrt 10\) exactly,
whereas \(\sqrt 4\) can be exactly represented. Precision in numerical
computing is a complex subject and a detailed discussion is beyond the
scope of this course. However, it's important to be aware of this
limitation (this limitation is true of any programming language, not
just R).

To test ``near equality'' R provides a function called
\texttt{all.equal()}. This function takes two inputs -- the numerical
values to be compared -- and returns True if their values are equal up
to a certain level of tolerance (defined by the built-in numerical
precision of your computer).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all.equal}\NormalTok{(}\DecValTok{10}\NormalTok{, }\KeywordTok{sqrt}\NormalTok{(}\DecValTok{10}\NormalTok{)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{logical-operators}{%
\subsection{Logical operators}\label{logical-operators}}

Logical values support Boolean operations, like logical negation
(``not''), ``and'', ``or'', ``xor'', etc. This is illustrated below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\OtherTok{TRUE}
\NormalTok{y <-}\StringTok{ }\OtherTok{FALSE}
\OperatorTok{!}\NormalTok{x  }\CommentTok{# logical negation -- reads as "not x"}
\NormalTok{x }\OperatorTok{&}\StringTok{ }\NormalTok{y }\CommentTok{# AND: are x and y both TRUE?}
\NormalTok{x }\OperatorTok{|}\StringTok{ }\NormalTok{y }\CommentTok{# OR: are either x or y TRUE?}
\KeywordTok{xor}\NormalTok{(x,y)  }\CommentTok{# XOR: is either x or y TRUE, but not both?}
\end{Highlighting}
\end{Shaded}

The function \texttt{isTRUE} is sometimes useful:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\DecValTok{5}
\NormalTok{y <-}\StringTok{ }\DecValTok{10}
\NormalTok{z <-}\StringTok{ }\NormalTok{x }\OperatorTok{>}\StringTok{ }\NormalTok{y}
\KeywordTok{isTRUE}\NormalTok{(z)}
\end{Highlighting}
\end{Shaded}

\hypertarget{character-strings}{%
\section{Character strings}\label{character-strings}}

Character strings (``character'') represent single textual characters or
a longer sequence of characters. They are created by enclosing the
characters in text either single our double quotes.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typeof}\NormalTok{(}\StringTok{"abc"}\NormalTok{)  }\CommentTok{# double quotes }
\CommentTok{#> [1] "character"}
\KeywordTok{typeof}\NormalTok{(}\StringTok{'abc'}\NormalTok{)  }\CommentTok{# single quotes}
\CommentTok{#> [1] "character"}
\end{Highlighting}
\end{Shaded}

Character strings have a length, which can be found using the
\texttt{nchar} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{first.name <-}\StringTok{ "jasmine"}
\KeywordTok{nchar}\NormalTok{(first.name)}
\CommentTok{#> [1] 7}

\NormalTok{last.name <-}\StringTok{ 'smith'}
\KeywordTok{nchar}\NormalTok{(last.name)}
\CommentTok{#> [1] 5}
\end{Highlighting}
\end{Shaded}

There are a number of built-in functions for manipulating character
strings. Here are some of the most common ones.

\hypertarget{joining-strings}{%
\subsection{Joining strings}\label{joining-strings}}

The \texttt{paste()} function joins two characters strings together:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{paste}\NormalTok{(first.name, last.name)  }\CommentTok{# join two strings}
\CommentTok{#> [1] "jasmine smith"}
\KeywordTok{paste}\NormalTok{(}\StringTok{"abc"}\NormalTok{, }\StringTok{"def"}\NormalTok{)}
\CommentTok{#> [1] "abc def"}
\end{Highlighting}
\end{Shaded}

Notice that \texttt{paste()} adds a space between the strings? If we
didn't want the space we can call the \texttt{paste()} function with an
optional argument called \texttt{sep} (short for separator) which
specifies the character(s) that are inserted between the joined strings.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{paste}\NormalTok{(}\StringTok{"abc"}\NormalTok{, }\StringTok{"def"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)  }\CommentTok{# join with no space; "" is an empty string}
\CommentTok{#> [1] "abcdef"}
\KeywordTok{paste}\NormalTok{(}\StringTok{"abc"}\NormalTok{, }\StringTok{"def"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{"|"}\NormalTok{) }\CommentTok{# join with a vertical bar}
\CommentTok{#> [1] "abc|def"}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-strings}{%
\subsection{Splitting strings}\label{splitting-strings}}

The \texttt{strsplit()} function allows us to split a character string
into substrains according to matches to a substring. For example, we
could break a sentence into it's constituent words as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sentence <-}\StringTok{ "Call me Ishmael."}
\NormalTok{words <-}\StringTok{ }\KeywordTok{strsplit}\NormalTok{(sentence, }\StringTok{" "}\NormalTok{)  }\CommentTok{# split on space}
\NormalTok{words}
\CommentTok{#> [[1]]}
\CommentTok{#> [1] "Call"     "me"       "Ishmael."}
\end{Highlighting}
\end{Shaded}

Notice that \texttt{strsplit()} is the reverse of \texttt{paste()}.

\hypertarget{substrings}{%
\subsection{Substrings}\label{substrings}}

The \texttt{substr()} function allows us to extract a substring from a
character object by specifying the first and last positions (indices) to
use in the extraction:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{substr}\NormalTok{(}\StringTok{"abcdef"}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{)  }\CommentTok{# get substring from characters 2 to 5}
\CommentTok{#> [1] "bcde"}
\KeywordTok{substr}\NormalTok{(first.name, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{) }\CommentTok{# get substring from characters 1 to       }
\CommentTok{#> [1] "jas"}
\end{Highlighting}
\end{Shaded}

\hypertarget{packages}{%
\section{Packages}\label{packages}}

Packages are libraries of R functions and data that provide additional
capabilities and tools beyond the standard library of functions included
with R. Hundreds of people around the world have developed packages for
R that provide functions and related data structures for conducting many
different types of analyses.

Throughout this course you'll need to install a variety of packages.
Here I show the basic procedure for installing new packages from the
console as well as from the R Studio interface.

\hypertarget{installing-packages-from-the-console}{%
\subsection{Installing packages from the
console}\label{installing-packages-from-the-console}}

The built-in function \texttt{install.packages} provides a quick and
conveniet way to install packages from the R console.

\hypertarget{install-the-tidyverse-package}{%
\subsection{Install the tidyverse
package}\label{install-the-tidyverse-package}}

To illustrate the use of \texttt{install.package}, we'll install a
collection of packages (a ``meta-package'') called the
\href{http://www.tidyverse.org}{tidyverse}. Here's how to install the
tidyverse meta-package from the R console:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"tidyverse"}\NormalTok{, }\DataTypeTok{dependencies =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The first argument to \texttt{install.packages} gives the names of the
package we want to install. The second argument,
\texttt{dependencies\ =\ TRUE}, tells R to install any additional
packages that tidyverse depends on.

\hypertarget{installing-packages-from-the-rstudio-dialog}{%
\subsection{Installing packages from the RStudio
dialog}\label{installing-packages-from-the-rstudio-dialog}}

You can also install packages using a graphical dialog provided by
RStudio. To do so pick the \texttt{Packages} tab in RStudio, and then
click the \texttt{Install} button.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./figures/fig-rstudio-packages-tab} 

}

\caption{The Packages tab in RStudio}\label{fig:unnamed-chunk-58}
\end{figure}

In the packages entry box you can type the name of the package you wish
to install.

\hypertarget{loading-packages-with-the-library-function}{%
\subsection{\texorpdfstring{Loading packages with the \texttt{library()}
function}{Loading packages with the library() function}}\label{loading-packages-with-the-library-function}}

Once a package is installed on your computer, the package can be loaded
into your R session using the \texttt{library} function. To insure our
previous install commands worked correctly, let's load the packages we
just installed.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

Since the tidyverse pacakge is a ``meta-package'' it provides some
additional info about the sub-packages that got loaded.

When you load tidyverse, you will also see a message about ``Conflicts''
as several of the functions provided in the dplyr package (a sub-package
in tidyverse) conflict with names of functions provided by the ``stats''
package which usually gets automically loaded when you start R. The
conflicting funcdtions are \texttt{filter} and \texttt{lag}. The
conflicting functions in the stats package are \texttt{lag} and
\texttt{filter} which are used in time series analysis. The
\texttt{dplyr} functions are more generally useful. Furthermore, if you
need these masked functions you can still access them by prefacing the
function name with the name of the package (e.g.
\texttt{stats::filter}).

\hypertarget{reading-data-from-a-file}{%
\section{Reading data from a file}\label{reading-data-from-a-file}}

We'll use the \texttt{read\_csv} function defined in the \texttt{readr}
package (loaded via \texttt{tidyverse}) to read a CSV formatted data
file. We'll load a data file called \texttt{possums.csv}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possums <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://tinyurl.com/bio304-possums-csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The possums data set includes information from a study of mountain
brushtail possums (\emph{Trichosurus caninus}; Lindenmayer DB et
al.~1995, Australian Journal of Zoology 43, 449-458.) The investigators
recorded variables about individual possum's sex, age, where they were
collected, and a range of morphological measurements. For example the
variable \texttt{skullw} is the width of the skull, \texttt{taill} is
tail length, etc.

Notice that we read the CSV file directly from a remote file via a URL.
If instead, you wanted to load a local file on your computer you would
specify the ``path'' -- i.e.~the location on your hard drive where you
stored the file. For example, here is how I would load the same file if
it was stored in the standard downloads directory on my Mac laptop:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# this assumes you're running a local version of R (i.e. on your laptop)}
\NormalTok{possums <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"/Users/pmagwene/Downloads/possums.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exploring-the-possums-data-set}{%
\section{Exploring the ``possums'' data
set}\label{exploring-the-possums-data-set}}

Let's take a moment to explore the possums data set. First, how big is
it? The \texttt{dim} function will tell us the dimensions (\# of rows
and columns) of the data table we loaded:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(possums)}
\end{Highlighting}
\end{Shaded}

What are the names of the columns of the table?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(possums)}
\end{Highlighting}
\end{Shaded}

\hypertarget{simple-tables}{%
\section{Simple tables}\label{simple-tables}}

Let's use the \texttt{count} function to count the number of male and
female possums and the number collected from each of the populations of
interest in this study (Victoria and ``other''):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(possums, sex)}
\KeywordTok{count}\NormalTok{(possums, Pop)}
\end{Highlighting}
\end{Shaded}

We can break down the counts by population and sex combinined by
specifying both variables:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(possums, Pop, sex)}
\end{Highlighting}
\end{Shaded}

How do the results differ if instead you write
\texttt{count(possums,\ sex,\ Pop)}?

Finally, let's get counts for the different age groups in the study:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(possums, age)}
\end{Highlighting}
\end{Shaded}

Notice that besides the nine age groups, there is a grouping for ``NA''.
``NA'' means ``not available'' and is the standard designation for
missing values. This table tells us there are two possums for which age
estimates were not available.

\hypertarget{simple-figures}{%
\section{Simple figures}\label{simple-figures}}

Throughout this course we'll use a package called ``ggplot2'' to
generate figures. The ggplot2 package is part of the tidyverse and is
automatically loaded when we load the tidyverse library. In the code
below, we'll demonstrate how to use ggplot by example. In a later
lecture we'll go into greater detail about how ggplot is structured and
the broader conceptual framework that underpins its design.

\hypertarget{bar-plots}{%
\section{Bar plots}\label{bar-plots}}

First let's create some simple bar plots as alternate representations of
the counts:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(possums) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sex))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-67-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(possums) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Pop))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-68-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(possums) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Pop, }\DataTypeTok{fill =}\NormalTok{ sex))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-69-1.pdf}

\hypertarget{histograms}{%
\section{Histograms}\label{histograms}}

A histogram is a special type of bar plot, typically used with
continuous data. In a histogram, we divide the range of the data into
bins of a given size, and use vertical bars to depict the frequency
(count) of observations that fall into each bin. This gives a good sense
of the intervals in which most of the observations are found.

Here is a histogram for the skull width data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(possums) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ skullw))}
\CommentTok{#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-70-1.pdf}

Notice the warning message that was generated, about the default number
of bins that were used. ggplot is alerting us that that we may want to
consider regenerating the plot with a different number of bins. Let's
try a smaller number of bins:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(possums) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ skullw), }\DataTypeTok{bins =} \DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-71-1.pdf}

Try creating histograms for \texttt{taill} and \texttt{totlngth}.

\hypertarget{scatter-plots}{%
\section{Scatter plots}\label{scatter-plots}}

A scatter plot is typically used to represent two numerical variables
simultaneously. Each point in a scatter plot is an individual in the
data set, and the location of the points represent the measured values
of the variables of interest on that individual.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(possums) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ totlngth, }\DataTypeTok{y =}\NormalTok{ taill))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-72-1.pdf}

We can add information about categorical variables to our scatter plot
by using color or shape to depict different classes

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(possums) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ totlngth, }\DataTypeTok{y =}\NormalTok{ taill, }\DataTypeTok{color =}\NormalTok{ Pop))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-73-1.pdf}

We can represent more than two categorical variables in our scatter plot
by using both shape and color. We'll also change the size and
transparency of the plotted points (via the \texttt{alpha} argument).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(possums) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ totlngth, }\DataTypeTok{y =}\NormalTok{ taill, }\DataTypeTok{color =}\NormalTok{ Pop, }\DataTypeTok{shape =}\NormalTok{ sex),}
             \DataTypeTok{size =} \DecValTok{2}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.75}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-74-1.pdf}

Explore some of the other bivariate relationships in the possums data by
creating additional scatter plots. Given 9 numerical variables, how many
distinct pairwise scatter plots could you create?

\hypertarget{r-markdown-and-r-notebooks}{%
\chapter{R Markdown and R Notebooks}\label{r-markdown-and-r-notebooks}}

RStudio comes with a useful set of tools, collectively called R
Markdown, for generating ``literate'' statistical analyses. The idea
behind literate statistical computing is that we should try to carry out
our analyses in a manner that is transparent, self-explanatory, and
reproducible. Literate statistical computing helps to ensure your
research is reproducible because:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The steps of your analyses are explicitly described, both as written
  text and the code and function calls used.
\item
  Analyses can be more easily checked for correctness and reproduced
  from your literate code.
\item
  Your literate code can serve as a template for future analyses, saving
  you time and the trouble of remembering all the gory details.
\end{enumerate}

As we'll see, R Markdown will allow us to produce statistical documents
that integrate prose, code, figures, and nicely formatted mathematics so
that we can share and explain our analyses to others. Sometimes those
``others'' are advisors, supervisors, or collaborators; sometimes the
``other'' is you six months from now. For the purposes of this class,
you will be asked to complete problem sets in the form of R Markdown
documents.

R Markdown documents are written in a light-weight markup language
called Markdown. Markdown provides simple plain text ``formatting''
commands for specifying the structured elements of a document. Markdown
was invented as a lightweight markup language for creating web pages and
blogs, and has been adopted to a variety of different purposes. This
chaptern provides a brief introduction to the capabilities of R
Markdown. For more complete details, including lots of examples, see the
\href{http://rmarkdown.rstudio.com/index.html}{R Markdown Website}.

\hypertarget{r-notebooks}{%
\section{R Notebooks}\label{r-notebooks}}

We're going to create a type of R Markdown document called an ``R
Notebook''. The \href{http://rmarkdown.rstudio.com/r_notebooks.html}{R
Notebook Documentation} describes R Notebooks as so: ``An R Notebook is
an R Markdown document with code chunks that can be executed
independently and interactively, with output visible immediately beneath
the input.''

\hypertarget{creating-an-r-notebook}{%
\section{Creating an R Notebook}\label{creating-an-r-notebook}}

To create an R Notebook select
\texttt{File\ \textgreater{}\ New\ File\ \textgreater{}\ R\ Notebook}
from the files menu in RStudio.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./figures/fig-create-rnotebook} 

}

\caption{Using the File menu to create a new R Notebook.}\label{fig:unnamed-chunk-75}
\end{figure}

\hypertarget{the-default-r-notebook-template}{%
\section{The default R Notebook
template}\label{the-default-r-notebook-template}}

The standard template that RStudio creates for you includes a header
section like the following where you can specify document properties
such as the title, author, and change the look and feel of the generated
HTML document.

\begin{verbatim}
---
title: "R Notebook"
output: html_notebook
---
\end{verbatim}

The header is followed by several example sections that illustrate a few
of the capabilities of R Markdown. Delete these and replace them with
your own code as necessary.

\hypertarget{code-and-non-code-blocks}{%
\section{Code and Non-code blocks}\label{code-and-non-code-blocks}}

R Markdown documents are divided into code blocks (also called
``chunks'') and non-code blocks. Code blocks are sets of R commands that
will be evalauted when the R Markdown document is run or ``knitted''
(see below). Non-code blocks include explanatory text, embedded images,
etc. The default notebook template includes both code and non-code
blocks.

\hypertarget{non-code-blocks}{%
\subsection{Non-code blocks}\label{non-code-blocks}}

The first bit of text in the default notebook template is a non-code
block that tells you how to use the notebook:

\begin{verbatim}
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. 
When you execute code within the notebook, the results appear
beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk 
or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 
\end{verbatim}

The text of non-code blocks can include lightweight markup information
that can be used to format HTML or PDF output generated from the R
Markdown document. Here are some examples:

\begin{verbatim}
# Simple textual formatting 

This is a paragraph with plain text.  Nothing fancy will happen here.

This is a second paragraph with *italic*, **bold**, and `verbatim` text. 

# Lists

## Bullet points lists

This is a list with bullet points:

  * Item a
  * Item b
  * Item c

## Numbered lists
  
This is a numbered list:

  1. Item 1
  #. Item 2
  #. Item 3
  
## Mathematics

R Markdown supports mathematical equations, formatted according to LaTeX
conventions. Dollar signs ($) are used to offset mathematics 
like so:  $x^2 + y^2 = z^2$.
\end{verbatim}

Notice from the example above that R Markdown supports LaTeX style
formatting of mathematical equations. For example,
\texttt{\$x\^{}2\ +\ y\^{}2\ =\ z\^{}2\$} appears as
\(x^2 + y^2 = z^2\).

\hypertarget{code-blocks}{%
\subsection{Code blocks}\label{code-blocks}}

Code blocks are delimited by matching sets of three backward ticks
(```). Everything within a code block is interpretted as an R command
and is evaluated by the R interpretter. Here's the first code block in
the default notebook template:

\begin{verbatim}
```
{r}
plot(cars)
```
\end{verbatim}

\hypertarget{running-a-code-chunk}{%
\section{Running a code chunk}\label{running-a-code-chunk}}

You can run a single code block by clicking the small green ``Run''
button in the upper right hand corner of the code block as shown in the
image below.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./figures/fig-run-code-chunk} 

}

\caption{Click the Run button to execute a code chunk.}\label{fig:unnamed-chunk-76}
\end{figure}

If you click this button the commands within this code block are
executed, and any generated output is shown below the code block.

Try running the first code block in the default template now. After the
code chunk is executed you should see a plot embedded in your R Notebook
as shown below:

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./figures/fig-rstudio-after-run-chunk} 

}

\caption{An R Notebook showing an embedded plot after executing a code chunk.}\label{fig:unnamed-chunk-77}
\end{figure}

\hypertarget{running-all-code-chunks-above}{%
\section{Running all code chunks
above}\label{running-all-code-chunks-above}}

Next to the ``Run'' button in each code chunk is a button for ``Run all
chunks above'' (see figure below). This is useful when the code chunk
you're working on depends on calculations in earlier code chunks, and
you want to evaluated those earlier code chunks prior to running the
focal code chunk.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./figures/fig-code-chunk-runall} 

}

\caption{Use the 'Run all chunks above' button to evaluate all previous code chunks.}\label{fig:unnamed-chunk-78}
\end{figure}

\hypertarget{knitting-an-r-markdown-to-html}{%
\section{``Knitting an'' R Markdown to
HTML}\label{knitting-an-r-markdown-to-html}}

Save your R Notebook as \texttt{first\_rnotebook.Rmd} (RStudio will
automatically add the \texttt{.Rmd} extension so you don't need to type
it). You can generate an HTML version of your notebook by clicking the
``Preview'' menu on the Notebook taskbar and then choosing ``Knit to
HTML'' (see image below).

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./figures/fig-rstudio-knit-to-html} 

}

\caption{Use the 'Knit to HTML' menu to generate HTML output from your R Notebook}\label{fig:unnamed-chunk-79}
\end{figure}

When an RMarkdown document is ``knit'', all of the code and non-code
blocks are executed in a ``clean'' environment, in order from top to
bottom. An output file is generated (HTML or one of the other available
output types) that shows the results of executing the notebook. By
default RStudio will pop-up a window showing you the HTML output you
generated.

Knitting a document is a good way to make sure your analysis is
reproducible. If your code compiles correctly when the document is knit,
and produces the expected output, there's a good chance that someone
else will be able to reproduce your analyses independently starting with
your R Notebook document (after accounting for differences in file
locations).

\hypertarget{sharing-your-reproducible-r-notebook}{%
\section{Sharing your reproducible R
Notebook}\label{sharing-your-reproducible-r-notebook}}

To share your R Notebook with someone else you just need to send them
the source R Markdown file (i.e.~the file with the \texttt{.Rmd}
extension). Assuming they have access to the same source data, another
user should be able to open the notebook file in RStudio and regenerate
your analyses by evaluating the individual code chunks or knitting the
document.

In this course you will be submitting homework assignments in the form
of R Notebook markdown files.

\hypertarget{more-r-basics-data-structures}{%
\chapter{More R Basics: Data
structures}\label{more-r-basics-data-structures}}

In computer science, the term ``data structure'' refers to the ways that
data are stored, retrieved, and organized in a computer's memory. Common
examples include lists, hash tables (also called dictionaries), sets,
queues, and trees. Different types of data structures are used to
support different types of operations on data.

In R, the three basic data structures are vectors, lists, and data
frames.

\hypertarget{vectors}{%
\section{Vectors}\label{vectors}}

Vectors are the core data structure in R. Vectors store an ordered lists
of items, \emph{all of the same type} (i.e.~the data in a vector are
``homogenous'' with respect to their type).

The simplest way to create a vector at the interactive prompt is to use
the \texttt{c()} function, which is short hand for ``combine'' or
``concatenate''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{)  }\CommentTok{# create a vector, assignn it the variable name `x`}
\NormalTok{x}
\CommentTok{#> [1] 2 4 6 8}
\end{Highlighting}
\end{Shaded}

Vectors in R always have a type (accessed with the \texttt{typeof()}
function) and a length (accessed with the \texttt{length()} function).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(x)}
\CommentTok{#> [1] 4}
\KeywordTok{typeof}\NormalTok{(x)}
\CommentTok{#> [1] "double"}
\end{Highlighting}
\end{Shaded}

Vectors don't have to be numerical; logical and character vectors work
just as well.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{)}
\NormalTok{y}
\CommentTok{#> [1]  TRUE  TRUE FALSE  TRUE FALSE FALSE}
\KeywordTok{typeof}\NormalTok{(y)}
\CommentTok{#> [1] "logical"}
\KeywordTok{length}\NormalTok{(y)}
\CommentTok{#> [1] 6}

\NormalTok{z <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"How"}\NormalTok{, }\StringTok{"now"}\NormalTok{, }\StringTok{"brown"}\NormalTok{, }\StringTok{"cow"}\NormalTok{)}
\NormalTok{z}
\CommentTok{#> [1] "How"   "now"   "brown" "cow"}
\KeywordTok{typeof}\NormalTok{(z)}
\CommentTok{#> [1] "character"}
\KeywordTok{length}\NormalTok{(z)}
\CommentTok{#> [1] 4}
\end{Highlighting}
\end{Shaded}

You can also use \texttt{c()} to concatenate two or more vectors
together.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{)}
\NormalTok{y <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{)  }\CommentTok{# create another vector, labeled y}
\NormalTok{xy <-}\StringTok{ }\KeywordTok{c}\NormalTok{(x,y)  }\CommentTok{# combine two vectors}
\NormalTok{xy}
\CommentTok{#> [1] 2 4 6 8 1 3 5 7 9}

\NormalTok{z <-}\StringTok{ }\KeywordTok{c}\NormalTok{(pi}\OperatorTok{/}\DecValTok{4}\NormalTok{, pi}\OperatorTok{/}\DecValTok{2}\NormalTok{, pi, }\DecValTok{2}\OperatorTok{*}\NormalTok{pi)}
\NormalTok{xyz <-}\StringTok{ }\KeywordTok{c}\NormalTok{(x, y, z)  }\CommentTok{# combine three vectors}
\NormalTok{xyz}
\CommentTok{#>  [1] 2.0000000 4.0000000 6.0000000 8.0000000 1.0000000 3.0000000 5.0000000}
\CommentTok{#>  [8] 7.0000000 9.0000000 0.7853982 1.5707963 3.1415927 6.2831853}
\end{Highlighting}
\end{Shaded}

\hypertarget{vector-arithmetic}{%
\subsection{Vector Arithmetic}\label{vector-arithmetic}}

The basic R arithmetic operations work on numeric vectors as well as on
single numbers (in fact, behind the scenes in R single numbers
\emph{are} vectors!).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{x }\OperatorTok{*}\StringTok{ }\DecValTok{2}  \CommentTok{# multiply each element of x by 2}
\CommentTok{#> [1]  4  8 12 16 20}
\NormalTok{x }\OperatorTok{-}\StringTok{ }\NormalTok{pi }\CommentTok{# subtract pi from each element of x}
\CommentTok{#> [1] -1.1415927  0.8584073  2.8584073  4.8584073  6.8584073}

\NormalTok{y <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\NormalTok{x }\OperatorTok{+}\StringTok{ }\NormalTok{y  }\CommentTok{# add together each matching element of x and y}
\CommentTok{#> [1]  2  5  9 13 19}
\NormalTok{x }\OperatorTok{*}\StringTok{ }\NormalTok{y }\CommentTok{# multiply each matching element of x and y}
\CommentTok{#> [1]  0  4 18 40 90}
\NormalTok{x}\OperatorTok{/}\NormalTok{y }\CommentTok{# divide each matching element of x and y}
\CommentTok{#> [1]      Inf 4.000000 2.000000 1.600000 1.111111}
\end{Highlighting}
\end{Shaded}

Basic numerical functions operate element-wise on numerical vectors:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sin}\NormalTok{(x)}
\CommentTok{#> [1]  0.9092974 -0.7568025 -0.2794155  0.9893582 -0.5440211}
\KeywordTok{cos}\NormalTok{(x }\OperatorTok{*}\StringTok{ }\NormalTok{pi)}
\CommentTok{#> [1] 1 1 1 1 1}
\KeywordTok{log}\NormalTok{(x)}
\CommentTok{#> [1] 0.6931472 1.3862944 1.7917595 2.0794415 2.3025851}
\end{Highlighting}
\end{Shaded}

\hypertarget{vector-recycling}{%
\subsection{Vector recycling}\label{vector-recycling}}

When vectors are not of the same length R `recycles' the elements of the
shorter vector to make the lengths conform.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\KeywordTok{length}\NormalTok{(x)}
\CommentTok{#> [1] 5}
\NormalTok{z <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{11}\NormalTok{)}
\KeywordTok{length}\NormalTok{(z)}
\CommentTok{#> [1] 4}
\NormalTok{x }\OperatorTok{+}\StringTok{ }\NormalTok{z}
\CommentTok{#> [1]  3  8 13 19 11}
\end{Highlighting}
\end{Shaded}

In the example above \texttt{z} was treated as if it was the vector
\texttt{(1,\ 4,\ 7,\ 11,\ 1)}.

\hypertarget{simple-statistical-functions-for-numeric-vectors}{%
\subsection{Simple statistical functions for numeric
vectors}\label{simple-statistical-functions-for-numeric-vectors}}

Now that we've introduced vectors as the simplest data structure for
holding collections of numerical values, we can introduce a few of the
most common statistical functions that operate on such vectors.

First let's create a vector to hold our sample data of interest. Here
I've taken a random sample of the lengths of the last names of students
enrolled in Bio 723 during Spring 2018.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{len.name <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Some common statistics of interest include minimum, maximum, mean,
median, variance, and standard deviation:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(len.name)}
\CommentTok{#> [1] 66}
\KeywordTok{min}\NormalTok{(len.name)}
\CommentTok{#> [1] 2}
\KeywordTok{max}\NormalTok{(len.name)}
\CommentTok{#> [1] 10}
\KeywordTok{mean}\NormalTok{(len.name)}
\CommentTok{#> [1] 6.6}
\KeywordTok{median}\NormalTok{(len.name)}
\CommentTok{#> [1] 7}
\KeywordTok{var}\NormalTok{(len.name)  }\CommentTok{# variance}
\CommentTok{#> [1] 6.044444}
\KeywordTok{sd}\NormalTok{(len.name)   }\CommentTok{# standard deviation}
\CommentTok{#> [1] 2.458545}
\end{Highlighting}
\end{Shaded}

The \texttt{summary()} function applied to a vector of doubles produce a
useful table of some of these key statistics:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(len.name)}
\CommentTok{#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. }
\CommentTok{#>    2.00    5.25    7.00    6.60    8.50   10.00}
\end{Highlighting}
\end{Shaded}

\hypertarget{indexing-vectors}{%
\subsection{Indexing Vectors}\label{indexing-vectors}}

Accessing the element of a vector is called ``indexing''. Indexing is
the process of specifying the numerical positions (indices) that you
want to take access from the vector.

For a vector of length \(n\), we can access the elements by the indices
\(1 \ldots n\). We say that R vectors (and other data structures like
lists) are `one-indexed'. Many other programming languages, such as
Python, C, and Java, use zero-indexing where the elements of a data
structure are accessed by the indices \(0 \ldots n-1\). Indexing errors
are a common source of bugs.

Indexing a vector is done by specifying the index in square brackets as
shown below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\KeywordTok{length}\NormalTok{(x)}
\CommentTok{#> [1] 5}

\NormalTok{x[}\DecValTok{1}\NormalTok{]  }\CommentTok{# return the 1st element of x}
\CommentTok{#> [1] 2}

\NormalTok{x[}\DecValTok{4}\NormalTok{]  }\CommentTok{# return the 4th element of x}
\CommentTok{#> [1] 8}
\end{Highlighting}
\end{Shaded}

Negative indices are used to exclude particular elements.
\texttt{x{[}-1{]}} returns all elements of \texttt{x} except the first.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[}\OperatorTok{-}\DecValTok{1}\NormalTok{]}
\CommentTok{#> [1]  4  6  8 10}
\end{Highlighting}
\end{Shaded}

You can get multiple elements of a vector by indexing by another vector.
In the example below, \texttt{x{[}c(3,5){]}} returns the third and fifth
element of x`.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{)]}
\CommentTok{#> [1]  6 10}
\end{Highlighting}
\end{Shaded}

\hypertarget{comparison-operators-applied-to-vectors}{%
\subsection{Comparison operators applied to
vectors}\label{comparison-operators-applied-to-vectors}}

When the comparison operators, such as``greater than''
(\texttt{\textgreater{}}), ``less than or equal to''
(\texttt{\textless{}=}), equality (\texttt{==}), etc. are applied to
numeric vectors, they return logical vectors:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{12}\NormalTok{)}
\NormalTok{x }\OperatorTok{<}\StringTok{ }\DecValTok{8}  \CommentTok{# returns TRUE for all elements lass than 8}
\CommentTok{#> [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE}
\end{Highlighting}
\end{Shaded}

Here's a fancier example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{>}\StringTok{ }\DecValTok{4} \OperatorTok{&}\StringTok{ }\NormalTok{x }\OperatorTok{<}\StringTok{ }\DecValTok{10}  \CommentTok{# greater than 4 AND less than 10}
\CommentTok{#> [1] FALSE FALSE  TRUE  TRUE FALSE FALSE}
\end{Highlighting}
\end{Shaded}

\hypertarget{combining-indexing-and-comparison-of-vectors}{%
\subsection{Combining Indexing and Comparison of
Vectors}\label{combining-indexing-and-comparison-of-vectors}}

A very powerful feature of R is the ability to combine the comparison
operators (which return TRUE or FALSE values) with indexing. This
facilitates data filtering and subsetting.

Here's an example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{) }
\NormalTok{x[x }\OperatorTok{>}\StringTok{ }\DecValTok{5}\NormalTok{]}
\CommentTok{#> [1]  6  8 10}
\end{Highlighting}
\end{Shaded}

In the first example we retrieved all the elements of \texttt{x} that
are larger than 5 (read as ``x where x is greater than 5''). Notice how
we got back all the elements where the statement in the brackets was
\texttt{TRUE}.

You can string together comparisons for more complex filtering.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[x }\OperatorTok{<}\StringTok{ }\DecValTok{4} \OperatorTok{|}\StringTok{ }\NormalTok{x }\OperatorTok{>}\StringTok{ }\DecValTok{8}\NormalTok{]  }\CommentTok{# less than four OR greater than 8}
\CommentTok{#> [1]  2 10}
\end{Highlighting}
\end{Shaded}

In the second example we retrieved those elements of \texttt{x} that
were smaller than four \emph{or} greater than six. Combining indexing
and comparison is a powerful concept which we'll use repeatedly in this
course.

\hypertarget{vector-manipulation}{%
\subsection{Vector manipulation}\label{vector-manipulation}}

You can combine indexing with assignment to change the elements of a
vectors:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{x[}\DecValTok{2}\NormalTok{] <-}\StringTok{ }\DecValTok{-4} 
\NormalTok{x}
\CommentTok{#> [1]  2 -4  6  8 10}
\end{Highlighting}
\end{Shaded}

You can also use indexing vectors to change multiple values at once:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{x[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{)]  <-}\StringTok{ }\DecValTok{6}
\NormalTok{x}
\CommentTok{#> [1] 6 4 6 8 6}
\end{Highlighting}
\end{Shaded}

Using logical vectors to manipulate the elements of a vector also works:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{x[x }\OperatorTok{>}\StringTok{ }\DecValTok{5}\NormalTok{] =}\StringTok{ }\DecValTok{5}    \CommentTok{# truncate all values to have max value 5}
\NormalTok{x}
\CommentTok{#> [1] 2 4 5 5 5}
\end{Highlighting}
\end{Shaded}

\hypertarget{vectors-from-regular-sequences}{%
\subsection{Vectors from regular
sequences}\label{vectors-from-regular-sequences}}

There are a variety of functions for creating regular sequences in the
form of vectors.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{:}\DecValTok{10}  \CommentTok{# create a vector with the integer values from 1 to 10}
\CommentTok{#>  [1]  1  2  3  4  5  6  7  8  9 10}
\DecValTok{20}\OperatorTok{:}\DecValTok{11}  \CommentTok{# a vector with the integer values from 20 to 11}
\CommentTok{#>  [1] 20 19 18 17 16 15 14 13 12 11}

\KeywordTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{)  }\CommentTok{# like 1:10}
\CommentTok{#>  [1]  1  2  3  4  5  6  7  8  9 10}
\KeywordTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DataTypeTok{by =} \DecValTok{2}\NormalTok{) }\CommentTok{# 1:10, in steps of 2}
\CommentTok{#> [1] 1 3 5 7 9}
\KeywordTok{seq}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DataTypeTok{by =} \FloatTok{0.25}\NormalTok{) }\CommentTok{# 2 to 4, in steps of 0.25}
\CommentTok{#> [1] 2.00 2.25 2.50 2.75 3.00 3.25 3.50 3.75 4.00}
\end{Highlighting}
\end{Shaded}

\hypertarget{additional-functions-for-working-with-vectors}{%
\subsection{Additional functions for working with
vectors}\label{additional-functions-for-working-with-vectors}}

The function \texttt{unique()} returns the unique items in a vector:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\KeywordTok{unique}\NormalTok{(x)}
\CommentTok{#> [1] 5 2 1 4 6 9 8 7}
\end{Highlighting}
\end{Shaded}

\texttt{rev()} returns the items in reverse order (without changing the
input vector):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y <-}\StringTok{ }\KeywordTok{rev}\NormalTok{(x)}
\NormalTok{y}
\CommentTok{#>  [1] 9 7 5 8 9 6 4 1 2 5}
\NormalTok{x  }\CommentTok{# x is still in original order}
\CommentTok{#>  [1] 5 2 1 4 6 9 8 5 7 9}
\end{Highlighting}
\end{Shaded}

There are a number of useful functions related to sorting. Plain
\texttt{sort()} returns a new vector with the items in sorted order:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sorted.x <-}\StringTok{ }\KeywordTok{sort}\NormalTok{(x)  }\CommentTok{# returns items of x sorted}
\NormalTok{sorted.x}
\CommentTok{#>  [1] 1 2 4 5 5 6 7 8 9 9}

\NormalTok{x        }\CommentTok{# but x remains in its unsorted state}
\CommentTok{#>  [1] 5 2 1 4 6 9 8 5 7 9}
\end{Highlighting}
\end{Shaded}

The related function \texttt{order()} gives the indices which would
rearrange the items into sorted order:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{order}\NormalTok{(x)}
\CommentTok{#>  [1]  3  2  4  1  8  5  9  7  6 10}
\end{Highlighting}
\end{Shaded}

\texttt{order()} can be useful when you want to sort one list by the
values of another:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{students <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"fred"}\NormalTok{, }\StringTok{"tabitha"}\NormalTok{, }\StringTok{"beatriz"}\NormalTok{, }\StringTok{"jose"}\NormalTok{)}
\NormalTok{class.ranking <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)}

\NormalTok{students[}\KeywordTok{order}\NormalTok{(class.ranking)]  }\CommentTok{# get the students sorted by their class.ranking}
\CommentTok{#> [1] "beatriz" "tabitha" "jose"    "fred"}
\end{Highlighting}
\end{Shaded}

\texttt{any()} and \texttt{all()}, return single boolean values based on
a specified comparison provided as an argument:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{)}

\KeywordTok{any}\NormalTok{(y }\OperatorTok{>}\StringTok{ }\DecValTok{5}\NormalTok{) }\CommentTok{# returns TRUE if any of the elements are TRUE}
\CommentTok{#> [1] TRUE}

\KeywordTok{all}\NormalTok{(y }\OperatorTok{>}\StringTok{ }\DecValTok{5}\NormalTok{) }\CommentTok{# returns TRUE if all of the elements are TRUE}
\CommentTok{#> [1] FALSE}
\end{Highlighting}
\end{Shaded}

\texttt{which()} returns the \emph{indices} of the vector for which the
input is true:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{which}\NormalTok{(y }\OperatorTok{>}\StringTok{ }\DecValTok{5}\NormalTok{)}
\CommentTok{#> [1] 4 5}
\end{Highlighting}
\end{Shaded}

\hypertarget{lists}{%
\section{Lists}\label{lists}}

R lists are like vectors, but unlike a vector where all the elements are
of the same type, the elements of a list can have arbitrary types (even
other lists). Lists are a powerful data structure for organizing
information, because there are few constraints on the shape or types of
the data included in a list.

Lists are easy to create:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\StringTok{'Bob'}\NormalTok{, pi, }\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that lists can contain arbitrary data. Lists can even contain other
lists:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\StringTok{'Bob'}\NormalTok{, pi, }\DecValTok{10}\NormalTok{, }\KeywordTok{list}\NormalTok{(}\StringTok{"foo"}\NormalTok{, }\StringTok{"bar"}\NormalTok{, }\StringTok{"baz"}\NormalTok{, }\StringTok{"qux"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Lists are displayed with a particular format, distinct from vectors:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l}
\CommentTok{#> [[1]]}
\CommentTok{#> [1] "Bob"}
\CommentTok{#> }
\CommentTok{#> [[2]]}
\CommentTok{#> [1] 3.141593}
\CommentTok{#> }
\CommentTok{#> [[3]]}
\CommentTok{#> [1] 10}
\CommentTok{#> }
\CommentTok{#> [[4]]}
\CommentTok{#> [[4]][[1]]}
\CommentTok{#> [1] "foo"}
\CommentTok{#> }
\CommentTok{#> [[4]][[2]]}
\CommentTok{#> [1] "bar"}
\CommentTok{#> }
\CommentTok{#> [[4]][[3]]}
\CommentTok{#> [1] "baz"}
\CommentTok{#> }
\CommentTok{#> [[4]][[4]]}
\CommentTok{#> [1] "qux"}
\end{Highlighting}
\end{Shaded}

In the example above, the correspondence between the list and its
display is obvious for the first three items. The fourth element may be
a little confusing at first. Remember that the fourth item of \texttt{l}
was another list. So what's being shown in the output for the fourth
item is the nested list.

An alternative way to display a list is using the \texttt{str()}
function (short for ``structure''). \texttt{str()} provides a more
compact representation that also tells us what type of data each element
is:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(l)}
\CommentTok{#> List of 4}
\CommentTok{#>  $ : chr "Bob"}
\CommentTok{#>  $ : num 3.14}
\CommentTok{#>  $ : num 10}
\CommentTok{#>  $ :List of 4}
\CommentTok{#>   ..$ : chr "foo"}
\CommentTok{#>   ..$ : chr "bar"}
\CommentTok{#>   ..$ : chr "baz"}
\CommentTok{#>   ..$ : chr "qux"}
\end{Highlighting}
\end{Shaded}

\hypertarget{length-and-type-of-lists}{%
\subsection{Length and type of lists}\label{length-and-type-of-lists}}

Like vectors, lists have length:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(l)}
\CommentTok{#> [1] 4}
\end{Highlighting}
\end{Shaded}

But the type of a list is simply ``list'', not the type of the items
within the list. This makes sense because lists are allowed to be
heterogeneous (i.e.~hold data of different types).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typeof}\NormalTok{(l)}
\CommentTok{#> [1] "list"}
\end{Highlighting}
\end{Shaded}

\hypertarget{indexing-lists}{%
\subsection{Indexing lists}\label{indexing-lists}}

Lists have two indexing operators. Indexing a list with single brackets,
like we did with vectors, returns a new list containing the element at
index \(i\). Lists also support double bracket indexing
(\texttt{x{[}{[}i{]}{]}}) which returns the \emph{bare} element at index
\(i\) (i.e.~the element without the enclosing list). \textbf{This is a
subtle but important point so make sure you understand the difference
between these two forms of indexing.}

\hypertarget{single-bracket-list-indexing}{%
\subsubsection{Single bracket list
indexing}\label{single-bracket-list-indexing}}

First, let's demonstrate single bracket indexing of the lists \texttt{l}
we created above.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l[}\DecValTok{1}\NormalTok{]           }\CommentTok{# single brackets, returns list('Bob') }
\CommentTok{#> [[1]]}
\CommentTok{#> [1] "Bob"}
\KeywordTok{typeof}\NormalTok{(l[}\DecValTok{1}\NormalTok{])   }\CommentTok{# notice the list type}
\CommentTok{#> [1] "list"}
\end{Highlighting}
\end{Shaded}

When using single brackets, lists support indexing with ranges and
numeric vectors:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l[}\DecValTok{3}\OperatorTok{:}\DecValTok{4}\NormalTok{]}
\CommentTok{#> [[1]]}
\CommentTok{#> [1] 10}
\CommentTok{#> }
\CommentTok{#> [[2]]}
\CommentTok{#> [[2]][[1]]}
\CommentTok{#> [1] "foo"}
\CommentTok{#> }
\CommentTok{#> [[2]][[2]]}
\CommentTok{#> [1] "bar"}
\CommentTok{#> }
\CommentTok{#> [[2]][[3]]}
\CommentTok{#> [1] "baz"}
\CommentTok{#> }
\CommentTok{#> [[2]][[4]]}
\CommentTok{#> [1] "qux"}
\NormalTok{l[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{)]}
\CommentTok{#> [[1]]}
\CommentTok{#> [1] "Bob"}
\CommentTok{#> }
\CommentTok{#> [[2]]}
\CommentTok{#> [1] 10}
\CommentTok{#> }
\CommentTok{#> [[3]]}
\CommentTok{#> NULL}
\end{Highlighting}
\end{Shaded}

\hypertarget{double-bracket-list-indexing}{%
\subsubsection{Double bracket list
indexing}\label{double-bracket-list-indexing}}

If double bracket indexing is used, the object at the given index in a
list is returned:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l[[}\DecValTok{1}\NormalTok{]]         }\CommentTok{# double brackets, return plain 'Bob'}
\CommentTok{#> [1] "Bob"}
\KeywordTok{typeof}\NormalTok{(l[[}\DecValTok{1}\NormalTok{]]) }\CommentTok{# notice the 'character' type}
\CommentTok{#> [1] "character"}
\end{Highlighting}
\end{Shaded}

Double bracket indexing does not support multiple indices, but you can
chain together double bracket operators to pull out the items of
sublists. For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# second item of the fourth item of the list}
\NormalTok{l[[}\DecValTok{4}\NormalTok{]][[}\DecValTok{2}\NormalTok{]]  }
\CommentTok{#> [1] "bar"}
\end{Highlighting}
\end{Shaded}

\hypertarget{naming-list-elements}{%
\subsection{Naming list elements}\label{naming-list-elements}}

The elements of a list can be given names when the list is created:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{first.name=}\StringTok{'Alice'}\NormalTok{, }\DataTypeTok{last.name=}\StringTok{"Qux"}\NormalTok{, }\DataTypeTok{age=}\DecValTok{27}\NormalTok{, }\DataTypeTok{years.in.school=}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can retrieve the names associated with a list using the
\texttt{names} function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(p)}
\CommentTok{#> [1] "first.name"      "last.name"       "age"             "years.in.school"}
\end{Highlighting}
\end{Shaded}

If a list has named elements, you can retrieve the corresponding
elements by indexing with the quoted name in either single or double
brackets. Consistent with previous usage, single brackets return a list
with the corresponding named element, whereas double brackets return the
bare element.

For example, make sure you understand the difference in the output
generated by these two indexing calls:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p[}\StringTok{"first.name"}\NormalTok{]}
\CommentTok{#> $first.name}
\CommentTok{#> [1] "Alice"}

\NormalTok{p[[}\StringTok{"first.name"}\NormalTok{]]}
\CommentTok{#> [1] "Alice"}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-operator}{%
\subsection{\texorpdfstring{The \texttt{\$}
operator}{The \$ operator}}\label{the-operator}}

Retrieving named elements of lists (and data frames as we'll see), turns
out to be a pretty common task (especially when doing interactive data
analysis) so R has a special operator to make this more convenient. This
is the \texttt{\$} operator, which is used as illustrated below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p}\OperatorTok{$}\NormalTok{first.name  }\CommentTok{# equivalent to p[["first.name"]]}
\CommentTok{#> [1] "Alice"}
\NormalTok{p}\OperatorTok{$}\NormalTok{age         }\CommentTok{# equivalent to p[["age"]]}
\CommentTok{#> [1] 27}
\end{Highlighting}
\end{Shaded}

\hypertarget{changing-and-adding-lists-items}{%
\subsection{Changing and adding lists
items}\label{changing-and-adding-lists-items}}

Combining indexing and assignment allows you to change items in a list:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{suspect <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{first.name =} \StringTok{"unknown"}\NormalTok{, }
                \DataTypeTok{last.name =} \StringTok{"unknown"}\NormalTok{, }
                \DataTypeTok{aka =} \StringTok{"little"}\NormalTok{)}

\NormalTok{suspect}\OperatorTok{$}\NormalTok{first.name <-}\StringTok{ "Bo"}
\NormalTok{suspect}\OperatorTok{$}\NormalTok{last.name <-}\StringTok{ "Peep"}
\NormalTok{suspect[[}\DecValTok{3}\NormalTok{]] <-}\StringTok{ "LITTLE"}

\KeywordTok{str}\NormalTok{(suspect)}
\CommentTok{#> List of 3}
\CommentTok{#>  $ first.name: chr "Bo"}
\CommentTok{#>  $ last.name : chr "Peep"}
\CommentTok{#>  $ aka       : chr "LITTLE"}
\end{Highlighting}
\end{Shaded}

By combining assignment with a new name or an index past the end of the
list you can add items to a list:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{suspect}\OperatorTok{$}\NormalTok{age <-}\StringTok{ }\DecValTok{17}  \CommentTok{# add a new item named age}
\NormalTok{suspect[[}\DecValTok{5}\NormalTok{]] <-}\StringTok{ "shepardess"}   \CommentTok{# create an unnamed item at position 5}
\end{Highlighting}
\end{Shaded}

Be careful when adding an item using indexing, because if you skip an
index an intervening NULL value is created:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# there are only five items in the list, what happens if we}
\CommentTok{# add a new item at position seven?}
\NormalTok{suspect[[}\DecValTok{7}\NormalTok{]] <-}\StringTok{ "wanted for sheep stealing"}

\KeywordTok{str}\NormalTok{(suspect)}
\CommentTok{#> List of 7}
\CommentTok{#>  $ first.name: chr "Bo"}
\CommentTok{#>  $ last.name : chr "Peep"}
\CommentTok{#>  $ aka       : chr "LITTLE"}
\CommentTok{#>  $ age       : num 17}
\CommentTok{#>  $           : chr "shepardess"}
\CommentTok{#>  $           : NULL}
\CommentTok{#>  $           : chr "wanted for sheep stealing"}
\end{Highlighting}
\end{Shaded}

\hypertarget{combining-lists}{%
\subsection{Combining lists}\label{combining-lists}}

The \texttt{c} (combine) function we introduced to create vectors can
also be used to combine lists:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{list.a <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\StringTok{"little"}\NormalTok{, }\StringTok{"bo"}\NormalTok{, }\StringTok{"peep"}\NormalTok{)}
\NormalTok{list.b <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\StringTok{"has lost"}\NormalTok{, }\StringTok{"her"}\NormalTok{, }\StringTok{"sheep"}\NormalTok{)}
\NormalTok{list.c <-}\StringTok{ }\KeywordTok{c}\NormalTok{(list.a, list.b)}
\NormalTok{list.c}
\CommentTok{#> [[1]]}
\CommentTok{#> [1] "little"}
\CommentTok{#> }
\CommentTok{#> [[2]]}
\CommentTok{#> [1] "bo"}
\CommentTok{#> }
\CommentTok{#> [[3]]}
\CommentTok{#> [1] "peep"}
\CommentTok{#> }
\CommentTok{#> [[4]]}
\CommentTok{#> [1] "has lost"}
\CommentTok{#> }
\CommentTok{#> [[5]]}
\CommentTok{#> [1] "her"}
\CommentTok{#> }
\CommentTok{#> [[6]]}
\CommentTok{#> [1] "sheep"}
\end{Highlighting}
\end{Shaded}

\hypertarget{converting-lists-to-vectors}{%
\subsection{Converting lists to
vectors}\label{converting-lists-to-vectors}}

Sometimes it's useful to convert a list to a vector. The
\texttt{unlist()} function takes care of this for us.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# a homogeneous list}
\NormalTok{ex1 <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{)}
\KeywordTok{unlist}\NormalTok{(ex1)}
\CommentTok{#> [1] 2 4 6 8}
\end{Highlighting}
\end{Shaded}

When you convert a list to a vector make sure you remember that vectors
are homogeneous, so items within the new vector will be ``coerced'' to
have the same type.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# a heterogeneous list}
\NormalTok{ex2 <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"bob"}\NormalTok{, }\StringTok{"fred"}\NormalTok{), }\KeywordTok{list}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{0i, }\StringTok{'foo'}\NormalTok{))}
\KeywordTok{unlist}\NormalTok{(ex2)}
\CommentTok{#> [1] "2"    "4"    "6"    "bob"  "fred" "1+0i" "foo"}
\end{Highlighting}
\end{Shaded}

Note that \texttt{unlist()} also unpacks nested vectors and lists as
shown in the second example above.

\hypertarget{data-frames}{%
\section{Data frames}\label{data-frames}}

Along with vectors and lists, data frames are one of the core data
structures when working in R. A data frame is essentially a list which
represents a data table, where each column in the table has the same
number of rows and every item in the a column has to be of the same
type. Unlike standard lists, the objects (columns) in a data frame must
have names. We've seen data frames previously, for example when we
loaded data sets using the \texttt{read\_csv} function.

\hypertarget{creating-a-data-frame}{%
\subsection{Creating a data frame}\label{creating-a-data-frame}}

While data frames will often be created by reading in a data set from a
file, they can also be created directly in the console as illustrated
below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{age <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{29}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{24}\NormalTok{, }\DecValTok{23}\NormalTok{, }\DecValTok{20}\NormalTok{)}
\NormalTok{sex <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"M"}\NormalTok{,}\StringTok{"F"}\NormalTok{), }\DecValTok{5}\NormalTok{)}
\NormalTok{wt.in.kg <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{88}\NormalTok{, }\DecValTok{76}\NormalTok{, }\DecValTok{67}\NormalTok{, }\DecValTok{66}\NormalTok{, }\DecValTok{56}\NormalTok{, }\DecValTok{74}\NormalTok{, }\DecValTok{71}\NormalTok{, }\DecValTok{60}\NormalTok{, }\DecValTok{52}\NormalTok{, }\DecValTok{72}\NormalTok{)}

\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{age =}\NormalTok{ age, }\DataTypeTok{sex =}\NormalTok{ sex, }\DataTypeTok{wt =}\NormalTok{ wt.in.kg)}
\end{Highlighting}
\end{Shaded}

Here we created a data frame with three columns, each of length 10.

\hypertarget{type-and-class-for-data-frames}{%
\subsection{Type and class for data
frames}\label{type-and-class-for-data-frames}}

Data frames can be thought of as specialized lists, and in fact the type
of a data frame is ``list'' as illustrated below:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typeof}\NormalTok{(df)}
\CommentTok{#> [1] "list"}
\end{Highlighting}
\end{Shaded}

To distinguish a data frame from a generic list, we have to ask about
it's ``class''.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(df) }\CommentTok{# the class of our data frame}
\CommentTok{#> [1] "data.frame"}
\KeywordTok{class}\NormalTok{(l)  }\CommentTok{# compare to the class of our generic list}
\CommentTok{#> [1] "list"}
\end{Highlighting}
\end{Shaded}

The term ``class'' comes from a style/approach to programming called
``object oriented programming''. We won't go into explicit detail about
how object oriented programming works in this class, though we will
exploit many of the features of objects that have a particular class.

\hypertarget{length-and-dimension-for-data-frames}{%
\subsection{Length and dimension for data
frames}\label{length-and-dimension-for-data-frames}}

Applying the \texttt{length()} function to a data frame returns the
number of columns. This is consistent with the fact that data frames are
specialized lists:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(df)}
\CommentTok{#> [1] 3}
\end{Highlighting}
\end{Shaded}

To get the dimensions (number of rows and columns) of a data frame, we
use the \texttt{dim()} function. \texttt{dim()} returns a vector, whose
first value is the number of rows and whose second value is the number
of columns:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(df)}
\CommentTok{#> [1] 10  3}
\end{Highlighting}
\end{Shaded}

We can get the number of rows and columns individually using the
\texttt{nrow()} and \texttt{ncol()} functions:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(df)  }\CommentTok{# number of rows}
\CommentTok{#> [1] 10}
\KeywordTok{ncol}\NormalTok{(df)  }\CommentTok{# number of columsn}
\CommentTok{#> [1] 3}
\end{Highlighting}
\end{Shaded}

\hypertarget{indexing-and-accessing-data-frames}{%
\subsection{Indexing and accessing data
frames}\label{indexing-and-accessing-data-frames}}

Data frames can be indexed by either column index, column name, row
number, or a combination of row and column numbers.

\hypertarget{single-bracket-indexing-of-the-columns-of-a-data-frame}{%
\subsubsection{Single bracket indexing of the columns of a data
frame}\label{single-bracket-indexing-of-the-columns-of-a-data-frame}}

The \emph{single bracket operator with a single numeric index} returns a
data frame with the corresponding column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\DecValTok{1}\NormalTok{]  }\CommentTok{# get the first column (=age) of the data frame}
\CommentTok{#>    age}
\CommentTok{#> 1   30}
\CommentTok{#> 2   26}
\CommentTok{#> 3   21}
\CommentTok{#> 4   29}
\CommentTok{#> 5   25}
\CommentTok{#> 6   22}
\CommentTok{#> 7   28}
\CommentTok{#> 8   24}
\CommentTok{#> 9   23}
\CommentTok{#> 10  20}
\end{Highlighting}
\end{Shaded}

The \emph{single bracket operator with multiple numeric indices} returns
a data frame with the corresponding columns.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{]  }\CommentTok{# first two columns}
\CommentTok{#>    age sex}
\CommentTok{#> 1   30   M}
\CommentTok{#> 2   26   F}
\CommentTok{#> 3   21   M}
\CommentTok{#> 4   29   F}
\CommentTok{#> 5   25   M}
\CommentTok{#> 6   22   F}
\CommentTok{#> 7   28   M}
\CommentTok{#> 8   24   F}
\CommentTok{#> 9   23   M}
\CommentTok{#> 10  20   F}
\NormalTok{df[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)]  }\CommentTok{# columns 1 (=age) and 3 (=wt)}
\CommentTok{#>    age wt}
\CommentTok{#> 1   30 88}
\CommentTok{#> 2   26 76}
\CommentTok{#> 3   21 67}
\CommentTok{#> 4   29 66}
\CommentTok{#> 5   25 56}
\CommentTok{#> 6   22 74}
\CommentTok{#> 7   28 71}
\CommentTok{#> 8   24 60}
\CommentTok{#> 9   23 52}
\CommentTok{#> 10  20 72}
\end{Highlighting}
\end{Shaded}

Column names can be substituted for indices when using the single
bracket operator:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\StringTok{"age"}\NormalTok{]  }
\CommentTok{#>    age}
\CommentTok{#> 1   30}
\CommentTok{#> 2   26}
\CommentTok{#> 3   21}
\CommentTok{#> 4   29}
\CommentTok{#> 5   25}
\CommentTok{#> 6   22}
\CommentTok{#> 7   28}
\CommentTok{#> 8   24}
\CommentTok{#> 9   23}
\CommentTok{#> 10  20}

\NormalTok{df[}\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"wt"}\NormalTok{)]}
\CommentTok{#>    age wt}
\CommentTok{#> 1   30 88}
\CommentTok{#> 2   26 76}
\CommentTok{#> 3   21 67}
\CommentTok{#> 4   29 66}
\CommentTok{#> 5   25 56}
\CommentTok{#> 6   22 74}
\CommentTok{#> 7   28 71}
\CommentTok{#> 8   24 60}
\CommentTok{#> 9   23 52}
\CommentTok{#> 10  20 72}
\end{Highlighting}
\end{Shaded}

\hypertarget{single-bracket-indexing-of-the-rows-of-a-data-frame}{%
\subsubsection{Single bracket indexing of the rows of a data
frame}\label{single-bracket-indexing-of-the-rows-of-a-data-frame}}

To get specific rows of a data frame, we use single bracket indexing
with an additional comma following the index. For example to get the
first row a data frame we would do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\DecValTok{1}\NormalTok{,]    }\CommentTok{# first row}
\CommentTok{#>   age sex wt}
\CommentTok{#> 1  30   M 88}
\end{Highlighting}
\end{Shaded}

This syntax extends to multiple rows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{,]  }\CommentTok{# first two rows}
\CommentTok{#>   age sex wt}
\CommentTok{#> 1  30   M 88}
\CommentTok{#> 2  26   F 76}

\NormalTok{df[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{),]  }\CommentTok{# rows 1, 3 and 5}
\CommentTok{#>   age sex wt}
\CommentTok{#> 1  30   M 88}
\CommentTok{#> 3  21   M 67}
\CommentTok{#> 5  25   M 56}
\end{Highlighting}
\end{Shaded}

\hypertarget{single-bracket-indexing-of-both-the-rows-and-columns-of-a-data-frame}{%
\subsubsection{Single bracket indexing of both the rows and columns of a
data
frame}\label{single-bracket-indexing-of-both-the-rows-and-columns-of-a-data-frame}}

Single bracket indexing of data frames extends naturally to retrieve
both rows and columns simultaneously:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{]  }\CommentTok{# first row, second column}
\CommentTok{#> [1] M}
\CommentTok{#> Levels: F M}
\NormalTok{df[}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{] }\CommentTok{# first three rows, columns 2 and 3}
\CommentTok{#>   sex wt}
\CommentTok{#> 1   M 88}
\CommentTok{#> 2   F 76}
\CommentTok{#> 3   M 67}

\CommentTok{# you can even mix numerical indexing (rows) with named indexing of columns}
\NormalTok{df[}\DecValTok{5}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"wt"}\NormalTok{)]  }
\CommentTok{#>    age wt}
\CommentTok{#> 5   25 56}
\CommentTok{#> 6   22 74}
\CommentTok{#> 7   28 71}
\CommentTok{#> 8   24 60}
\CommentTok{#> 9   23 52}
\CommentTok{#> 10  20 72}
\end{Highlighting}
\end{Shaded}

\hypertarget{double-bracket-and-indexing-of-data-frames}{%
\subsubsection{\texorpdfstring{Double bracket and \texttt{\$} indexing
of data
frames}{Double bracket and \$ indexing of data frames}}\label{double-bracket-and-indexing-of-data-frames}}

Whereas single bracket indexing of a data frame always returns a new
data frame, double bracket indexing and indexing using the \texttt{\$}
operator, returns vectors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[[}\StringTok{"age"}\NormalTok{]]}
\CommentTok{#>  [1] 30 26 21 29 25 22 28 24 23 20}
\KeywordTok{typeof}\NormalTok{(df[[}\StringTok{"age"}\NormalTok{]])}
\CommentTok{#> [1] "double"}

\NormalTok{df}\OperatorTok{$}\NormalTok{wt}
\CommentTok{#>  [1] 88 76 67 66 56 74 71 60 52 72}
\KeywordTok{typeof}\NormalTok{(df}\OperatorTok{$}\NormalTok{wt)}
\CommentTok{#> [1] "double"}
\end{Highlighting}
\end{Shaded}

\hypertarget{logical-indexing-of-data-frames}{%
\subsection{Logical indexing of data
frames}\label{logical-indexing-of-data-frames}}

Logical indexing using boolean values works on data frames in much the
same way it works on vectors. Typically, logical indexing of a data
frame is used to filter the rows of a data frame.

For example, to get all the subject in our example data frame who are
older than 25 we could do:

\begin{Shaded}
\begin{Highlighting}[]
 \CommentTok{# }\AlertTok{NOTE}\CommentTok{: the comma after 25 is important to insure we're indexing rows!}
\NormalTok{df[df}\OperatorTok{$}\NormalTok{age }\OperatorTok{>}\StringTok{ }\DecValTok{25}\NormalTok{, ] }
\CommentTok{#>   age sex wt}
\CommentTok{#> 1  30   M 88}
\CommentTok{#> 2  26   F 76}
\CommentTok{#> 4  29   F 66}
\CommentTok{#> 7  28   M 71}
\end{Highlighting}
\end{Shaded}

Similarly, to get all the individuals whose weight is between 60 and 70
kgs we could do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[(df}\OperatorTok{$}\NormalTok{wt }\OperatorTok{>=}\StringTok{ }\DecValTok{60} \OperatorTok{&}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{wt }\OperatorTok{<=}\StringTok{ }\DecValTok{70}\NormalTok{),]}
\CommentTok{#>   age sex wt}
\CommentTok{#> 3  21   M 67}
\CommentTok{#> 4  29   F 66}
\CommentTok{#> 8  24   F 60}
\end{Highlighting}
\end{Shaded}

\hypertarget{adding-columns-to-a-data-frame}{%
\subsection{Adding columns to a data
frame}\label{adding-columns-to-a-data-frame}}

Adding columns to a data frame is similar to adding items to a list. The
easiest way to do so is using named indexing. For example, to add a new
column to our data frame that gives the individuals ages in number of
days, we could do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[[}\StringTok{"age.in.days"}\NormalTok{]] <-}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{age }\OperatorTok{*}\StringTok{ }\DecValTok{365}
\KeywordTok{dim}\NormalTok{(df)}
\CommentTok{#> [1] 10  4}
\end{Highlighting}
\end{Shaded}

\hypertarget{introduction-to-ggplot2}{%
\chapter{Introduction to ggplot2}\label{introduction-to-ggplot2}}

Pretty much any statistical plot can be thought of as a \textbf{mapping}
between data and one or more visual representations. For example, in a
scatter plot we map two ordered sets of numbers (the variables of
interest) to points in the Cartesian plane (x,y-coordinates). The
representation of data as points in a plane can be thought of as a type
of \textbf{geometric mapping}. In a histogram, we divide the range of a
variable of interest into bins, count the number of observations in each
bin, and represent those counts as bars. The process of counting the
data in bins is a type of \textbf{statistical transformation} (summing
in this case), while the representation of the counts as bars is another
example of a geometric mapping. Both types of plots can be further
embellished with additional information, such as coloring the points or
bars based on a categorical variable of interest, changing the shape of
points, etc. These are examples of \textbf{aesthetic mappings}. An
additional operation that is frequently useful is \textbf{faceting}
(also called conditioning), in which a series of subplots are created to
show particular subsets of the data.

The package \texttt{ggplot2} is based on a formalized approach for
building statistical graphics as a combination of geometric mappings,
aesthetic mappings, statistical transformations, and faceting
(conditioning). In ggplot2, complex figures are built up by combining
layers -- where each layer includes a geometric mapping, an aesthetic
mapping, and a statistical transformation -- along with any desired
faceting information.

Many of the key ideas behind ggplot2 (and its predecessor,``ggplot'')
are based on a book called ``The Grammar of Graphics'' (Leland
Wilkinson, 1985). The ``grammar of graphics'' is the ``gg'' in the
ggplot2 name.

\hypertarget{loading-ggplot2}{%
\section{Loading ggplot2}\label{loading-ggplot2}}

\texttt{ggplot2} is one of the packages included in the
\texttt{tidyverse} meta-package we installed during the previous class
session (see the previous lecture notes for instruction if you have not
installed \texttt{tidyverse}). If we load the tidyverse package, ggplot2
is automatically loaded as well.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

However if we wanted to we could load only ggplot2 as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)  }\CommentTok{# not necessary if we already loaded tidyverse}
\end{Highlighting}
\end{Shaded}

\hypertarget{example-data-set-andersons-iris-data}{%
\section{Example data set: Anderson's Iris
Data}\label{example-data-set-andersons-iris-data}}

To illustrate ggplot2 we'll use a dataset called \texttt{iris}. This
data set was made famous by the statistician and geneticist R. A. Fisher
who used it to illustrate many of the fundamental statistical methods he
developed (Recall that Fisher was one of the key contributors to the
modern synthesis in biology, reconciling evolution and genetics in the
early 20th century). The data set consists of four morphometric
measurements for specimens from three different iris species (\emph{Iris
setosa}, \emph{I. versicolor}, and \emph{I. virginica}). Use the R help
to read about the iris data set (\texttt{?iris}). We'll be using this
data set repeatedly in future weeks so familiarize yourself with it.

The iris data is included in a standard R package (\texttt{datasets})
that is made available automatically when you start up R. As a
consequence we don't need to explicitly load the iris data from a file.
Let's take a few minutes to explore this iris data set before we start
generating plots:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(iris) }\CommentTok{# get the variable names in the dataset}
\CommentTok{#> [1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width" }
\CommentTok{#> [5] "Species"}
\KeywordTok{dim}\NormalTok{(iris)   }\CommentTok{# dimensions given as rows, columns}
\CommentTok{#> [1] 150   5}
\KeywordTok{head}\NormalTok{(iris)  }\CommentTok{# can you figure out what the head function does?}
\CommentTok{#>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species}
\CommentTok{#> 1          5.1         3.5          1.4         0.2  setosa}
\CommentTok{#> 2          4.9         3.0          1.4         0.2  setosa}
\CommentTok{#> 3          4.7         3.2          1.3         0.2  setosa}
\CommentTok{#> 4          4.6         3.1          1.5         0.2  setosa}
\CommentTok{#> 5          5.0         3.6          1.4         0.2  setosa}
\CommentTok{#> 6          5.4         3.9          1.7         0.4  setosa}
\KeywordTok{tail}\NormalTok{(iris)  }\CommentTok{# what about the tail function?}
\CommentTok{#>     Sepal.Length Sepal.Width Petal.Length Petal.Width   Species}
\CommentTok{#> 145          6.7         3.3          5.7         2.5 virginica}
\CommentTok{#> 146          6.7         3.0          5.2         2.3 virginica}
\CommentTok{#> 147          6.3         2.5          5.0         1.9 virginica}
\CommentTok{#> 148          6.5         3.0          5.2         2.0 virginica}
\CommentTok{#> 149          6.2         3.4          5.4         2.3 virginica}
\CommentTok{#> 150          5.9         3.0          5.1         1.8 virginica}
\end{Highlighting}
\end{Shaded}

\hypertarget{template-for-single-layer-plots-in-ggplot2}{%
\section{Template for single layer plots in
ggplot2}\label{template-for-single-layer-plots-in-ggplot2}}

A basic template for building a single layer plot using \texttt{ggplot2}
is shown below. When creating a plot, you need to replace the text in
brackets (e.g. \texttt{\textless{}DATA\textgreater{}}) with appropriate
objects, functions, or arguments:

\begin{verbatim}
# NOTE: this is pseudo-code. It will not run!

ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))
\end{verbatim}

The base function \texttt{ggplot()} is responsible for creating the
coordinate system in which the plot will be display. To this coordinate
system we add a geometric mapping (called a ``geom'' for short) that
specifies how data gets mapped into the coordinate system (e.g.~points,
bars, etc). Included as an input to the geom function is the aesthetic
mapping function that specifies which variables to use in the geometric
mapping (e.g.~which variables to treat as the x- and y-coordinates),
colors, etc.

For example, using this template we can create a scatter plot that show
the relationship between the variables \texttt{Sepal.Width} and
\texttt{Petal.Width}. To do so we subsitute \texttt{iris} for
\texttt{\textless{}DATA\textgreater{}}, \texttt{geom\_point} for
\texttt{\textless{}GEOM\_FUNCTION\textgreater{}}, and
\texttt{x\ =\ Sepal.Width} and \texttt{y\ =\ Petal.Width} for
\texttt{\textless{}MAPPINGS\textgreater{}}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width,  }\DataTypeTok{y =}\NormalTok{ Petal.Width))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-147-1.pdf}

If we were to translate this code block to English, we might write it as
``Using the iris data frame as the source of data, create a point plot
using each observeration's Sepal.Width variable for the x-coordinate and
the Petal.Width variable for the y-coordinate.''

\hypertarget{an-aside-about-function-arguments}{%
\section{An aside about function
arguments}\label{an-aside-about-function-arguments}}

The inputs to a function are also known as ``arguments''. In R, when you
call a function you can specify the arguments by keyword (i.e.~using
names specified in the function definition) or by position (i.e.~the
order of the inputs).

In our bar plot above, we're using using keyword arguments. For example,
in the line \texttt{ggplot(data\ =\ iris)}, iris is treated as the
``data'' argument. Similarly, in the second line,
\texttt{aes(x\ =\ Sepal.Width,\ y\ =\ Petal.Width)} is the ``mapping''
argument to \texttt{geom\_bar}. Note that \texttt{aes} is itself a
function (see \texttt{?aes}) that takes arguments that can be specified
positionally or with keywords.

If we wanted to, we could instead use position arguments when calling a
function, by passing inputs to the function corresponding to the order
they are specified in the function definition. For example, take a
minute to read the documentation for the \texttt{ggplot} function
(\texttt{?ggplot}). Near the top of the help page you'll see a
description of how the function is called under ``Usage''. Reading the
Usage section you'll see that the the ``data'' argument is the first
positional argument to \texttt{ggplot}. Similarly, if you read the docs
for the \texttt{geom\_point} function you'll see that mapping is the
first positional argument for that function.

The equivalent of our previous example, but now using positional
arguments is:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{   }\CommentTok{# note we dropped the "data = " part}
\StringTok{  }\CommentTok{# note we dropped the "mapping = " part from the geom_point call}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width,  }\DataTypeTok{y =}\NormalTok{ Petal.Width))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-148-1.pdf}

The upside of using positional arguments is that it means less typing,
which is useful when working interactively at the console (or in an R
Notebok). The downside to using positional arguments is you need to
remember or lookup the order of the arguments. Using positional
arguments can also make your code less ``self documenting'' in the sense
that it is less explicit about how the inputs are being treated. While
the argument ``x'' is the first argument to the \texttt{aes} function, I
chose to explicitly include the argument name to make it clear what
variable I'm plotting on the x-axis.

We will cover function arguments in greater detail a class session or
two from now, when we learn how to write our own functions.

\hypertarget{strip-plots}{%
\section{Strip plots}\label{strip-plots}}

One of the simplest visualizations of a continuous variable is to draw
points along a number line, where each point represent the value of one
of the observations. This is sometimes called a ``strip plot''.

First, we'll use the \texttt{geom\_point} function as shown below to
generate a strip plot for the \texttt{Sepal.Width} variable in the iris
data set.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{y =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-149-1.pdf}

\hypertarget{jittering-data}{%
\subsection{Jittering data}\label{jittering-data}}

There should have been 150 points plotted in the figure above (one for
each of the iris plants in the data set), but visually it looks like
only about 25 or 30 points are shown. What's going on? If you examine
the iris data, you'll see that the all the measures are rounded to the
nearest tenth of a centimer, so that there are a large number of
observations with identical values of \texttt{Sepal.Width}. This is a
limitation of the precision of measurements that was used when
generating the data set.

To provide a visual clue that there are multiple observations that share
the same value, we can slightly ``jitter'' the values (randomly move
points a small amount in either in the vertical or horizontal
direction). Jittering is used solely to enhance visualization, and any
statistical analyses you carry out would be based on the original data.
When presenting your data to someone else, should note when you've used
jittering so as not to misconvey the actual data.

Jittering can be accomplished using \texttt{geom\_jitter}, which is
derived from \texttt{geom\_point}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{y =} \DecValTok{0}\NormalTok{), }
              \DataTypeTok{width =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{height =} \DecValTok{0}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-150-1.pdf}

The \texttt{width} and \texttt{height} arguments specify the maximum
amount (as fractions of the data) to jitter the observed data points in
the horizontal (width) and vertical (height) directions. Here we only
jitter the data in the horizontal direction. The \texttt{alpha} argument
controls the transparency of the points -- the valid range of alpha
values is 0 to 1, where 0 means completely transparent and 1 is
completely opaque.

Within a geom, arguments outside of the \texttt{aes} mapping apply
uniformly across the visualization (i.e.~they are fixed values). For
example, setting `alpha = 0.25' made all the points transparent.

\hypertarget{adding-categorical-information}{%
\subsection{Adding categorical
information}\label{adding-categorical-information}}

Recall that are three different species represented in the data: Iris
setosa, I. versicolor, and I. virginica. Let's see how to generate a
strip plot that also includes a breakdown by species.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{y =}\NormalTok{ Species),}
              \DataTypeTok{width=}\FloatTok{0.05}\NormalTok{, }\DataTypeTok{height=}\FloatTok{0.1}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-151-1.pdf}

That was easy! All we had to do was change the aesthetic mapping in
\texttt{geom\_jitter}, specifying ``Species'' as the y variable. I also
added a little vertical jitter as well to better separate the points.

Now we have a much better sense of the data. In particular it's clear
that the \emph{I. setosa} specimens generally have wider sepals than
samples from the other two species.

Let's tweak this a little by also adding color information, to further
emphasize the distinct groupings. We can do this by adding another
argument to the aesthetic mapping in \texttt{geom\_jitter}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{y =}\NormalTok{ Species, }\DataTypeTok{color=}\NormalTok{Species),}
              \DataTypeTok{width=}\FloatTok{0.05}\NormalTok{, }\DataTypeTok{height=}\FloatTok{0.1}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-152-1.pdf}

\hypertarget{rotating-plot-coordinates}{%
\subsection{Rotating plot coordinates}\label{rotating-plot-coordinates}}

What if we wanted to rotate this plot 90 degrees, depicting species on
the x-axis and sepal width on the y-axis. For this example, it would be
easy to do this by simpling swapping the variables in the \texttt{aes}
mapping argument. However an alternate way to do this is with a
coordinate transformation function. Here we use \texttt{coord\_flip} to
flip the x- and y-axes:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{y =}\NormalTok{ Species, }\DataTypeTok{color=}\NormalTok{Species),}
              \DataTypeTok{width=}\FloatTok{0.05}\NormalTok{, }\DataTypeTok{height=}\FloatTok{0.1}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-153-1.pdf}

We'll see other uses of coordinate transformations in later lectures.

\hypertarget{histograms-1}{%
\section{Histograms}\label{histograms-1}}

Histograms are probably the most common way to depict univariate data.
In a histogram rather than showing individual observations, we divide
the range of the data into a set of bins, and use vertical bars to
depict the number (frequency) of observations that fall into each bin.
This gives a good sense of the intervals in which most of the
observations are found.

The geom, \texttt{geom\_histogram}, takes care of both the geometric
representation and the statistical transformations of the data necessary
to calculate the counts in each binn.

Here's the simplest way to use \texttt{geom\_histogram}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width))}
\CommentTok{#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-154-1.pdf}

The default number of bins that \texttt{geom\_histogram} uses is 30. For
modest size data sets this is often too many bins, so it's worth
exploring how the histogram changes with different bin numbers:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width), }\DataTypeTok{bins =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-155-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width), }\DataTypeTok{bins =} \DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-156-1.pdf}

One important thing to note when looking at these histograms with
different numbers of bins is that the number of bins used can change
your perception of the data. For example, the number of peaks (modes) in
the data can be very sensitive to the bin number as can the perception
of gaps.

\hypertarget{variations-on-histograms-when-considering-categorical-data}{%
\subsection{Variations on histograms when considering categorical
data}\label{variations-on-histograms-when-considering-categorical-data}}

As before, we probably want to break the data down by species. Here
we're faced with some choices about how we depict that data. Do we
generate a ``stacked histogram'' to where the colors indicate the number
of observations in each bin that belong to each species? Do we generate
side-by-side bars for each species? Or Do we generate separate
histograms for each species, and show them overlapping?

Stacked histograms are the default if we associate a categorical
variable with the bar fill color:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{fill =}\NormalTok{ Species), }
                 \DataTypeTok{bins =} \DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-157-1.pdf}

To get side-by-side bars, specify ``dodge'' as the \texttt{position}
argument to \texttt{geom\_histogram}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{fill =}\NormalTok{ Species),}
                 \DataTypeTok{bins =} \DecValTok{12}\NormalTok{, }\DataTypeTok{position =} \StringTok{"dodge"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-158-1.pdf}

If you want overlapping histograms, use \texttt{position\ =\ "identity"}
instead. When generating overlapping histograms like this, you probably
want to make the bars semi-transparent so you can can distinguish the
overlapping data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{fill =}\NormalTok{ Species), }
                 \DataTypeTok{bins =} \DecValTok{12}\NormalTok{, }\DataTypeTok{position =} \StringTok{"identity"}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-159-1.pdf}

\hypertarget{faceting-to-depict-categorical-information}{%
\section{Faceting to depict categorical
information}\label{faceting-to-depict-categorical-information}}

Yet another way to represent the histograms for the three species is to
using faceting, the create subplots for each species. Faceting is the
operation of subsetting the data with respect to a discrete or
categorical variable of interest, and generating the same plot type for
each subset. Here we use the ``ncol'' argument to the
\texttt{facet\_wrap} function to specify that the subplots should be
drawn in a single vertical column to facilitate comparison of the
distributions.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{fill =}\NormalTok{ Species), }\DataTypeTok{bins =} \DecValTok{12}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{Species, }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-160-1.pdf}

\hypertarget{density-plots}{%
\section{Density plots}\label{density-plots}}

One shortcoming of histograms is that they are sensitive to the choice
of bin margins and the number of bins. An alternative is a ``density
plot'', which you can think of as a smoothed version of a histogram.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_density}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width, }\DataTypeTok{fill =}\NormalTok{ Species), }\DataTypeTok{alpha=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-161-1.pdf}

Density plots still make some assumptions that affect the visualization,
in particular a ``smoothing bandwidth'' (specified by the argument
\texttt{bw}) which determines how course or granular the density
estimation is.

Note that the vertical scale on a density plot is no longer counts
(frequency) but probability density. In a density plot, the total area
under the plot adds up to one. Intervals in a density plot therefore
have a probabilistic intepretation.

\hypertarget{violin-or-beanplot}{%
\section{Violin or Beanplot}\label{violin-or-beanplot}}

A violin plot (sometimes called a bean plot) is closely related to a
density plot. In fact you can think of a violin plot as a density plot
rotated 90 degress and mirrored left/right.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_violin}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Species, }\DataTypeTok{y =}\NormalTok{ Sepal.Width, }\DataTypeTok{color =}\NormalTok{ Species, }\DataTypeTok{fill=}\NormalTok{Species), }
              \DataTypeTok{alpha =} \FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-162-1.pdf}

\hypertarget{boxplots}{%
\section{Boxplots}\label{boxplots}}

Boxplots are another frequently used univariate visualization. Boxplots
provide a compact summary of single variables, and are most often used
for comparing distributions between groups.

A standard box plot depicts five useful features of a set of
observations: 1) the median (center most line); 2 and 3) the first and
third quartiles (top and bottom of the box); 4) the whiskers of a
boxplot extend from the first/third quartile to the highest value that
is within 1.5 * IQR, where IQR is the inter-quartile range (distance
between the first and third quartiles); 5) points outside of the
whiskers are usually consider extremal points or outliers. There are
many variants on box plots, particularly with respect to the
``whiskers''. It's always a good idea to be explicit about what a box
plot you've created shows.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Species, }\DataTypeTok{y =}\NormalTok{ Sepal.Width, }\DataTypeTok{color =}\NormalTok{ Species))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-163-1.pdf}

Boxplots are most commonly drawn with the cateogorical variable on the
x-axis.

\hypertarget{building-complex-visualizations-with-layers}{%
\section{Building complex visualizations with
layers}\label{building-complex-visualizations-with-layers}}

All of our ggplot2 examples up to now have involved a single geom. We
can think of geoms as ``layers'' of information in a plot. One of the
powerful features of plotting useing ggplot2 is that it is trivial to
combine layers to make more complex plots.

The template for multi-layered plots is a simple extension of the single
layer:

\begin{verbatim}
ggplot(data = <DATA>) + 
  <GEOM_FUNCTION1>(mapping = aes(<MAPPINGS>)) + 
  <GEOM_FUNCTION2>(mapping = aes(<MAPPINGS>)) 
\end{verbatim}

\hypertarget{useful-combination-plots}{%
\section{Useful combination plots}\label{useful-combination-plots}}

Boxplot or violin plots represent visual summaries/simplifications of
the underlying data. This is useful but sometimes key information is
lost in the process of summarizing. Combining these plots with a strip
plot give you both the ``birds eye view'' as well as granular
information.

\hypertarget{boxplot-plus-strip-plot}{%
\subsection{Boxplot plus strip plot}\label{boxplot-plus-strip-plot}}

Here's an example of combining box plots and strip plots:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris) }\OperatorTok{+}
\StringTok{  }\CommentTok{# outlier.shape = NA suppresses the depiction of outlier points in the boxplot}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Species, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{outlier.shape =} \OtherTok{NA}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\CommentTok{# size sets the point size for the jitter plot}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Species, }\DataTypeTok{y =}\NormalTok{ Sepal.Width), }\DataTypeTok{width=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{height=}\FloatTok{0.05}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.35}\NormalTok{, }\DataTypeTok{size=}\FloatTok{0.75}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-164-1.pdf}
Note that I suppressed the plotting of outliers in
\texttt{geom\_boxplot} so as not to draw the same points twice (the
individual data are drawn by \texttt{geom\_jitter}).

\hypertarget{setting-shared-aesthetics}{%
\subsection{Setting shared aesthetics}\label{setting-shared-aesthetics}}

The example above works well, but you might have noticed that there's
some repetition of code. In particular, we set the same aesthetic
mapping in both \texttt{geom\_boxplot} and \texttt{geom\_jitter}. It
turns out that creating layers that share some of the same aesthetic
values is a common case. To deal with such cases, you can specify
\emph{shared aesthetic mappings} as an argument to the \texttt{ggplot}
function and then set additional aesthetics specific to each layer in
the individual geoms. Using this approach, our previous example can be
written more compactly as follow.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(iris, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Species, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\DataTypeTok{outlier.shape =} \OtherTok{NA}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\CommentTok{# note how we specify a layer specific aesthetic in geom_jitter}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Species), }\DataTypeTok{width=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{height=}\FloatTok{0.05}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{, }\DataTypeTok{size=}\FloatTok{0.75}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-165-1.pdf}

\hypertarget{ggplot-layers-can-be-assigned-to-variables}{%
\section{ggplot layers can be assigned to
variables}\label{ggplot-layers-can-be-assigned-to-variables}}

The function \texttt{ggplot()} returns a ``plot object'' that we can
assign to a variable. The following example illustrates this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create base plot object and assign to variable p}
\CommentTok{# this does NOT draw the plot}
\NormalTok{p <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(iris, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Species, }\DataTypeTok{y =}\NormalTok{ Sepal.Width))   }
\end{Highlighting}
\end{Shaded}

In the code above we created a plot object and assigned it to the
variable \texttt{p}. However, the plot wasn't drawn. To draw the plot
object we evaluate it as so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p  }\CommentTok{# try to draw the plot object}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-167-1.pdf}

The code block above didn't generate an image, because we haven't added
a geom to the plot to determine how our data should be drawn. We can add
a geom to our pre-created plot object as so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# add a point geom to our base layer and draw the plot}
\NormalTok{p }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_boxplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-168-1.pdf}

If we wanted to we could have assigned the geom to a variable as well:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{box.layer <-}\StringTok{ }\KeywordTok{geom_boxplot}\NormalTok{()}
\NormalTok{p }\OperatorTok{+}\StringTok{ }\NormalTok{box.layer}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-169-1.pdf}

In this case we don't really gain anything by creating an intermediate
variable, but for more complex plots or when considering different
versions of a plot this can be very useful.

\hypertarget{violin-plot-plus-strip-plot}{%
\subsection{Violin plot plus strip
plot}\label{violin-plot-plus-strip-plot}}

Here is the principle of combining layers, applied to a combined violin
plot + strip plot. Again, we set shared aesthetic mappings in
\texttt{ggplot} function call and this time we assign individual layers
of the plot to variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(iris, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Species, }\DataTypeTok{y =}\NormalTok{ Sepal.Width, }\DataTypeTok{color =}\NormalTok{ Species))}

\NormalTok{violin.layer <-}\StringTok{ }\KeywordTok{geom_violin}\NormalTok{()}
\NormalTok{jitter.layer <-}\StringTok{ }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{width=}\FloatTok{0.15}\NormalTok{, }\DataTypeTok{height=}\FloatTok{0.05}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{, }\DataTypeTok{size=}\FloatTok{0.75}\NormalTok{)}

\NormalTok{p }\OperatorTok{+}\StringTok{ }\NormalTok{violin.layer }\OperatorTok{+}\StringTok{ }\NormalTok{jitter.layer }\CommentTok{# combined layers of plot and draw}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-170-1.pdf}

\hypertarget{adding-titles-and-tweaking-axis-labels}{%
\section{Adding titles and tweaking axis
labels}\label{adding-titles-and-tweaking-axis-labels}}

ggplot2 automatically adds axis labels based on the variable names in
the data frame passed to \texttt{ggplot}. Sometimes these are
appropriate, but more presentable figures you'll usually want to tweak
the axis labs (e.g.~adding units). The \texttt{labs} (short for labels)
function allows you to do so, and also let's you set a title for your
plot. We'll illustrate this by modifying our previous figure. Note that
we save considerable amounts of re-typing since we had already assigned
three of the plot layers to variables in the previous code block:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OperatorTok{+}\StringTok{ }\NormalTok{violin.layer }\OperatorTok{+}\StringTok{ }\NormalTok{jitter.layer }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Species"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Sepal Width (cm)"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Sepal Width Distributions for Three Iris Species"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-171-1.pdf}

\hypertarget{ggplot2-themes}{%
\section{ggplot2 themes}\label{ggplot2-themes}}

By now you're probably familiar with the default ``look'' of plots
generated by ggplot2, in particular the ubiquitous gray background with
a white grid. This default works fairly well in the context of RStudio
notebooks and HTML output, but might not work as well for a published
figure or a slide presentation. Almost every individual aspect of a plot
can be tweaked, but ggplot2 provides an easier way to make consistent
changes to a plot using ``themes''. You can think of a theme as adding
another layer to your plot. Themes should generally be applied after all
the other graphical layers are created (geoms, facets, labels) so the
changes they create affect all the prior layers.

There are eight default themes included with ggplot2, which can be
invoked by calling the corresponding theme functions:
\texttt{theme\_gray}, \texttt{theme\_bw}, \texttt{theme\_linedraw},
\texttt{theme\_light}, \texttt{theme\_dark}, \texttt{theme\_minimal},
\texttt{theme\_classic}, and \texttt{theme\_void} (See
\url{http://ggplot2.tidyverse.org/reference/ggtheme.html} for a visual
tour of all the default themes)

For example, let's generate a boxplot using \texttt{theme\_bw} which
get's rid of the gray background:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create another variable to hold combination of three previous }
\CommentTok{# ggplot layers. I'm doing this because I'm going to keep re-using}
\CommentTok{# the same plot in the following code blocks}
\NormalTok{violin.plus.jitter <-}\StringTok{ }\NormalTok{p }\OperatorTok{+}\StringTok{ }\NormalTok{violin.layer }\OperatorTok{+}\StringTok{ }\NormalTok{jitter.layer}

\NormalTok{violin.plus.jitter }\OperatorTok{+}\StringTok{ }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-172-1.pdf}

Another theme, \texttt{theme\_classic}, remove the grid lines
completely, and also gets rid of the top-most and right-most axis lines.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{violin.plus.jitter }\OperatorTok{+}\StringTok{ }\KeywordTok{theme_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-173-1.pdf}

\hypertarget{further-customization-with-ggplot2theme}{%
\subsection{\texorpdfstring{Further customization with
\texttt{ggplot2::theme}}{Further customization with ggplot2::theme}}\label{further-customization-with-ggplot2theme}}

In addition to the eight complete themes, there is a \texttt{theme}
function in ggplot2 that allows you to tweak particular elements of a
theme (see \texttt{?theme} for all the possible options). For example,
to tweak just the aspect ratio of a plot (the ratio of width to height),
you can set the \texttt{aspect.ratio} argument in \texttt{theme}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{violin.plus.jitter }\OperatorTok{+}\StringTok{ }\KeywordTok{theme_classic}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{aspect.ratio =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-174-1.pdf}

Theme related function calls can be combined to generate new themes. For
example, let's create a theme called \texttt{my.theme} by combining
\texttt{theme\_classic} with a call to \texttt{theme}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my.theme <-}\StringTok{ }\KeywordTok{theme_classic}\NormalTok{()  }\OperatorTok{+}\StringTok{ }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{aspect.ratio =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can then apply this theme as so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{violin.plus.jitter }\OperatorTok{+}\StringTok{ }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-176-1.pdf}

\hypertarget{other-aspects-of-ggplots-can-be-assigned-to-variables}{%
\section{Other aspects of ggplots can be assigned to
variables}\label{other-aspects-of-ggplots-can-be-assigned-to-variables}}

Plot objects, geoms and themes are not the only aspects of a figure that
can be assigned to variables for later use. For example, we can create a
label object:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my.labels <-}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Species"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Sepal Width (cm)"}\NormalTok{, }
                  \DataTypeTok{title =} \StringTok{"Sepal Width Distributions for Three Iris Species"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Combining all of our variables as so, we generate our new plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{violin.plus.jitter }\OperatorTok{+}\StringTok{ }\NormalTok{my.labels }\OperatorTok{+}\StringTok{ }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-178-1.pdf}

\hypertarget{bivariate-plots}{%
\section{Bivariate plots}\label{bivariate-plots}}

Now we turn our attention to some useful representations of bivariate
distributions.

For the purposes of these illustrations I'm initially going to restrict
my attention to just one of the three species represented in the iris
data set -- the I. setosa specimens. This allows us to introduce a vary
useful base function called \texttt{subset()}. \texttt{subset()} will
return subsets of a vector or data frames that meets the specified
conditions. This can also be accomplished with conditional indexing but
\texttt{subset()} is usually less verbose.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create a new data frame composed only of the I. setosa samples}
\NormalTok{setosa.only <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(iris, Species }\OperatorTok{==}\StringTok{ "setosa"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In the examples that follow, I'm going to illustrate different ways of
representing the same bivariate distribution -- the joint distribution
of Sepal Length and Sepal Width -- over and over again. To avoid
repitition, let's assign the base ggplot layer to a variable as we did
in our previous examples. We'll also pre-create a label layer.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(setosa.only, }
                        \DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width))}

\NormalTok{sepal.labels <-}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Sepal Length (cm)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Sepal Width (cm)"}\NormalTok{,}
                     \DataTypeTok{title =} \StringTok{"Relationship between Sepal Length and Width"}\NormalTok{,}
                     \DataTypeTok{caption =} \StringTok{"data from Anderson (1935)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{scatter-plots-1}{%
\subsection{Scatter plots}\label{scatter-plots-1}}

A scatter plot is one of the simplest representations of a bivariate
distribution. Scatter plots are simple to create in ggplot2 by
specifying the appropriate X and Y variables in the aesthetic mapping
and using \texttt{geom\_point} for the geometric mapping.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals  }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{sepal.labels}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-181-1.pdf}

\hypertarget{adding-a-trend-line-to-a-scatter-plot}{%
\subsection{Adding a trend line to a scatter
plot}\label{adding-a-trend-line-to-a-scatter-plot}}

ggplot2 makes it easy to add trend lines to plots. I use ``trend lines''
here to refer to representations like regression lines, smoothing
splines, or other representations mean to help visualize the
relationship between pairs of variables. We'll spend a fair amount of
time exploring the mathematics and interpetation of regression lines and
related techniques in later lectures, but for now just think about
trends lines as summary representations for bivariate relationships.

Trend lines can be created using \texttt{geom\_smooth}. Let's add a
default trend line to our \emph{I. setosa} scatter plot of the Sepal
Width vs Sepal Length:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{() }\OperatorTok{+}\StringTok{  }\CommentTok{# using geom_jitter to avoid overplotting of points}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"I. setosa data only"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\CommentTok{#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-182-1.pdf}

The defaul trend line that \texttt{geom\_smooth} fits is generated by a
technique called ``LOESS regression''. LOESS regression is a non-linear
curve fitting method, hence the squiggly trend line we see above. The
smoothness of the LOESS regression is controlled by a parameter called
\texttt{span} which is related to the proportion of points used. We'll
discuss LOESS in detail in a later lecture, but here's an illustration
how changing the span affects the smoothness of the fit curve:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{() }\OperatorTok{+}\StringTok{  }\CommentTok{# using geom_jitter to avoid overplotting of points}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{span =} \FloatTok{0.95}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"I. setosa data only"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\CommentTok{#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-183-1.pdf}

\hypertarget{linear-trend-lines}{%
\subsubsection{Linear trend lines}\label{linear-trend-lines}}

If instead we want a straight trend line, as would typically be depicted
for a linear regression model we can specify a different statistical
method:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{() }\OperatorTok{+}\StringTok{  }\CommentTok{# using geom_jitter to avoid overplotting of points}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\CommentTok{# using linear model ("lm")}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"I. setosa data only"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-184-1.pdf}

\hypertarget{bivariate-density-plots}{%
\section{Bivariate density plots}\label{bivariate-density-plots}}

The density plot, which we introduced as a visualization for univariate
data, can be extended to two-dimensional data. In a one dimensional
density plot, the height of the curve was related to the relatively
density of points in the surrounding region. In a 2D density plot,
nested contours (or contours plus colors) indicate regions of higher
local density. Let's illustrate this with an example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_density2d}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"I. setosa data only"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-185-1.pdf}

The relationship between the 2D density plot and a scatter plot can be
made clearer if we combine the two:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_density_2d}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{alpha=}\FloatTok{0.35}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"I. setosa data only"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-186-1.pdf}

\hypertarget{combining-scatter-plots-and-density-plots-with-categorical-information}{%
\section{Combining Scatter Plots and Density Plots with Categorical
Information}\label{combining-scatter-plots-and-density-plots-with-categorical-information}}

As with many of the univariate visualizations we explored, it is often
useful to depict bivariate relationships as we change a categorical
variable. To illustrate this, we'll go back to using the full iris data
set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.sepals <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width))}

\NormalTok{all.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Species, }\DataTypeTok{shape =}\NormalTok{ Species), }\DataTypeTok{size =} \DecValTok{2}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.6}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"All species"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-187-1.pdf}

Notice how in our aesthetic mapping we specified that both color and
shape should be used to represent the species categories.

The same thing can be accomplished with a 2D density plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_density_2d}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Species)) }\OperatorTok{+}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"All species"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-188-1.pdf}

As you can see, in the density plots above, when you have multiple
categorical variables and there is significant overlap in the range of
each sub-distribution, figures can become quite busy. As we've seen
previously, faceting (conditioning) can be a good way to deal with this.
Below a combination of scatter plots and 2D density plots, combined with
faceting on the species variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_density_2d}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Species), }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Species), }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{, }\DataTypeTok{size=}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{Species) }\OperatorTok{+}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"All species"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{aspect.ratio =} \DecValTok{1}\NormalTok{, }\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)  }\CommentTok{# get rid of legend}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-189-1.pdf}

In this example I went back to using a theme that includes grid lines to
facilitate more accurate comparisons of the distributions across the
facets. I also got rid of the legend, because the information there was
redundant.

\hypertarget{density-plots-with-fill}{%
\section{Density plots with fill}\label{density-plots-with-fill}}

Let's revisit our earlier single species 2D density plot. Instead of
simply drawing contour lines, let's use color information to help guide
the eye to areas of higher density. To draw filled contours, we use a
sister function to \texttt{geom\_density\_2d} called
\texttt{stat\_density\_2d}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_density_2d}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ ..level..), }\DataTypeTok{geom =} \StringTok{"polygon"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"I. setosa data only"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-190-1.pdf}

Using the default color scale, areas of low density are drawn in dark
blue, whereas areas of high density are drawn in light blue. I
personally find this dark -to-light color scale non-intuitive for
density data, and would prefer that darker regions indicate area of
higher density. If we want to change the color scale, we can use the a
scale function (in this case \texttt{scale\_fill\_continuous}) to set
the color values used for the low and high values (this function we'll
interpolate the intervening values for us).

NOTE: when specifying color names, R accepts standard HTML color names
(see the \href{https://en.wikipedia.org/wiki/Web_colors}{Wikipedia page
on web colors} for a list). We'll also see other ways to set color
values in a later class session.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_density_2d}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ ..level..), }\DataTypeTok{geom =} \StringTok{"polygon"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\CommentTok{# lavenderblush is the HTML standard name for a light purplish-pink color}
\StringTok{  }\KeywordTok{scale_fill_continuous}\NormalTok{(}\DataTypeTok{low=}\StringTok{"lavenderblush"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"I. setosa data only"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-191-1.pdf}

The two contour plots we generated looked a little funny because the
contours are cutoff due to the contour regions being outside the limits
of the plot. To fix this, we can change the plot limits using the
\texttt{lims} function as shown in the following code block. We'll also
add the scatter (jittered) to the emphasize the relationship between the
levels, and we'll change the title for the color legend on the right by
specifying a text label associated with the fill arguments in the
\texttt{labs} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_density_2d}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ ..level..), }\DataTypeTok{geom =} \StringTok{"polygon"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_continuous}\NormalTok{(}\DataTypeTok{low=}\StringTok{"lavenderblush"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }
\StringTok{  }\CommentTok{# customize labels, including legend label for fill}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Sepal Length(cm)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Sepal Width (cm)"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Relationship between sepal length and width"}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"I. setosa specimens only"}\NormalTok{,}
       \DataTypeTok{fill =} \StringTok{"Density"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }
\StringTok{  }\CommentTok{# Set plot limits}
\StringTok{  }\KeywordTok{lims}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{), }\DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\FloatTok{2.5}\NormalTok{, }\FloatTok{4.5}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-192-1.pdf}

\hypertarget{d-bin-and-hex-plots}{%
\section{2D bin and hex plots}\label{d-bin-and-hex-plots}}

Two dimensional bin and hex plots are alterative ways to represent the
joint density of points in the Cartesian plane. Here are examples of to
generate these plot types. Compare them to our previous examples.

A 2D bin plot can be tought of as a 2D histogram:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bin2d}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{0.2}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_fill_continuous}\NormalTok{(}\DataTypeTok{low=}\StringTok{"lavenderblush"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"I. setosa data only"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-193-1.pdf}

A hex plot is similar to a 2D bin plot but uses hexagonal regions
instead of squares. Hexagonal bins are useful because they can somtimes
avoid visual artefacts sometimes apparent with square bins:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa.sepals }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hex}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{0.2}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_fill_continuous}\NormalTok{(}\DataTypeTok{low=}\StringTok{"lavenderblush"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{sepal.labels }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{subtitle =} \StringTok{"I. setosa data only"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\NormalTok{my.theme}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-194-1.pdf}

\hypertarget{the-cowplot-package}{%
\section{\texorpdfstring{The \texttt{cowplot}
package}{The cowplot package}}\label{the-cowplot-package}}

A common task when preparing visualizations for scientific presentations
and manuscripts is combining different plots as subfigures of a larger
figure. To accomplish this we'll use a package called
\href{https://cran.r-project.org/web/packages/cowplot/index.html}{\texttt{cowplot}}
that compliments the power of ggplot2. Install cowplot either via the
command line or the R Studio GUI (see Section \ref{packages}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(cowplot) }\CommentTok{# assumes package has been installed}
\end{Highlighting}
\end{Shaded}

\texttt{cowplot} allows us to create individual plots using ggplot, and
then arrange them in a grid-like fashion with labels for each plot of
interest, as you would typically see in publications. The core function
of \texttt{cowplot} is \texttt{plot\_grid()}, which allows the user to
layout the sub-plots in an organized fashion and add labels as necesary.

To illustrate \texttt{plot\_grid()} let's create three different
representations of the distribution of sepal width in the irisu data
set, and combine them into a single figure:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(iris, }
            \DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Species, }\DataTypeTok{y =}\NormalTok{ Sepal.Width, }\DataTypeTok{color =}\NormalTok{ Species))}

\CommentTok{# for the histogram we're going to override the mapping because}
\CommentTok{# geom_histogram only takes an x argument}
\NormalTok{plot}\FloatTok{.1}\NormalTok{ <-}\StringTok{ }\NormalTok{p }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{12}\NormalTok{,}
                 \DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Width), }\DataTypeTok{inherit.aes =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{plot}\FloatTok{.2}\NormalTok{ <-}\StringTok{ }\NormalTok{p }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_boxplot}\NormalTok{() }
\NormalTok{plot}\FloatTok{.3}\NormalTok{ <-}\StringTok{ }\NormalTok{p }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_violin}\NormalTok{()}

\KeywordTok{plot_grid}\NormalTok{(plot}\FloatTok{.1}\NormalTok{, plot}\FloatTok{.2}\NormalTok{, plot}\FloatTok{.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-196-1.pdf}

If instead, we wanted to layout the plots in a single row we could
change the call to \texttt{plot\_grid} as so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_grid}\NormalTok{(plot}\FloatTok{.1}\NormalTok{, plot}\FloatTok{.2}\NormalTok{, plot}\FloatTok{.3}\NormalTok{, }
          \DataTypeTok{nrow =} \DecValTok{1}\NormalTok{, }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-197-1.pdf}

Notice we also added labels to our sub-plots.

\hypertarget{introduction-to-the-dplyr-package}{%
\chapter{\texorpdfstring{Introduction to the \texttt{dplyr}
package}{Introduction to the dplyr package}}\label{introduction-to-the-dplyr-package}}

In today's class we introduce a new package, \texttt{dplyr}, which,
along with ggplot2 will be used in almost every class session. We will
also explore in a little more depth the \texttt{readr} package, for
reading tabular data.

\hypertarget{libraries-1}{%
\section{Libraries}\label{libraries-1}}

Both \texttt{readr} and \texttt{dplyr} are members of the tidyverse, so
a single invocation of \texttt{library()} makes the functions defined in
these two packages available for our use:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)  }
\end{Highlighting}
\end{Shaded}

\hypertarget{reading-data-with-the-readr-package}{%
\section{\texorpdfstring{Reading data with the \texttt{readr}
package}{Reading data with the readr package}}\label{reading-data-with-the-readr-package}}

The \href{http://readr.tidyverse.org}{\texttt{readr}} package defines a
number of functions for reading data tables from common file formats
like Comma-Separated-Value (CSV) and Tab-Separated-Value (TSV) files.

The two most frequently used \texttt{readr} functions we'll use in this
class are \texttt{read\_csv()} and \texttt{read\_tsv()} for reading CSV
and TSV files respectively. There are some variants of these basic
function, which you can read about by invoking the help system
(\texttt{?read\_csv}).

\hypertarget{example-data-nc-births}{%
\subsection{Example data: NC Births}\label{example-data-nc-births}}

For today's hands on session we'll use a data set that contains
information on 150 cases of mothers and their newborns in North Carolina
in 2004. This data set is available at the following URL:

\begin{itemize}
\tightlist
\item
  \url{https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/nc-births.txt}
\end{itemize}

The births data is a TSV file, so we'll use the \texttt{read\_tsv()}
function to read it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{births <-}\StringTok{ }\KeywordTok{read_tsv}\NormalTok{(}\StringTok{"https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/nc-births.txt"}\NormalTok{)}
\CommentTok{#> Parsed with column specification:}
\CommentTok{#> cols(}
\CommentTok{#>   fAge = col_integer(),}
\CommentTok{#>   mAge = col_integer(),}
\CommentTok{#>   weeks = col_integer(),}
\CommentTok{#>   premature = col_character(),}
\CommentTok{#>   visits = col_integer(),}
\CommentTok{#>   gained = col_integer(),}
\CommentTok{#>   weight = col_double(),}
\CommentTok{#>   sexBaby = col_character(),}
\CommentTok{#>   smoke = col_character()}
\CommentTok{#> )}
\end{Highlighting}
\end{Shaded}

Notice that when you used \texttt{read\_tsv()} the function printed
information about how it ``parsed'' the data (i.e.~the types it assigned
to each of the columns).

The variables in the data set are:

\begin{itemize}
\tightlist
\item
  father's age (\texttt{fAge}),
\item
  mother's age (\texttt{mAge}),\\
\item
  weeks of gestation (\texttt{weeks})
\item
  whether the birth was premature or full term (\texttt{premature})
\item
  number of OB/GYN visits (\texttt{visits})
\item
  mother's weight gained in pounds (\texttt{gained})
\item
  babies birth weight (\texttt{weight})
\item
  sex of the baby (\texttt{sexBaby})
\item
  whether the mother was a smoker (\texttt{smoke}).
\end{itemize}

Notice too that we read the TSV file directly from a remote location via
a URL. If instead, you wanted to load a local file on your computer you
would specify the ``path'' -- i.e.~the location on your hard drive where
you stored the file. For example, here is how I would load the same file
if it was stored in the Downloads directory on my Mac laptop:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# load the data from a local file}
\NormalTok{births <-}\StringTok{ }\KeywordTok{read_tsv}\NormalTok{(}\StringTok{"/Users/pmagwene/Downloads/nc-births.txt"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{reading-excel-files}{%
\subsection{Reading Excel files}\label{reading-excel-files}}

The tidyverse also includes a package called
\href{http://readxl.tidyverse.org}{\texttt{readxl}} which can be used to
read Excel spreadsheets (recent versions with \texttt{.xls} and
\texttt{.xlsx} extensions). Excel files are somewhat more complicated to
deal with because they can include separate ``sheets''. We won't use
\texttt{readxl} in this class, but documentation and examples of how
\texttt{readxl} is used can be found at the page linked above.

\hypertarget{a-note-on-tibbles}{%
\section{A note on ``tibbles''}\label{a-note-on-tibbles}}

You may have noticed that most of the functions defined in tidyverse
related packages return not data frames, but rather something called a
``tibble''. You can think about tibbles as light-weight data frames. In
fact if you ask about the ``class'' of a tibble you'll see that it
includes \texttt{data.frame} as one of it's classes as well as
\texttt{tbl} and \texttt{tbl\_df}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(births)}
\CommentTok{#> [1] "tbl_df"     "tbl"        "data.frame"}
\end{Highlighting}
\end{Shaded}

There are some minor differences between data frame and tibbles. For
example, tibbles print differently in the console and don't
automatically change variable names and types in the same way that
standard data frames do. Usually tibbles can be used wherever a standard
data frame is expected, but you may occasionally find a function that
only works with a standard data frame. It's easy to convert a tibble to
a standard data frame using the \texttt{as.data.frame} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{births.std.df <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(births)}
\end{Highlighting}
\end{Shaded}

For more details about tibbles, see the
\href{http://r4ds.had.co.nz/tibbles.html}{Tibbles chapter in R for Data
Analysis}.

\hypertarget{data-filtering-and-transformation-with-dplyr}{%
\section{\texorpdfstring{Data filtering and transformation with
\texttt{dplyr}}{Data filtering and transformation with dplyr}}\label{data-filtering-and-transformation-with-dplyr}}

\texttt{dplyr} is powerful tool for data filter and transformation. In
the same way that \texttt{ggplot2} attempts to provide a ``grammar of
graphics'', \texttt{dplyr} aims to provide a ``grammar of data
manipulation''. In today's material we will see how \texttt{dplyr}
complements and simplifies standard data frame indexing and subsetting
operations. However, \texttt{dplyr} is focused only on data frames and
doesn't completely replace the basic subsetting operations, and so being
adept with both \texttt{dplyr} and the indexing approaches we've seen
previously is important. If you're curious about the name ``dplyr'', the
package's originator Hadley Wickham says it's supposed to invoke the
idea of pliers for data frames
(\href{https://github.com/tidyverse/dplyr/issues/1857}{Github: Meaning
of dplyrs name})

\hypertarget{dplyrs-verbs}{%
\section{dplyr's ``verbs''}\label{dplyrs-verbs}}

The primary functions in the \texttt{dplyr} package can be thought of as
a set of ``verbs'', each verb corresponding to a common data
manipulation task. Some of the most frequently used verbs/functions in
\texttt{dplyr} include:

\begin{itemize}
\tightlist
\item
  \texttt{select} -- select columns
\item
  \texttt{filter} -- filter rows
\item
  \texttt{mutate} -- create new columns
\item
  \texttt{arrange}-- reorder rows
\item
  \texttt{summarize} -- summarize values
\item
  \texttt{group\_by} -- split data frame on some grouping variable. Can
  be powerfully combined with \texttt{summarize}
\end{itemize}

All of these functions return new data frames rather than modifying the
existing data frame (though some of the functions support in place
modification of data frames via optional arguments).We illustrate these
below by example using the NC births data.

\hypertarget{select}{%
\subsection{\texorpdfstring{\texttt{select}}{select}}\label{select}}

The \texttt{select} function subsets the columns (variables) of a data
frame. For example, to select just the weeks and weight columns from the
births data set we could do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wks.weight <-}\StringTok{ }\KeywordTok{select}\NormalTok{(births, weeks, weight)}
\KeywordTok{dim}\NormalTok{(wks.weight)  }\CommentTok{# dim should be 50 x 2}
\CommentTok{#> [1] 150   2}
\KeywordTok{head}\NormalTok{(wks.weight)}
\CommentTok{#> # A tibble: 6 x 2}
\CommentTok{#>   weeks weight}
\CommentTok{#>   <int>  <dbl>}
\CommentTok{#> 1    39   6.88}
\CommentTok{#> 2    39   7.69}
\CommentTok{#> 3    40   8.88}
\CommentTok{#> 4    40   9   }
\CommentTok{#> 5    40   7.94}
\CommentTok{#> 6    40   8.25}
\end{Highlighting}
\end{Shaded}

The equivalent using standard indexing would be:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wks.wt.alt <-}\StringTok{ }\NormalTok{births[}\KeywordTok{c}\NormalTok{(}\StringTok{"weeks"}\NormalTok{, }\StringTok{"weight"}\NormalTok{)]}
\KeywordTok{dim}\NormalTok{(wks.wt.alt)}
\CommentTok{#> [1] 150   2}
\KeywordTok{head}\NormalTok{(wks.wt.alt)}
\CommentTok{#> # A tibble: 6 x 2}
\CommentTok{#>   weeks weight}
\CommentTok{#>   <int>  <dbl>}
\CommentTok{#> 1    39   6.88}
\CommentTok{#> 2    39   7.69}
\CommentTok{#> 3    40   8.88}
\CommentTok{#> 4    40   9   }
\CommentTok{#> 5    40   7.94}
\CommentTok{#> 6    40   8.25}
\end{Highlighting}
\end{Shaded}

\textbf{Notes}:\\
* The first argument to all of the \texttt{dplyr} functions is the data
frame you're operating on

\begin{itemize}
\tightlist
\item
  When using functions defined in \texttt{dplyr} and \texttt{ggplot2}
  variable names are (usually) not quoted or used with the \texttt{\$}
  operator. This is a design feature of these libraries and makes it
  easier to carry out interactive analyes because it saves a fair amount
  of typing.
\end{itemize}

\hypertarget{filter}{%
\subsection{\texorpdfstring{\texttt{filter}}{filter}}\label{filter}}

The \texttt{filter} function returns those rows of the data set that
meet the given logical criterion.

For example, to get all the premature babies in the data set we could
use filter as so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{premies <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(births, premature }\OperatorTok{==}\StringTok{ "premie"}\NormalTok{)}
\KeywordTok{dim}\NormalTok{(premies)}
\CommentTok{#> [1] 21  9}
\end{Highlighting}
\end{Shaded}

The equivalent using standard indexing would be:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{premies.alt <-}\StringTok{ }\NormalTok{births[births}\OperatorTok{$}\NormalTok{premature }\OperatorTok{==}\StringTok{ "premie"}\NormalTok{,] }
\end{Highlighting}
\end{Shaded}

The \texttt{filter} function will work with more than one logical
argument, and these are joined together using Boolean AND logic
(i.e.~intersection). For example, to find those babies that were
premature \emph{and} whose mothers were smokers we could do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{smoking.premies <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(births, premature }\OperatorTok{==}\StringTok{ "premie"}\NormalTok{, smoke }\OperatorTok{==}\StringTok{ "smoker"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The equivalent call using standard indexing is:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# don't forget the trailing comma to indicate rows!}
\NormalTok{smoking.premies.alt <-}\StringTok{ }\NormalTok{births[(births}\OperatorTok{$}\NormalTok{premature }\OperatorTok{==}\StringTok{ "premie"}\NormalTok{) }\OperatorTok{&}\StringTok{ }\NormalTok{(births}\OperatorTok{$}\NormalTok{smoke }\OperatorTok{==}\StringTok{ "smoker"}\NormalTok{),]}
\end{Highlighting}
\end{Shaded}

\texttt{filter} also accepts logical statements chained together using
the standard Boolean operators. For example, to find babies who were
premature \emph{or} whose moms were older than 35 you could use the OR
operator \texttt{\textbar{}}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{premies.or.oldmom <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(births, premature }\OperatorTok{==}\StringTok{ "premie"} \OperatorTok{|}\StringTok{ }\NormalTok{fAge }\OperatorTok{>}\StringTok{ }\DecValTok{35}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{mutate}{%
\subsection{\texorpdfstring{\texttt{mutate}}{mutate}}\label{mutate}}

The \texttt{mutate} function creates a new data frame that is the same
as input data frame but with additional variables (columns) as specified
by the function arguments. In the example below, I create two new
variables, \texttt{weight.in.kg} and a \texttt{mom.smoked}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# to make code more readable it's sometime useful to spread out}
\CommentTok{# function arguments over multiple lines like I've done here}
\NormalTok{births.plus <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(births, }
                      \DataTypeTok{weight.in.kg =}\NormalTok{ weight }\OperatorTok{/}\StringTok{ }\FloatTok{2.2}\NormalTok{,}
                      \DataTypeTok{mom.smoked =}\NormalTok{ (smoke }\OperatorTok{==}\StringTok{ "smoker"}\NormalTok{))}

\KeywordTok{head}\NormalTok{(births.plus)}
\CommentTok{#> # A tibble: 6 x 11}
\CommentTok{#>    fAge  mAge weeks premature visits gained weight sexBaby smoke}
\CommentTok{#>   <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>}
\CommentTok{#> 1    31    30    39 full term     13      1   6.88 male    smok~}
\CommentTok{#> 2    34    36    39 full term      5     35   7.69 male    nons~}
\CommentTok{#> 3    36    35    40 full term     12     29   8.88 male    nons~}
\CommentTok{#> 4    41    40    40 full term     13     30   9    female  nons~}
\CommentTok{#> 5    42    37    40 full term     NA     10   7.94 male    nons~}
\CommentTok{#> 6    37    28    40 full term     12     35   8.25 male    smok~}
\CommentTok{#> # ... with 2 more variables: weight.in.kg <dbl>, mom.smoked <lgl>}
\end{Highlighting}
\end{Shaded}

The equivalent using standard indexing would be to create a new data
frame from \texttt{births}, appending the new variables to the end as
so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{births.plus.alt <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(births,}
                              \DataTypeTok{weight.in.kg =}\NormalTok{ births}\OperatorTok{$}\NormalTok{weight }\OperatorTok{/}\StringTok{ }\FloatTok{2.2}\NormalTok{,}
                              \DataTypeTok{mom.smoked =}\NormalTok{ (births}\OperatorTok{$}\NormalTok{smoke }\OperatorTok{==}\StringTok{ "smoker"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{arrange}{%
\subsection{\texorpdfstring{\texttt{arrange}}{arrange}}\label{arrange}}

Arrange creates a new data frame where the rows are sorted according to
their values for one or more variables. For example, to sort by mothers
age we could do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{young.moms.first <-}\StringTok{ }\KeywordTok{arrange}\NormalTok{(births, mAge)}
\KeywordTok{head}\NormalTok{(young.moms.first)}
\CommentTok{#> # A tibble: 6 x 9}
\CommentTok{#>    fAge  mAge weeks premature visits gained weight sexBaby smoke    }
\CommentTok{#>   <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>    }
\CommentTok{#> 1    18    15    37 full term     12     76   8.44 male    nonsmoker}
\CommentTok{#> 2    NA    16    40 full term      4     12   6    female  nonsmoker}
\CommentTok{#> 3    21    16    38 full term     15     75   7.56 female  smoker   }
\CommentTok{#> 4    26    17    38 full term     11     30   9.5  female  nonsmoker}
\CommentTok{#> 5    17    17    29 premie         4     10   2.63 female  nonsmoker}
\CommentTok{#> 6    20    17    40 full term     17     38   7.19 male    nonsmoker}
\end{Highlighting}
\end{Shaded}

The equivalent to \texttt{arrange} using standard indexing would be to
use the information returned by the \texttt{order} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{young.moms.first.alt <-}\StringTok{ }\NormalTok{births[}\KeywordTok{order}\NormalTok{(births}\OperatorTok{$}\NormalTok{mAge),]}
\KeywordTok{head}\NormalTok{(young.moms.first.alt)}
\CommentTok{#> # A tibble: 6 x 9}
\CommentTok{#>    fAge  mAge weeks premature visits gained weight sexBaby smoke    }
\CommentTok{#>   <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>    }
\CommentTok{#> 1    18    15    37 full term     12     76   8.44 male    nonsmoker}
\CommentTok{#> 2    NA    16    40 full term      4     12   6    female  nonsmoker}
\CommentTok{#> 3    21    16    38 full term     15     75   7.56 female  smoker   }
\CommentTok{#> 4    26    17    38 full term     11     30   9.5  female  nonsmoker}
\CommentTok{#> 5    17    17    29 premie         4     10   2.63 female  nonsmoker}
\CommentTok{#> 6    20    17    40 full term     17     38   7.19 male    nonsmoker}
\end{Highlighting}
\end{Shaded}

When using \texttt{arrange}, multiple sorting variables can be
specified:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sorted.by.moms.and.dads <-}\StringTok{ }\KeywordTok{arrange}\NormalTok{(births, mAge, fAge)}
\KeywordTok{head}\NormalTok{(sorted.by.moms.and.dads)}
\CommentTok{#> # A tibble: 6 x 9}
\CommentTok{#>    fAge  mAge weeks premature visits gained weight sexBaby smoke    }
\CommentTok{#>   <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>    }
\CommentTok{#> 1    18    15    37 full term     12     76   8.44 male    nonsmoker}
\CommentTok{#> 2    21    16    38 full term     15     75   7.56 female  smoker   }
\CommentTok{#> 3    NA    16    40 full term      4     12   6    female  nonsmoker}
\CommentTok{#> 4    17    17    29 premie         4     10   2.63 female  nonsmoker}
\CommentTok{#> 5    20    17    40 full term     17     38   7.19 male    nonsmoker}
\CommentTok{#> 6    26    17    38 full term     11     30   9.5  female  nonsmoker}
\end{Highlighting}
\end{Shaded}

If you want to sort in descending order, you can combing
\texttt{arrange} with the \texttt{desc} (=descend) function, also
defined in \texttt{dplyr}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{old.moms.first <-}\StringTok{ }\KeywordTok{arrange}\NormalTok{(births, }\KeywordTok{desc}\NormalTok{(mAge))}
\KeywordTok{head}\NormalTok{(old.moms.first)}
\CommentTok{#> # A tibble: 6 x 9}
\CommentTok{#>    fAge  mAge weeks premature visits gained weight sexBaby smoke    }
\CommentTok{#>   <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>    }
\CommentTok{#> 1    NA    41    33 premie        13      0   5.69 female  nonsmoker}
\CommentTok{#> 2    41    40    40 full term     13     30   9    female  nonsmoker}
\CommentTok{#> 3    33    40    36 premie        13     23   7.81 female  nonsmoker}
\CommentTok{#> 4    40    40    38 full term     13     38   7.31 male    nonsmoker}
\CommentTok{#> 5    46    39    38 full term     10     35   6.75 male    smoker   }
\CommentTok{#> 6    NA    38    32 premie        10     16   2.19 female  smoker}
\end{Highlighting}
\end{Shaded}

\hypertarget{summarize}{%
\subsection{\texorpdfstring{\texttt{summarize}}{summarize}}\label{summarize}}

\texttt{summarize} applies a function of interest to one or more
variables in a data frame, reducing a vector of values to a single value
and returning the results in a data frame. This is most often used to
calculate statistics like means, medians, count, etc. As we'll see
below, this is powerful when combined with the \texttt{group\_by}
function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summarize}\NormalTok{(births, }
          \DataTypeTok{mean.wt =} \KeywordTok{mean}\NormalTok{(weight), }
          \DataTypeTok{median.wks =} \KeywordTok{median}\NormalTok{(weeks))}
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>   mean.wt median.wks}
\CommentTok{#>     <dbl>      <dbl>}
\CommentTok{#> 1   7.046         39}
\end{Highlighting}
\end{Shaded}

You'll need to be diligent if your data has missing values (NAs). For
example, by default the \texttt{mean} function returns NA if any of the
input values are NA:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summarize}\NormalTok{(births, }
          \DataTypeTok{mean.gained =} \KeywordTok{mean}\NormalTok{(gained))}
\CommentTok{#> # A tibble: 1 x 1}
\CommentTok{#>   mean.gained}
\CommentTok{#>         <dbl>}
\CommentTok{#> 1          NA}
\end{Highlighting}
\end{Shaded}

However, if you read the \texttt{mean} docs (\texttt{?mean}) you'll see
that there is an \texttt{na.rm} argument that indicates whether NA
values should be removed before computing the mean. This is what we want
so we instead call summarize as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summarize}\NormalTok{(births, }
          \DataTypeTok{mean.gained =} \KeywordTok{mean}\NormalTok{(gained, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{))}
\CommentTok{#> # A tibble: 1 x 1}
\CommentTok{#>   mean.gained}
\CommentTok{#>         <dbl>}
\CommentTok{#> 1       32.45}
\end{Highlighting}
\end{Shaded}

\hypertarget{group_by}{%
\subsection{\texorpdfstring{\texttt{group\_by}}{group\_by}}\label{group_by}}

The \texttt{group\_by} function implicitly adds grouping information to
a data frame.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# group the births by whether mom smoked or not}
\NormalTok{by_smoking <-}\StringTok{ }\KeywordTok{group_by}\NormalTok{(births, smoke)}
\end{Highlighting}
\end{Shaded}

The object returned by \texttt{group\_by} is a ``grouped data frame'':

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(by_smoking)}
\CommentTok{#> [1] "grouped_df" "tbl_df"     "tbl"        "data.frame"}
\end{Highlighting}
\end{Shaded}

Some functions, like \texttt{count()} and \texttt{summarize()} (see
below) know how to use the grouping information. For example, to count
the number of births conditional on mother smoking status we could do:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{count}\NormalTok{(by_smoking)}
\CommentTok{#> # A tibble: 2 x 2}
\CommentTok{#> # Groups:   smoke [2]}
\CommentTok{#>   smoke         n}
\CommentTok{#>   <chr>     <int>}
\CommentTok{#> 1 nonsmoker   100}
\CommentTok{#> 2 smoker       50}
\end{Highlighting}
\end{Shaded}

\texttt{group\_by} also works with multiple grouping variables, with
each added grouping variable specified as an additional argument:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{by_smoking.and.mAge <-}\StringTok{ }\KeywordTok{group_by}\NormalTok{(births, smoke, mAge }\OperatorTok{>}\StringTok{ }\DecValTok{35}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{combining-grouping-and-summarizing}{%
\subsection{Combining grouping and
summarizing}\label{combining-grouping-and-summarizing}}

Grouped data frames can be combined with the \texttt{summarize} function
we saw above. For example, if we wanted to calculate mean birth weight,
broken down by whether the baby's mother smoked or not we could call
\texttt{summarize} with our \texttt{by\_smoking} grouped data frame:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summarize}\NormalTok{(by_smoking, }\DataTypeTok{mean.wt =} \KeywordTok{mean}\NormalTok{(weight))}
\CommentTok{#> # A tibble: 2 x 2}
\CommentTok{#>   smoke     mean.wt}
\CommentTok{#>   <chr>       <dbl>}
\CommentTok{#> 1 nonsmoker   7.180}
\CommentTok{#> 2 smoker      6.779}
\end{Highlighting}
\end{Shaded}

Similarly to get the mean birth weight of children conditioned on
mothers smoking status and age:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summarize}\NormalTok{(by_smoking.and.mAge, }\KeywordTok{mean}\NormalTok{(weight))}
\CommentTok{#> # A tibble: 4 x 3}
\CommentTok{#> # Groups:   smoke [?]}
\CommentTok{#>   smoke     `mAge > 35` `mean(weight)`}
\CommentTok{#>   <chr>     <lgl>                <dbl>}
\CommentTok{#> 1 nonsmoker FALSE                7.171}
\CommentTok{#> 2 nonsmoker TRUE                 7.258}
\CommentTok{#> 3 smoker    FALSE                6.832}
\CommentTok{#> 4 smoker    TRUE                 6.302}
\end{Highlighting}
\end{Shaded}

\hypertarget{scoped-variants-of-mutate-and-summarize}{%
\subsection{\texorpdfstring{Scoped variants of \texttt{mutate} and
\texttt{summarize}}{Scoped variants of mutate and summarize}}\label{scoped-variants-of-mutate-and-summarize}}

Both the \texttt{mutate()} and \texttt{summarize()} functions provide
``scoped'' alternatives, that allow us to apply the operation on a
selection of variables. These variants are often used in combination
with grouping. We'll look at the \texttt{summarize} versions --
\texttt{summarize\_all()}, \texttt{summarize\_at()}, and
\texttt{summarize\_if()}. See the documentation (\texttt{?mutate\_all})
for descriptions of the \texttt{mutate} versions.

\hypertarget{summarize_all}{%
\subsubsection{\texorpdfstring{\texttt{summarize\_all()}}{summarize\_all()}}\label{summarize_all}}

\texttt{summarize\_all()} applies a one or more functions to all columns
in a data frame. Here we illustrate a simple version of this with the
iris data:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# group by species}
\NormalTok{by_species <-}\StringTok{ }\KeywordTok{group_by}\NormalTok{(iris, Species)}
\CommentTok{# calculate the mean of every variable, grouped by species}
\KeywordTok{summarize_all}\NormalTok{(by_species, mean)  }
\CommentTok{#> # A tibble: 3 x 5}
\CommentTok{#>   Species    Sepal.Length Sepal.Width Petal.Length Petal.Width}
\CommentTok{#>   <fct>             <dbl>       <dbl>        <dbl>       <dbl>}
\CommentTok{#> 1 setosa            5.006       3.428        1.462       0.246}
\CommentTok{#> 2 versicolor        5.936       2.77         4.26        1.326}
\CommentTok{#> 3 virginica         6.588       2.974        5.552       2.026}
\end{Highlighting}
\end{Shaded}

Note that if we try and apply \texttt{summarize\_all()} in the same way
to the grouped data frame \texttt{by\_smoking} we'll get a bunch of
warning messages:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summarize_all}\NormalTok{(by_smoking, mean)}
\CommentTok{#> # A tibble: 2 x 9}
\CommentTok{#>   smoke      fAge  mAge weeks premature visits gained weight sexBaby}
\CommentTok{#>   <chr>     <dbl> <dbl> <dbl>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>}
\CommentTok{#> 1 nonsmoker    NA  26.9 38.55        NA   NA       NA  7.180      NA}
\CommentTok{#> 2 smoker       NA  26   38.54        NA   10.8     NA  6.779      NA}
\end{Highlighting}
\end{Shaded}

Here's an example of one of these warnings:

\begin{verbatim}
Warning messages:
1: In mean.default(premature) :
  argument is not numeric or logical: returning NA
\end{verbatim}

This message is telling us that we can't apply the \texttt{mean()}
function to the data frame column \texttt{premature} because this is not
a numerical or logical vector. Despite this and the other similar
warnings, \texttt{summarize\_all()} does return a result, but the means
for any non-numeric values are replaced with NAs, as shown below:

\begin{verbatim}
# A tibble: 2 x 9
  smoke      fAge  mAge weeks premature visits gained weight sexBaby
  <chr>     <dbl> <dbl> <dbl>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>
1 nonsmoker    NA  26.9  38.6        NA   NA       NA   7.18      NA
2 smoker       NA  26.0  38.5        NA   10.8     NA   6.78      NA
\end{verbatim}

If you examine the output above, you'll see that there are several
variables that are numeric, however we still got NAs when we calculated
the grouped means. This is because those variables contain NA values.
The \texttt{mean} function has an optional argument, \texttt{na.rm},
which tells the function to remove any missing data before calculating
the mean. Thus we can modify our call to \texttt{summarize\_all} as
follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculate mean of all variables, grouped by smoking status}
\KeywordTok{summarize_all}\NormalTok{(by_smoking, mean, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{#> # A tibble: 2 x 9}
\CommentTok{#>   smoke      fAge  mAge weeks premature visits gained weight sexBaby}
\CommentTok{#>   <chr>     <dbl> <dbl> <dbl>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>}
\CommentTok{#> 1 nonsmoker 29.81  26.9 38.55        NA  11.86  32.55  7.180      NA}
\CommentTok{#> 2 smoker    29.71  26   38.54        NA  10.8   32.27  6.779      NA}
\end{Highlighting}
\end{Shaded}

Note that the non-numeric data columns still lead to NA values.

\hypertarget{summarize_if}{%
\subsubsection{\texorpdfstring{\texttt{summarize\_if()}}{summarize\_if()}}\label{summarize_if}}

\texttt{summarize\_if()} is similar to \texttt{summarize\_all()}, except
it only applies the function of interest to those variables that match a
particular predicate (i.e.~are TRUE for a particular TRUE/FALSE test).

Here we use \texttt{summarize\_if()} to apply the \texttt{mean()}
function to only those variables (columns) that are numeric.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculate mean of all numeric variables, grouped by smoking status}
\KeywordTok{summarize_if}\NormalTok{(by_smoking, is.numeric, mean, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{#> # A tibble: 2 x 7}
\CommentTok{#>   smoke      fAge  mAge weeks visits gained weight}
\CommentTok{#>   <chr>     <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>}
\CommentTok{#> 1 nonsmoker 29.81  26.9 38.55  11.86  32.55  7.180}
\CommentTok{#> 2 smoker    29.71  26   38.54  10.8   32.27  6.779}
\end{Highlighting}
\end{Shaded}

\hypertarget{summarize_at}{%
\subsubsection{\texorpdfstring{\texttt{summarize\_at()}}{summarize\_at()}}\label{summarize_at}}

\texttt{summarize\_at()} allows us to apply functions of interest only
to specific variables.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculate mean of gained and weight variables, grouped by smoking status}
\KeywordTok{summarize_at}\NormalTok{(by_smoking, }\KeywordTok{c}\NormalTok{(}\StringTok{"gained"}\NormalTok{, }\StringTok{"weight"}\NormalTok{), mean, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{#> # A tibble: 2 x 3}
\CommentTok{#>   smoke     gained weight}
\CommentTok{#>   <chr>      <dbl>  <dbl>}
\CommentTok{#> 1 nonsmoker  32.55  7.180}
\CommentTok{#> 2 smoker     32.27  6.779}
\end{Highlighting}
\end{Shaded}

All three of the scoped summarize functions can also be used to apply
multiple functions, by wrapping the function names in a call to
\texttt{dplyr::funs()}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculate mean and std deviation of }
\CommentTok{# gained and weight variables, grouped by smoking status}
\KeywordTok{summarize_at}\NormalTok{(by_smoking, }\KeywordTok{c}\NormalTok{(}\StringTok{"gained"}\NormalTok{, }\StringTok{"weight"}\NormalTok{), }\KeywordTok{funs}\NormalTok{(mean, sd), }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{#> # A tibble: 2 x 5}
\CommentTok{#>   smoke     gained_mean weight_mean gained_sd weight_sd}
\CommentTok{#>   <chr>           <dbl>       <dbl>     <dbl>     <dbl>}
\CommentTok{#> 1 nonsmoker       32.55       7.180     15.23     1.434}
\CommentTok{#> 2 smoker          32.27       6.779     16.65     1.597}
\end{Highlighting}
\end{Shaded}

\texttt{summarize\_at()} accepts as the the argument for variables a
character vector of column names, a numeric vector of column positions,
or a list of columns generated by the \texttt{dplyr::vars()} function,
which can be be used as so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# reformatted to promote readability of arguments}
\KeywordTok{summarize_at}\NormalTok{(by_smoking, }
             \KeywordTok{vars}\NormalTok{(gained, weight),}
             \KeywordTok{funs}\NormalTok{(mean, sd),}
             \DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{#> # A tibble: 2 x 5}
\CommentTok{#>   smoke     gained_mean weight_mean gained_sd weight_sd}
\CommentTok{#>   <chr>           <dbl>       <dbl>     <dbl>     <dbl>}
\CommentTok{#> 1 nonsmoker       32.55       7.180     15.23     1.434}
\CommentTok{#> 2 smoker          32.27       6.779     16.65     1.597}
\end{Highlighting}
\end{Shaded}

\hypertarget{combining-summarize-with-grouping-aesthetics-in-ggplot2}{%
\subsection{\texorpdfstring{Combining summarize with grouping aesthetics
in
\texttt{ggplot2}}{Combining summarize with grouping aesthetics in ggplot2}}\label{combining-summarize-with-grouping-aesthetics-in-ggplot2}}

We've already seen an instance of grouping (conditioning) when we used
aesthetics like color or fill to distinguish subgroups in different
types of statistical graphics. Below is an example where we integrate
information from a \texttt{group\_by}/\texttt{summarize} operation into
a plot:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculate mean weights, conditioned on smoking status}
\NormalTok{wt.by.smoking <-}\StringTok{ }
\StringTok{  }\KeywordTok{summarize}\NormalTok{(by_smoking, }\DataTypeTok{mean_weight =} \KeywordTok{mean}\NormalTok{(weight, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{))}

\CommentTok{# create density plot for all the data}
\CommentTok{# and then use geom_vline to draw vertical lines at the means for}
\CommentTok{# each group}
\KeywordTok{ggplot}\NormalTok{(births) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_density}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ weight, }\DataTypeTok{color =}\NormalTok{ smoke)) }\OperatorTok{+}\StringTok{ }\CommentTok{# data drawn from births}
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ wt.by.smoking,  }\CommentTok{# note use of different data frame!}
             \DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ mean_weight, }\DataTypeTok{color =}\NormalTok{ smoke),}
             \DataTypeTok{linetype =} \StringTok{'dashed'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-232-1.pdf}

\hypertarget{pipes}{%
\section{Pipes}\label{pipes}}

\texttt{dplyr} includes a very useful operator available called a pipe
available to us. Pipes are powerful because they allow us to chain
together sets of operations in a very intuitive fashion while minimizing
nested function calls. We can think of pipes as taking the output of one
function and feeding it as the \emph{first argument} to another function
call, where we've already specified the subsequent arguments.

Pipes are actually defined in another packaged called \texttt{magrittr}.
We'll look at the basic pipe operator and then look at a few additional
``special'' pipes that \texttt{magrittr} provides.

\hypertarget{install-and-load-magrittr}{%
\subsection{\texorpdfstring{Install and load
\texttt{magrittr}}{Install and load magrittr}}\label{install-and-load-magrittr}}

In magrittr in not already installed, install it via the command line or
the RStudio GUI. Having done so, you will need to load magrittr via the
\texttt{library()} function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(magrittr)}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-basic-pipe-operator}{%
\subsection{The basic pipe operator}\label{the-basic-pipe-operator}}

The pipe operator is designated by \texttt{\%\textgreater{}\%}. Using
pipes, the expression \texttt{x\ \%\textgreater{}\%\ f()} is equivalent
to \texttt{f(x)} and the expression \texttt{x\ \%\textgreater{}\%\ f(y)}
is equivalent to \texttt{f(x,y)}. The documentation on pipes (see
\texttt{?magrittr}) uses the notation
\texttt{lhs\ \%\textgreater{}\%\ rhs} where \texttt{lhs} and
\texttt{rhs} are short for ``left-hand side'' and ``right-hand side''
respectively. I'll use this same notation in some of the explanations
that follow.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{births }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{()   }\CommentTok{# same as head(births)}
\CommentTok{#> # A tibble: 6 x 9}
\CommentTok{#>    fAge  mAge weeks premature visits gained weight sexBaby smoke    }
\CommentTok{#>   <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>    }
\CommentTok{#> 1    31    30    39 full term     13      1   6.88 male    smoker   }
\CommentTok{#> 2    34    36    39 full term      5     35   7.69 male    nonsmoker}
\CommentTok{#> 3    36    35    40 full term     12     29   8.88 male    nonsmoker}
\CommentTok{#> 4    41    40    40 full term     13     30   9    female  nonsmoker}
\CommentTok{#> 5    42    37    40 full term     NA     10   7.94 male    nonsmoker}
\CommentTok{#> 6    37    28    40 full term     12     35   8.25 male    smoker}
\NormalTok{births }\OperatorTok{%>%}\StringTok{ }\NormalTok{head     }\CommentTok{# you can even leave the parentheses out}
\CommentTok{#> # A tibble: 6 x 9}
\CommentTok{#>    fAge  mAge weeks premature visits gained weight sexBaby smoke    }
\CommentTok{#>   <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>    }
\CommentTok{#> 1    31    30    39 full term     13      1   6.88 male    smoker   }
\CommentTok{#> 2    34    36    39 full term      5     35   7.69 male    nonsmoker}
\CommentTok{#> 3    36    35    40 full term     12     29   8.88 male    nonsmoker}
\CommentTok{#> 4    41    40    40 full term     13     30   9    female  nonsmoker}
\CommentTok{#> 5    42    37    40 full term     NA     10   7.94 male    nonsmoker}
\CommentTok{#> 6    37    28    40 full term     12     35   8.25 male    smoker}
\NormalTok{births }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{) }\CommentTok{# same as head(births, 10)}
\CommentTok{#> # A tibble: 10 x 9}
\CommentTok{#>     fAge  mAge weeks premature visits gained weight sexBaby smoke    }
\CommentTok{#>    <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>    }
\CommentTok{#>  1    31    30    39 full term     13      1   6.88 male    smoker   }
\CommentTok{#>  2    34    36    39 full term      5     35   7.69 male    nonsmoker}
\CommentTok{#>  3    36    35    40 full term     12     29   8.88 male    nonsmoker}
\CommentTok{#>  4    41    40    40 full term     13     30   9    female  nonsmoker}
\CommentTok{#>  5    42    37    40 full term     NA     10   7.94 male    nonsmoker}
\CommentTok{#>  6    37    28    40 full term     12     35   8.25 male    smoker   }
\CommentTok{#>  7    35    35    28 premie         6     29   1.63 female  nonsmoker}
\CommentTok{#>  8    28    21    35 premie         9     15   5.5  female  smoker   }
\CommentTok{#>  9    22    20    32 premie         5     40   2.69 male    smoker   }
\CommentTok{#> 10    36    25    40 full term     13     34   8.75 female  nonsmoker}
\end{Highlighting}
\end{Shaded}

Multiple pipes can be chained together, such that
\texttt{x\ \%\textgreater{}\%\ f()\ \%\textgreater{}\%\ g()\ \%\textgreater{}\%\ h()}
is equivalent to \texttt{h(g(f(x)))}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# equivalent to: head(arrange(births, weight), 10)}
\NormalTok{births }\OperatorTok{%>%}\StringTok{ }\KeywordTok{arrange}\NormalTok{(weight) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{) }
\CommentTok{#> # A tibble: 10 x 9}
\CommentTok{#>     fAge  mAge weeks premature visits gained weight sexBaby smoke    }
\CommentTok{#>    <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>    }
\CommentTok{#>  1    35    35    28 premie         6     29   1.63 female  nonsmoker}
\CommentTok{#>  2    NA    18    33 premie         7     40   1.69 male    smoker   }
\CommentTok{#>  3    NA    38    32 premie        10     16   2.19 female  smoker   }
\CommentTok{#>  4    17    17    29 premie         4     10   2.63 female  nonsmoker}
\CommentTok{#>  5    22    20    32 premie         5     40   2.69 male    smoker   }
\CommentTok{#>  6    38    37    26 premie         5     25   3.63 male    nonsmoker}
\CommentTok{#>  7    25    22    34 premie        10     20   3.75 male    nonsmoker}
\CommentTok{#>  8    NA    24    38 full term     16     50   3.75 female  nonsmoker}
\CommentTok{#>  9    30    25    35 premie        15     40   4.5  male    smoker   }
\CommentTok{#> 10    19    20    34 premie        13      6   4.5  male    nonsmoker}
\end{Highlighting}
\end{Shaded}

When there are multiple piping operations, I like to arrange the
statements vertically to help emphasize the flow of processing and to
facilitate debugging and/or modification. I would usually rearrange the
above code block as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{births }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(weight) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{#> # A tibble: 10 x 9}
\CommentTok{#>     fAge  mAge weeks premature visits gained weight sexBaby smoke    }
\CommentTok{#>    <int> <int> <int> <chr>      <int>  <int>  <dbl> <chr>   <chr>    }
\CommentTok{#>  1    35    35    28 premie         6     29   1.63 female  nonsmoker}
\CommentTok{#>  2    NA    18    33 premie         7     40   1.69 male    smoker   }
\CommentTok{#>  3    NA    38    32 premie        10     16   2.19 female  smoker   }
\CommentTok{#>  4    17    17    29 premie         4     10   2.63 female  nonsmoker}
\CommentTok{#>  5    22    20    32 premie         5     40   2.69 male    smoker   }
\CommentTok{#>  6    38    37    26 premie         5     25   3.63 male    nonsmoker}
\CommentTok{#>  7    25    22    34 premie        10     20   3.75 male    nonsmoker}
\CommentTok{#>  8    NA    24    38 full term     16     50   3.75 female  nonsmoker}
\CommentTok{#>  9    30    25    35 premie        15     40   4.5  male    smoker   }
\CommentTok{#> 10    19    20    34 premie        13      6   4.5  male    nonsmoker}
\end{Highlighting}
\end{Shaded}

\hypertarget{an-example-without-pipes}{%
\subsection{An example without pipes}\label{an-example-without-pipes}}

To illustrate how pipes help us, first let's look at an example set of
analysis steps without using pipes. Let's say we wanted to explore the
relationship between father's age and baby's birth weight. We'll start
this process of exploration by generating a bivariate scatter plot.
Being good scientists we want to express our data in SI units, so we'll
need to converts pounds to kilograms. You'll also recall that a number
of the cases have missing data on father's age, so we'll want to remove
those before we plot them. Here's how we might accomplish these steps:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# add a new column for weight in kg}
\NormalTok{births.kg <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(births, }\DataTypeTok{weight.kg =}\NormalTok{ weight }\OperatorTok{/}\StringTok{ }\FloatTok{2.2}\NormalTok{)}

\CommentTok{# filter out the NA fathers}
\NormalTok{filtered.births <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(births.kg, }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(fAge))}

\CommentTok{# create our plot}
\KeywordTok{ggplot}\NormalTok{(filtered.births, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ fAge, }\DataTypeTok{y =}\NormalTok{ weight.kg)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Father's Age (years)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Birth Weight (kg)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-237-1.pdf}

Notice that we created two ``temporary'' data frames along the way --
\texttt{births.kg} and \texttt{filtered.births}. These probably aren't
of particular interest to us, but we needed to generate them to build
the plot we wanted. If you were particularly masochistic you could avoid
these temporary data frames by using nested functions call like this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# You SHOULD NOT write nested code like this.}
\CommentTok{# Code like this is hard to debug and understand!}
\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{filter}\NormalTok{(}\KeywordTok{mutate}\NormalTok{(births, }\DataTypeTok{weight.kg =}\NormalTok{ weight }\OperatorTok{/}\StringTok{ }\FloatTok{2.2}\NormalTok{), }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(fAge)), }
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ fAge, }\DataTypeTok{y =}\NormalTok{ weight.kg)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Father's Age (years)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Birth Weight (kg)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-same-example-using-pipes}{%
\subsection{The same example using
pipes}\label{the-same-example-using-pipes}}

The pipe operator makes the output of one statement (\texttt{lhs}) as
the first input of a following function (\texttt{rhs}). This simplifies
the above example to:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{births }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{weight.kg =}\NormalTok{ weight }\OperatorTok{/}\StringTok{ }\FloatTok{2.2}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(fAge)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ fAge, }\DataTypeTok{y =}\NormalTok{ weight.kg)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Father's Age (years)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Birth Weight (kg)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-239-1.pdf}

In the example above, we feed the data frame into the \texttt{mutate}
function. \texttt{mutate} expects a data frame as a first argument, and
subsequent arguments specify the new variables to be created.
\texttt{births\ \%\textgreater{}\%\ mutate(weight.kg\ =\ weight\ /\ 2.2)}
is thus equivalent to
\texttt{mutate(births,\ weight.kg\ =\ weight\ /\ 2.2))}. We then pipe
the output to \texttt{filter}, removing NA fathers, and then pipe that
output as the input to ggplot.

As mentioned previously, it's good coding style to write each discrete
step as its own line when using piping. This make it easier to
understand what the steps of the analysis are as well as facilitating
changes to the code (commenting out lines, adding lines, etc)

\hypertarget{assigning-the-output-of-a-statement-involving-pipes-to-a-variable}{%
\subsection{Assigning the output of a statement involving pipes to a
variable}\label{assigning-the-output-of-a-statement-involving-pipes-to-a-variable}}

It's important to recognize that pipes are simply a convenient way to
chain together a series of expression. Just like any other compound
expression, the output of a series of pipe statements can be assigned to
a variable, like so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stats.old.moms <-}
\StringTok{  }\NormalTok{births }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(mAge }\OperatorTok{>}\StringTok{ }\DecValTok{35}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{median.gestation =} \KeywordTok{median}\NormalTok{(weeks), }
            \DataTypeTok{mean.weight =} \KeywordTok{mean}\NormalTok{(weight))}

\NormalTok{stats.old.moms}
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>   median.gestation mean.weight}
\CommentTok{#>              <int>       <dbl>}
\CommentTok{#> 1               38       6.939}
\end{Highlighting}
\end{Shaded}

Note that our summary table, \texttt{stats.old.moms}, is itself a data
frame.

\hypertarget{compound-assignment-pipe-operator}{%
\subsection{Compound assignment pipe
operator}\label{compound-assignment-pipe-operator}}

A fairly common operation when working interactively in R is to update
an existing data frame. \texttt{magrittr} defines another pipe operator
-- \texttt{\%\textless{}\textgreater{}\%} -- called the ``compound
assignment'' pipe operator, to facilitate this. The compound assignment
pipe operator has the basic usage
\texttt{lhs\ \%\textless{}\textgreater{}\%\ rhs}. This operator
evaluates the function on the \texttt{rhs} using the \texttt{lhs} as the
first argument, and \emph{then} updates the \texttt{lhs} with the
resulting value. This is simply shorthand for writing
\texttt{lhs\ \textless{}-\ lhs\ \%\textgreater{}\%\ rhs}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stats.old.moms }\OperatorTok{%<>%}\StringTok{  }\CommentTok{# note compound pipe operator!}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{mean.weight.kg =}\NormalTok{ mean.weight }\OperatorTok{/}\StringTok{ }\FloatTok{2.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-dot-operator-with-pipes}{%
\subsection{The dot operator with
pipes}\label{the-dot-operator-with-pipes}}

When working with pipes, sometimes you'll want to use the \texttt{lhs}
in multiple places on the \texttt{rhs}, or as something other than the
first argument to the \texttt{rhs}. \texttt{magrittr} provides for this
situation by using the dot (\texttt{.}) operator as a placeholder. Using
the dot operator, the expression
\texttt{y\ \%\textgreater{}\%\ f(x,\ .)} is equivalent to
\texttt{f(x,y)}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cakes"}\NormalTok{, }\StringTok{"sauce"}\NormalTok{, }\StringTok{"house"}\NormalTok{) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# create a vector}
\StringTok{  }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\CommentTok{# pick a random single element of that vector}
\StringTok{  }\KeywordTok{str_c}\NormalTok{(}\StringTok{"hot"}\NormalTok{, .)  }\CommentTok{# string concatenate the pick with the word "hot"}
\CommentTok{#> [1] "hotcakes"}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-exposition-pipe-operator}{%
\subsection{The exposition pipe
operator}\label{the-exposition-pipe-operator}}

\texttt{magrittr} defines another operator called the ``exposition pipe
operator'', designed \texttt{\%\$\%}. This operator exposes the names in
the \texttt{lhs} to the expression on the \texttt{rhs}.

Here is an example of using the exposition pipe operator to simply
return the vector of weights:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{births }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(premature }\OperatorTok{==}\StringTok{ "premie"}\NormalTok{) }\OperatorTok{%$%}\StringTok{  }\CommentTok{# note the different pipe operator!}
\StringTok{  }\NormalTok{weight}
\CommentTok{#>  [1] 1.63 5.50 2.69 6.50 7.81 4.75 3.75 2.19 6.81 4.69 6.75 4.50 5.94 4.50}
\CommentTok{#> [15] 5.06 5.69 1.69 6.31 2.63 5.88 3.63}
\end{Highlighting}
\end{Shaded}

If we wanted to calculate the minimum and maximum weight of premature
babies in the data set we could do the following (though I'd usually
prefer \texttt{summarize()} unless I needed the results in the form of a
vector):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{births }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(mAge }\OperatorTok{>}\StringTok{ }\DecValTok{35}\NormalTok{) }\OperatorTok{%$%}\StringTok{  }\CommentTok{# note the different pipe operator!}
\StringTok{  }\KeywordTok{c}\NormalTok{(}\KeywordTok{min}\NormalTok{(weight), }\KeywordTok{max}\NormalTok{(weight)) }
\CommentTok{#> [1]  2.19 10.13}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-wrangling-part-i}{%
\chapter{Data wrangling, Part I}\label{data-wrangling-part-i}}

In the real world you'll often create a data set (or be given one) in a
format that is less than ideal for analysis. This can happen for a
number of reasons. For example, the data may have been recorded in a
manner convenient for collection and visual inspection, but which does
not work well for analysis and plotting. Or the data may be an
amalgamation of multiple experiments, in which each of the experimenters
used slightly different naming conventions. Or the data may have been
produced by an instrument that produces output with a fixed format.
Sometimes important experimental information is included in the column
headers of a spreadsheet.

Whatever the case, we often find ourselves in the situation where we
need to ``wrangle'' our data into a ``tidy'' format before we can
proceed with visualization and analysis. The ``R for Data Science'' text
discusses some desirable rules for ``tidy'' data in order to facilitate
downstream analyses. These are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Each variable must have its own column.
\item
  Each observation must have its own row.
\item
  Each value must have its own cell.
\end{enumerate}

In this lecture we're going to walk through an extended example of
wrangling some data into a ``tidy'' format.

\hypertarget{libraries-2}{%
\section{Libraries}\label{libraries-2}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(magrittr)}
\KeywordTok{library}\NormalTok{(stringr)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(cowplot)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data}{%
\section{Data}\label{data}}

To illustrate a data wrangling pipeline, we're going to use a gene
expression microarray data set, based on the following paper:

\begin{itemize}
\tightlist
\item
  Spellman PT, et al.~1998. Comprehensive identification of cell
  cycle-regulated genes of the yeast Saccharomyces cerevisiae by
  microarray hybridization. Mol Biol Cell 9(12): 3273-97.
\end{itemize}

In this paper, Spellman and colleagues tried to identify all the genes
in the yeast genome (\textgreater{}6000 genes) that exhibited
oscillatory behaviors suggestive of cell cycle regulation. To do so,
they combined gene expression measurements from six different types of
cell cycle synchronization experiments.

\emph{Download the Spellman data to your filesystem} from
\href{https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/spellman-combined.txt}{this
link} (right-click the ``Download'' button and save to your Downloads
folder or similar).

I suggest that once you download the data, you open it in a spreadsheet
program (e.g.~Excel) or use the RStudio Data Viewer to get a sense of
what the data looks like.

Let's load it into R, using the \texttt{read\_tsv()} function, using the
appropriate file path.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# the filepath may differ on your computer}
\NormalTok{spellman <-}\StringTok{ }\KeywordTok{read_tsv}\NormalTok{(}\StringTok{"~/Downloads/spellman-combined.txt"}\NormalTok{)}
\CommentTok{#> Parsed with column specification:}
\CommentTok{#> cols(}
\CommentTok{#>   .default = col_double(),}
\CommentTok{#>   X1 = col_character(),}
\CommentTok{#>   clb = col_character(),}
\CommentTok{#>   alpha = col_character(),}
\CommentTok{#>   cdc15 = col_character(),}
\CommentTok{#>   cdc28 = col_character(),}
\CommentTok{#>   elu = col_character()}
\CommentTok{#> )}
\CommentTok{#> See spec(...) for full column specifications.}
\end{Highlighting}
\end{Shaded}

The initial dimenions of the data frame are:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(spellman)}
\CommentTok{#> [1] 6178   83}
\end{Highlighting}
\end{Shaded}

The six types of cell cycle synchronization experiments included in this
data set are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  synchronization by alpha-factor = ``alpha''
\item
  synchronization by cdc15 temperature sensitive mutants = ``cdc15''
\item
  synchronization by cdc28 temperature sensitive mutants = ``cdc28''
\item
  synchronization by elutration = ``elu''
\item
  synchronization by cln3 mutatant strains = ``cln3''
\item
  synchronization by clb2 mutant strains = ``clb2''
\end{enumerate}

\hypertarget{renaming-data-frame-columms}{%
\section{Renaming data frame
columms}\label{renaming-data-frame-columms}}

Notice that when we imported the data we got a warning message:
\texttt{Missing\ column\ names\ filled\ in:\ \textquotesingle{}X1\textquotesingle{}\ {[}1{]}}.
In a data frame, every column must have a name. The first column of our
data set did not have a name in the header, so \texttt{read\_tsv}
automatically gave it the name \texttt{X1}.

Our first task is to give the first column a more meaningful name. This
column gives ``systematic gene names'' -- a standardized naming scheme
for genes in the yeast genome. We'll use \texttt{dplyr::rename} to
rename \texttt{X1} to \texttt{gene}. Note that \texttt{rename} can take
multiple arguments if you need to rename multiple columns
simultaneously.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.clean <-}\StringTok{ }
\StringTok{  }\NormalTok{spellman }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{gene =}\NormalTok{ X1)}
\end{Highlighting}
\end{Shaded}

Note the use of the compound assingment operator --
\texttt{\%\textless{}\textgreater{}\%} -- from the \texttt{magrittr}
package, which we introduced in our last class session.

\hypertarget{dropping-unneeded-columns}{%
\section{Dropping unneeded columns}\label{dropping-unneeded-columns}}

Take a look at the Spellman data again in your spreadsheet program (or
the RStudio data viewer). You'll notice there are some blank columns.
For example there is a column with the header ``alpha'' that has no
entries. These are simply visual organizing elements that the creator of
the spreadsheet added to separate the different experiments that are
included in the data set.

We can use \texttt{dplyr::select()} to drop columns by prepending column
names with the negative sign:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# drop the alpha column keeping all others}
\NormalTok{spellman.clean }\OperatorTok{%<>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{alpha)  }
\end{Highlighting}
\end{Shaded}

Note that usually \texttt{select()} keeps only the variables you
specify. However if the first expression is negative, \texttt{select}
will instead automatically keep all variables, dropping only those you
specify.

\hypertarget{finding-all-empty-columns}{%
\subsection{Finding all empty columns}\label{finding-all-empty-columns}}

In the example above, we looked at the data and saw that the ``alpha''
column was empty, and thus dropped it. This worked because there are
only a modest number of columns in the data frame in it's initial form.
However, if our data frame contained thousands of columns, this ``look
and see'' procedure would not be efficient. Can we come up with a
general solution for removing empty columns from a data frame?

When you load a data frame from a spreadsheet, empty cells are given the
value \texttt{NA}. In previous class sessions we were introduced to the
function \texttt{is.na()} which tests each value in a vector or data
frame for whether it's NA or not. We can count NA values in a vector by
summing the output of \texttt{is.na()}. Conversely we can count the
number of ``not NA'' items by using the negation operator (\texttt{!}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# count number of NA values in the alpha0 column}
\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(spellman}\OperatorTok{$}\NormalTok{alpha0))}
\CommentTok{#> [1] 165}

\CommentTok{# count number of values that are NOT NA in alpha0}
\KeywordTok{sum}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(spellman}\OperatorTok{$}\NormalTok{alpha0))}
\CommentTok{#> [1] 6013}
\end{Highlighting}
\end{Shaded}

This seems like it should get us close to a solution but
\texttt{sum(is.na(..))} when applied to a data frame counts NAs across
the entire data frame, not column-by-column.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# doesn't do what we hoped!}
\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(spellman))}
\CommentTok{#> [1] 59017}
\end{Highlighting}
\end{Shaded}

If we want sums of NAs by column, we instead use the \texttt{colSums()}
function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# get number of NAs by column}
\KeywordTok{colSums}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(spellman))}
\CommentTok{#>        X1    cln3-1    cln3-2       clb    clb2-2    clb2-1     alpha }
\CommentTok{#>         0       193       365      6178       454       142      6178 }
\CommentTok{#>    alpha0    alpha7   alpha14   alpha21   alpha28   alpha35   alpha42 }
\CommentTok{#>       165       525       191       312       267       207       123 }
\CommentTok{#>   alpha49   alpha56   alpha63   alpha70   alpha77   alpha84   alpha91 }
\CommentTok{#>       257       147       186       185       178       155       329 }
\CommentTok{#>   alpha98  alpha105  alpha112  alpha119     cdc15  cdc15_10  cdc15_30 }
\CommentTok{#>       209       174       222       251      6178       677       477 }
\CommentTok{#>  cdc15_50  cdc15_70  cdc15_80  cdc15_90 cdc15_100 cdc15_110 cdc15_120 }
\CommentTok{#>       501       608       573       562       606       570       611 }
\CommentTok{#> cdc15_130 cdc15_140 cdc15_150 cdc15_160 cdc15_170 cdc15_180 cdc15_190 }
\CommentTok{#>       495       574       811       583       571       803       613 }
\CommentTok{#> cdc15_200 cdc15_210 cdc15_220 cdc15_230 cdc15_240 cdc15_250 cdc15_270 }
\CommentTok{#>      1014       573       741       596       847       379       537 }
\CommentTok{#> cdc15_290     cdc28   cdc28_0  cdc28_10  cdc28_20  cdc28_30  cdc28_40 }
\CommentTok{#>       426      6178       122        72        67        55        66 }
\CommentTok{#>  cdc28_50  cdc28_60  cdc28_70  cdc28_80  cdc28_90 cdc28_100 cdc28_110 }
\CommentTok{#>        56        82        84        75       237       165       319 }
\CommentTok{#> cdc28_120 cdc28_130 cdc28_140 cdc28_150 cdc28_160       elu      elu0 }
\CommentTok{#>       312      1439      2159       521       543      6178       122 }
\CommentTok{#>     elu30     elu60     elu90    elu120    elu150    elu180    elu210 }
\CommentTok{#>       153       175       132       103       119       111       118 }
\CommentTok{#>    elu240    elu270    elu300    elu330    elu360    elu390 }
\CommentTok{#>       131       110       112       112       156       114}
\end{Highlighting}
\end{Shaded}

Columns with \emph{all} missing values can be more conveniently found by
asking for those columns where the number of ``not missing'' values is
zero:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# get names of all columns for which all rows are NA}
\CommentTok{# useing standard indexing}
\KeywordTok{names}\NormalTok{(spellman)[}\KeywordTok{colSums}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(spellman)) }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{]}
\CommentTok{#> [1] "clb"   "alpha" "cdc15" "cdc28" "elu"}
\end{Highlighting}
\end{Shaded}

We can combine the \texttt{colSums(!is.na())} idiom with the
\texttt{dplyr::select\_if} function to quickly remove all empty columns
as so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.clean }\OperatorTok{%<>%}
\StringTok{  }\CommentTok{# keep ONLY the non-empty columns}
\StringTok{  }\KeywordTok{select_if}\NormalTok{(}\KeywordTok{colSums}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(.)) }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{dropping-columns-by-matching-names}{%
\subsection{Dropping columns by matching
names}\label{dropping-columns-by-matching-names}}

Only two time points from the cln3 and clb2 experiments were reported in
the original publication. Since complete time series are unavailable for
these two experimental conditions we will drop them from further
consideration.

\texttt{select()} can be called be called with a number of ``helper
function'' (\texttt{?select\_helpers}). Here we'll illustrate the
\texttt{matches()} helper function which matches column names to a
``regular expression''. Regular expressions (also referred to as
``regex'' or ``regexp'') are a way of specifying patterns in strings.
For the purposes of this document we'll illustrate regexs by example;
for a more detailed explanation of regular expressions see the the regex
help(\texttt{?regex}) and the
\href{http://r4ds.had.co.nz/strings.html}{Chapter on Strings in ``R for
Data Analysis''}:

Let's see how to drop all the ``cln3'' and ``clb2'' columns from the
data frame using \texttt{matches()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.clean }\OperatorTok{%<>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{matches}\NormalTok{(}\StringTok{"cln3"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{matches}\NormalTok{(}\StringTok{"clb2"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

If we wanted we could have collapsed our two match statements into one
as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.clean }\OperatorTok{%<>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{matches}\NormalTok{(}\StringTok{"cln3|clb2"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

In this second example, the character ``\textbar{}'' is specifing an OR
match within the regular expression, so this regular expression matches
column names that contain ``cln3'' OR ``clb2''.

\hypertarget{merging-data-frames}{%
\section{Merging data frames}\label{merging-data-frames}}

Often you'll find yourself in the situation where you want to combine
information from multiple data sources. The usual requirement is that
the data sources have one or more shared columns, that allow you to
relate the entities or observations (rows) between the data sets.
\texttt{dplyr} provides a variety of \texttt{join} functions to handle
different data merging operators.

To illustrating merging or joining data sources, we'll add information
about each genes ``common name'' and a description of the gene functions
to our Spellman data set. I've prepared a file with this info based on
info I downloaded from the
\href{https://www.yeastgenome.org}{Saccharomyces Genome Database}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gene.info <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/yeast-ORF-info.csv"}\NormalTok{)}
\CommentTok{#> Parsed with column specification:}
\CommentTok{#> cols(}
\CommentTok{#>   ftr.name = col_character(),}
\CommentTok{#>   std.name = col_character(),}
\CommentTok{#>   description = col_character()}
\CommentTok{#> )}
\end{Highlighting}
\end{Shaded}

Having loaded the data, let's get a quick overview of it's structure:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(gene.info)}
\CommentTok{#> [1] "ftr.name"    "std.name"    "description"}
\KeywordTok{dim}\NormalTok{(gene.info)}
\CommentTok{#> [1] 6610    3}
\KeywordTok{head}\NormalTok{(gene.info)}
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>   ftr.name  std.name description                                          }
\CommentTok{#>   <chr>     <chr>    <chr>                                                }
\CommentTok{#> 1 YAL069W   <NA>     Dubious open reading frame; unlikely to encode a fun~}
\CommentTok{#> 2 YAL068W-A <NA>     Dubious open reading frame; unlikely to encode a fun~}
\CommentTok{#> 3 YAL068C   PAU8     Protein of unknown function; member of the seripaupe~}
\CommentTok{#> 4 YAL067W-A <NA>     Putative protein of unknown function; identified by ~}
\CommentTok{#> 5 YAL067C   SEO1     Putative permease; member of the allantoate transpor~}
\CommentTok{#> 6 YAL066W   <NA>     Dubious open reading frame; unlikely to encode a fun~}
\end{Highlighting}
\end{Shaded}

In \texttt{gene.info}, the \texttt{ftr.name} column corresponds to the
\texttt{gene} column in our Spellman data set. The \texttt{std.name}
column gives the ``common'' gene name (not every gene has a common name
so there are lots of NAs). The \texttt{description} column gives a brief
textual description of what the gene product does.

To combine \texttt{spellmean.clean} with \texttt{gene.info} we use the
\texttt{left\_join} function defined in dplyr. As noted in the
description of the function, \texttt{left\_join(x,\ y)} returns ``all
rows from x, and all columns from x and y. Rows in x with no match in y
will have NA values in the new columns.'' In addition, we have to
specify the column to join by using the \texttt{by} argument to
\texttt{left\_join}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.merged <-}
\StringTok{  }\KeywordTok{left_join}\NormalTok{(spellman.clean, gene.info, }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"gene"}\NormalTok{ =}\StringTok{ "ftr.name"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

By default, the joined columns are merged at the end of the data frame,
so we'll reorder variables to bring the \texttt{std.name} and
\texttt{description} to the second and thirds columns, preserving the
order of all the other colums.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.merged }\OperatorTok{%<>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(gene, std.name, description, }\KeywordTok{everything}\NormalTok{())}

\NormalTok{spellman.merged}
\CommentTok{#> # A tibble: 6,178 x 76}
\CommentTok{#>    gene  std.name description alpha0 alpha7 alpha14 alpha21 alpha28 alpha35}
\CommentTok{#>    <chr> <chr>    <chr>        <dbl>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>}
\CommentTok{#>  1 YAL0~ TFC3     Subunit of~  -0.15  -0.15   -0.21    0.17   -0.42  -0.44 }
\CommentTok{#>  2 YAL0~ VPS8     Membrane-b~  -0.11   0.1     0.01    0.06    0.04  -0.26 }
\CommentTok{#>  3 YAL0~ EFB1     Translatio~  -0.14  -0.71    0.1    -0.32   -0.4   -0.580}
\CommentTok{#>  4 YAL0~ <NA>     Dubious op~  -0.02  -0.48   -0.11    0.12   -0.03   0.19 }
\CommentTok{#>  5 YAL0~ SSA1     ATPase inv~  -0.05  -0.53   -0.47   -0.06    0.11  -0.07 }
\CommentTok{#>  6 YAL0~ ERP2     Member of ~  -0.6   -0.45   -0.13    0.35   -0.01   0.49 }
\CommentTok{#>  7 YAL0~ FUN14    Integral m~  -0.28  -0.22   -0.06    0.22    0.25   0.13 }
\CommentTok{#>  8 YAL0~ SPO7     Putative r~  -0.03  -0.27    0.17   -0.12   -0.27   0.06 }
\CommentTok{#>  9 YAL0~ MDM10    Subunit of~  -0.05   0.13    0.13   -0.21   -0.45  -0.21 }
\CommentTok{#> 10 YAL0~ SWC3     Protein of~  -0.31  -0.43   -0.3    -0.23   -0.13  -0.07 }
\CommentTok{#> # ... with 6,168 more rows, and 67 more variables: alpha42 <dbl>,}
\CommentTok{#> #   alpha49 <dbl>, alpha56 <dbl>, alpha63 <dbl>, alpha70 <dbl>,}
\CommentTok{#> #   alpha77 <dbl>, alpha84 <dbl>, alpha91 <dbl>, alpha98 <dbl>,}
\CommentTok{#> #   alpha105 <dbl>, alpha112 <dbl>, alpha119 <dbl>, cdc15_10 <dbl>,}
\CommentTok{#> #   cdc15_30 <dbl>, cdc15_50 <dbl>, cdc15_70 <dbl>, cdc15_80 <dbl>,}
\CommentTok{#> #   cdc15_90 <dbl>, cdc15_100 <dbl>, cdc15_110 <dbl>, cdc15_120 <dbl>,}
\CommentTok{#> #   cdc15_130 <dbl>, cdc15_140 <dbl>, cdc15_150 <dbl>, cdc15_160 <dbl>,}
\CommentTok{#> #   cdc15_170 <dbl>, cdc15_180 <dbl>, cdc15_190 <dbl>, cdc15_200 <dbl>,}
\CommentTok{#> #   cdc15_210 <dbl>, cdc15_220 <dbl>, cdc15_230 <dbl>, cdc15_240 <dbl>,}
\CommentTok{#> #   cdc15_250 <dbl>, cdc15_270 <dbl>, cdc15_290 <dbl>, cdc28_0 <dbl>,}
\CommentTok{#> #   cdc28_10 <dbl>, cdc28_20 <dbl>, cdc28_30 <dbl>, cdc28_40 <dbl>,}
\CommentTok{#> #   cdc28_50 <dbl>, cdc28_60 <dbl>, cdc28_70 <dbl>, cdc28_80 <dbl>,}
\CommentTok{#> #   cdc28_90 <dbl>, cdc28_100 <dbl>, cdc28_110 <dbl>, cdc28_120 <dbl>,}
\CommentTok{#> #   cdc28_130 <dbl>, cdc28_140 <dbl>, cdc28_150 <dbl>, cdc28_160 <dbl>,}
\CommentTok{#> #   elu0 <dbl>, elu30 <dbl>, elu60 <dbl>, elu90 <dbl>, elu120 <dbl>,}
\CommentTok{#> #   elu150 <dbl>, elu180 <dbl>, elu210 <dbl>, elu240 <dbl>, elu270 <dbl>,}
\CommentTok{#> #   elu300 <dbl>, elu330 <dbl>, elu360 <dbl>, elu390 <dbl>}
\end{Highlighting}
\end{Shaded}

\hypertarget{reshaping-data-with-tidyr}{%
\section{Reshaping data with tidyr}\label{reshaping-data-with-tidyr}}

The \texttt{tidyr} package provides functions for reshaping or tidying
data frames. \texttt{tidyr} is yet another component of the tidyverse,
and thus was loaded by the \texttt{library(tidyverse)}.

We're going to look at two functions \texttt{tidyr::gather()} and
\texttt{tidyr::extract()}, and how they can be combined with now
familiar \texttt{dplyr} functions we've seen previously. The reading
assignment for today's class session covers a variety of other functions
defined in \texttt{tidyr}.

The Spellman data, as I provided it to you, is in what we would call
``wide'' format. Each column (besides the \texttt{gene} column)
corresponds to an experimental condition \emph{and} time point. For
example, ``alpha0'' is the alpha-factor experiment at time point 0 mins;
``alpha7'' is the alpha-factor experiment at time point 7 mins, etc. The
cells within each column correspond to the expression of a corresponding
gene (given by the first column which we renamed \texttt{gene}) in that
particular experiment at that particular time point.

In every column (except ``gene''), the cells represents the same
abstract property of interest -- the expression of a gene of interest in
a particular experiment/time point. Our first task will be to rearrange
our ``wide'' data frame that consists of many different columns
representing gene expression into a ``long'' data frame with just a
single column representing expression. We'll also create a new column to
keep track of which experiment and time point the measurement came from.

\hypertarget{wide-to-long-conversions-using-tidyrgather}{%
\subsection{\texorpdfstring{Wide to long conversions using
\texttt{tidyr::gather}}{Wide to long conversions using tidyr::gather}}\label{wide-to-long-conversions-using-tidyrgather}}

\texttt{tidyr::gather()} takes multiple columns, and collapses them
together into a smaller number of new columns. When using
\texttt{gather()} you give the names of the \emph{new} columns to
create, as well as the names of any existing columns \texttt{gather()}
should \emph{not} collect together.

Here we want to collapse all 73 or the expression columns -- ``alpha0''
to ``elu390'' -- into two columns: 1) a column to represent the
expt/time point of the measurement, and 2) a column to represent the
corresponding expression value. The column we don't want to touch are
the \texttt{gene}, \texttt{std.name}, and \texttt{description}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# convert "wide" data to "long"}
\NormalTok{spellman.long <-}
\StringTok{  }\NormalTok{spellman.merged }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(expt.and.time, expression, }\OperatorTok{-}\NormalTok{gene, }\OperatorTok{-}\NormalTok{std.name, }\OperatorTok{-}\NormalTok{description)}
\end{Highlighting}
\end{Shaded}

Take a moment to look at the data in the ``long format'':

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(spellman.long)}
\CommentTok{#> # A tibble: 6 x 5}
\CommentTok{#>   gene   std.name description                     expt.and.time expression}
\CommentTok{#>   <chr>  <chr>    <chr>                           <chr>              <dbl>}
\CommentTok{#> 1 YAL00~ TFC3     Subunit of RNA polymerase III ~ alpha0             -0.15}
\CommentTok{#> 2 YAL00~ VPS8     Membrane-binding component of ~ alpha0             -0.11}
\CommentTok{#> 3 YAL00~ EFB1     Translation elongation factor ~ alpha0             -0.14}
\CommentTok{#> 4 YAL00~ <NA>     Dubious open reading frame; un~ alpha0             -0.02}
\CommentTok{#> 5 YAL00~ SSA1     ATPase involved in protein fol~ alpha0             -0.05}
\CommentTok{#> 6 YAL00~ ERP2     Member of the p24 family invol~ alpha0             -0.6}
\end{Highlighting}
\end{Shaded}

And compare the dimensions of the wide data to the new data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(spellman.merged)  }\CommentTok{# for comparison}
\CommentTok{#> [1] 6178   76}
\KeywordTok{dim}\NormalTok{(spellman.long)}
\CommentTok{#> [1] 450994      5}
\end{Highlighting}
\end{Shaded}

As you see, we've gone from a data frame with 6178 rows and 76 columns
(wide format), to a new data frame with 450994 rows and 5 columns (long
format).

\hypertarget{extracting-information-from-combined-variables-using-tidyrextract}{%
\subsection{\texorpdfstring{Extracting information from combined
variables using
\texttt{tidyr::extract}}{Extracting information from combined variables using tidyr::extract}}\label{extracting-information-from-combined-variables-using-tidyrextract}}

The column \texttt{expt.and.time} violates one of our principles of tidy
data: ``Each variable must have its own column.''. This column conflates
two different types of information -- the experiment type and the time
point of the measurement. Our next task is to split this information up
into two new variables, which will help to facilitate downstream
plotting and analysis.

One complicating factor is that the different experiments/time
combinations have different naming conventions:

\begin{itemize}
\item
  The ``alpha'' and ``elu'' experiments are of the form ``alpha0'',
  ``alpha7'', ``elu0'', ``elu30'', etc. In this case, the first part of
  the string gives the experiment type (either alpha or elu) and the
  following digits give the time point.
\item
  In the ``cdc15'' and ``cdc28'' experiments the convention is slightly
  different; they are of the form ``cdc15\_0'', ``cdc15\_10'',
  ``cdc28\_0'', ``cdc28\_10'', etc. Here the part of the string before
  the underscore gives the experiment type, and the digits after the
  underscore give the time point.
\end{itemize}

Because of the differences in naming conventions, we will find it
easiest to break up \texttt{spellman.long} into a series of sub-data
sets corresponding to each experiment type in order to extract out the
experiment and time information. After processing each data subset
separately, we will join the modified sub-data frames back together.

\hypertarget{subsetting-rows}{%
\subsection{Subsetting rows}\label{subsetting-rows}}

Let's start by getting just the rows corresponding to the ``alpha''
experiment/times. Here we use \texttt{dplyr::filter} in combination with
\texttt{stringr::str\_detect} to get all those rows in which the
\texttt{expt.and.time} variable contains the string ``alpha''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alpha.long <-}\StringTok{ }
\StringTok{  }\NormalTok{spellman.long }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{str_detect}\NormalTok{(expt.and.time, }\StringTok{"alpha"}\NormalTok{))}

\CommentTok{# look at the new data frame}
\KeywordTok{dim}\NormalTok{(alpha.long)}
\CommentTok{#> [1] 111204      5}
\KeywordTok{head}\NormalTok{(alpha.long, }\DataTypeTok{n =} \DecValTok{10}\NormalTok{)}
\CommentTok{#> # A tibble: 10 x 5}
\CommentTok{#>    gene   std.name description                    expt.and.time expression}
\CommentTok{#>    <chr>  <chr>    <chr>                          <chr>              <dbl>}
\CommentTok{#>  1 YAL00~ TFC3     Subunit of RNA polymerase III~ alpha0             -0.15}
\CommentTok{#>  2 YAL00~ VPS8     Membrane-binding component of~ alpha0             -0.11}
\CommentTok{#>  3 YAL00~ EFB1     Translation elongation factor~ alpha0             -0.14}
\CommentTok{#>  4 YAL00~ <NA>     Dubious open reading frame; u~ alpha0             -0.02}
\CommentTok{#>  5 YAL00~ SSA1     ATPase involved in protein fo~ alpha0             -0.05}
\CommentTok{#>  6 YAL00~ ERP2     Member of the p24 family invo~ alpha0             -0.6 }
\CommentTok{#>  7 YAL00~ FUN14    Integral mitochondrial outer ~ alpha0             -0.28}
\CommentTok{#>  8 YAL00~ SPO7     Putative regulatory subunit o~ alpha0             -0.03}
\CommentTok{#>  9 YAL01~ MDM10    Subunit of both the ERMES and~ alpha0             -0.05}
\CommentTok{#> 10 YAL01~ SWC3     Protein of unknown function; ~ alpha0             -0.31}
\end{Highlighting}
\end{Shaded}

\hypertarget{splitting-columns}{%
\subsection{Splitting columns}\label{splitting-columns}}

Having subsetted the data, we can now split \texttt{expt.and.time} into
two new variables -- \texttt{expt} and \texttt{time}. To do this we use
\texttt{tidyr::extract}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alpha.long }\OperatorTok{%<>%}\StringTok{ }
\StringTok{  }\NormalTok{tidyr}\OperatorTok{::}\KeywordTok{extract}\NormalTok{(expt.and.time,     }\CommentTok{# column we're extracting from}
                 \KeywordTok{c}\NormalTok{(}\StringTok{"expt"}\NormalTok{, }\StringTok{"time"}\NormalTok{), }\CommentTok{# new columns we're creating}
                 \DataTypeTok{regex=}\StringTok{"(alpha)([[:digit:]]+)"}\NormalTok{,  }\CommentTok{# regexp (see below)}
                 \DataTypeTok{convert=}\OtherTok{TRUE}\NormalTok{)      }\CommentTok{# automatically convert column types}

\CommentTok{# }\AlertTok{NOTE}\CommentTok{: I'm being explict about saying tidyr::extract because the}
\CommentTok{# magrittr package defines a different extract function}
\end{Highlighting}
\end{Shaded}

Let's take a moment to look at the \texttt{regex} argument to
\texttt{extract} -- \texttt{regex="(alpha)({[}{[}:digit:{]}{]}+)"}. The
regex is specified as a character string. Each part we want to match
\emph{and} extract is surround by parentheses. In this case we have two
sets of parentheses corresponding to the two matches we want to make.
The first part of the regex is \texttt{(alpha)}; here we're looking to
make an exact match to the string ``alpha''. The second part of the
regex reads \texttt{({[}{[}:digit:{]}{]}+)}.
\texttt{{[}{[}:digit:{]}{]}} indicates we're looking for a numeric
digit. The \texttt{+} after \texttt{{[}{[}:digit:{]}{]}} indicates that
we want to match \emph{one or more} digits (i.e.~to get a match we need
to find at least one digit, but more than one digit should also be a
match).

Let's take a look at the new version of \texttt{alpha.long} following
application of \texttt{extract}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(alpha.long, }\DataTypeTok{n =} \DecValTok{10}\NormalTok{)}
\CommentTok{#> # A tibble: 10 x 6}
\CommentTok{#>    gene   std.name description                      expt   time expression}
\CommentTok{#>    <chr>  <chr>    <chr>                            <chr> <int>      <dbl>}
\CommentTok{#>  1 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha     0      -0.15}
\CommentTok{#>  2 YAL00~ VPS8     Membrane-binding component of t~ alpha     0      -0.11}
\CommentTok{#>  3 YAL00~ EFB1     Translation elongation factor 1~ alpha     0      -0.14}
\CommentTok{#>  4 YAL00~ <NA>     Dubious open reading frame; unl~ alpha     0      -0.02}
\CommentTok{#>  5 YAL00~ SSA1     ATPase involved in protein fold~ alpha     0      -0.05}
\CommentTok{#>  6 YAL00~ ERP2     Member of the p24 family involv~ alpha     0      -0.6 }
\CommentTok{#>  7 YAL00~ FUN14    Integral mitochondrial outer me~ alpha     0      -0.28}
\CommentTok{#>  8 YAL00~ SPO7     Putative regulatory subunit of ~ alpha     0      -0.03}
\CommentTok{#>  9 YAL01~ MDM10    Subunit of both the ERMES and t~ alpha     0      -0.05}
\CommentTok{#> 10 YAL01~ SWC3     Protein of unknown function; co~ alpha     0      -0.31}
\end{Highlighting}
\end{Shaded}

Notice our two new variables, both of which have appropriate types!

A data frame for the elutriation data can be created similarly:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elu.long <-}
\StringTok{  }\NormalTok{spellman.long }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{str_detect}\NormalTok{(expt.and.time, }\StringTok{"elu"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{tidyr}\OperatorTok{::}\KeywordTok{extract}\NormalTok{(expt.and.time,     }\CommentTok{# column we're extracting from}
                 \KeywordTok{c}\NormalTok{(}\StringTok{"expt"}\NormalTok{, }\StringTok{"time"}\NormalTok{), }\CommentTok{# new columns we're creating}
                 \DataTypeTok{regex=}\StringTok{"(elu)([[:digit:]]+)"}\NormalTok{,  }\CommentTok{# regexp (see below)}
                 \DataTypeTok{convert=}\OtherTok{TRUE}\NormalTok{)      }\CommentTok{# automatically convert column types}
\end{Highlighting}
\end{Shaded}

\hypertarget{a-fancier-regex-for-the-cdc-experiments}{%
\subsubsection{A fancier regex for the cdc
experiments}\label{a-fancier-regex-for-the-cdc-experiments}}

Now let's process the cdc experiments (cdc15 and cdc28). As before we
extract the corresponding rows of the data frame using \texttt{filter}
and \texttt{str\_detect}. We then split \texttt{expt.and.time} using
\texttt{tidyr::extract}. In this case we carry out the two steps in a
single code block using pipes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cdc.long <-}\StringTok{ }
\StringTok{  }\NormalTok{spellman.long }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# both cdc15 and cdc28 contain "cdc" as a sub-string}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{str_detect}\NormalTok{(expt.and.time, }\StringTok{"cdc"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{tidyr}\OperatorTok{::}\KeywordTok{extract}\NormalTok{(expt.and.time, }
                 \KeywordTok{c}\NormalTok{(}\StringTok{"expt"}\NormalTok{, }\StringTok{"time"}\NormalTok{), }
                 \DataTypeTok{regex=}\StringTok{"(cdc15|cdc28)_([[:digit:]]+)"}\NormalTok{, }\CommentTok{# note the fancier regex}
                 \DataTypeTok{convert=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The regex -- \texttt{"(cdc15\textbar{}cdc28)\_({[}{[}:digit:{]}{]}+)"}
-- is slightly fancier in this example. As before there are two parts
we're extracting: \texttt{(cdc15\textbar{}cdc28)} and
\texttt{({[}{[}:digit:{]}{]}+)}. The first parenthesized regexp is an
``OR'' -- i.e.~match ``cdc15'' \emph{or} ``cdc28''. The second
parenthesized regexp is the same as we saw previously. Separating the
two parenthesized regexps is an underscore (\texttt{\_}). The underscore
isn't parenthesized because we only want to use it to make a match
\emph{not} to extract the corresponding match.

\hypertarget{combining-data-frames}{%
\subsection{Combining data frames}\label{combining-data-frames}}

If you have two or more data frames with identical columns, the rows of
the data frames can be combined into a single data frame using
\texttt{rbind} (defined in the \texttt{base} package). For example, to
reassemble the \texttt{alpha.long}, \texttt{elu.long}, and
\texttt{cdc.long} data frames into a single data frame we do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.final <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(alpha.long, elu.long, cdc.long)}

\CommentTok{# check the dimensions of the new data frame}
\KeywordTok{dim}\NormalTok{(spellman.final)}
\CommentTok{#> [1] 450994      6}
\end{Highlighting}
\end{Shaded}

\hypertarget{sorting-data-frame-rows}{%
\subsection{Sorting data frame rows}\label{sorting-data-frame-rows}}

Currently the \texttt{spellman.final} data frame is sorted by time point
and experiment.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(spellman.final, }\DataTypeTok{n =} \DecValTok{10}\NormalTok{)}
\CommentTok{#> # A tibble: 10 x 6}
\CommentTok{#>    gene   std.name description                      expt   time expression}
\CommentTok{#>    <chr>  <chr>    <chr>                            <chr> <int>      <dbl>}
\CommentTok{#>  1 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha     0      -0.15}
\CommentTok{#>  2 YAL00~ VPS8     Membrane-binding component of t~ alpha     0      -0.11}
\CommentTok{#>  3 YAL00~ EFB1     Translation elongation factor 1~ alpha     0      -0.14}
\CommentTok{#>  4 YAL00~ <NA>     Dubious open reading frame; unl~ alpha     0      -0.02}
\CommentTok{#>  5 YAL00~ SSA1     ATPase involved in protein fold~ alpha     0      -0.05}
\CommentTok{#>  6 YAL00~ ERP2     Member of the p24 family involv~ alpha     0      -0.6 }
\CommentTok{#>  7 YAL00~ FUN14    Integral mitochondrial outer me~ alpha     0      -0.28}
\CommentTok{#>  8 YAL00~ SPO7     Putative regulatory subunit of ~ alpha     0      -0.03}
\CommentTok{#>  9 YAL01~ MDM10    Subunit of both the ERMES and t~ alpha     0      -0.05}
\CommentTok{#> 10 YAL01~ SWC3     Protein of unknown function; co~ alpha     0      -0.31}
\end{Highlighting}
\end{Shaded}

It might be useful instead to sort by gene and experiment. To do this we
can use \texttt{dplyr::arrange}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.final }\OperatorTok{%<>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(gene, expt)}

\CommentTok{# look again at the rearranged data}
\KeywordTok{head}\NormalTok{(spellman.final, }\DataTypeTok{n =} \DecValTok{10}\NormalTok{)}
\CommentTok{#> # A tibble: 10 x 6}
\CommentTok{#>    gene   std.name description                      expt   time expression}
\CommentTok{#>    <chr>  <chr>    <chr>                            <chr> <int>      <dbl>}
\CommentTok{#>  1 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha     0      -0.15}
\CommentTok{#>  2 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha     7      -0.15}
\CommentTok{#>  3 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha    14      -0.21}
\CommentTok{#>  4 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha    21       0.17}
\CommentTok{#>  5 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha    28      -0.42}
\CommentTok{#>  6 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha    35      -0.44}
\CommentTok{#>  7 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha    42      -0.15}
\CommentTok{#>  8 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha    49       0.24}
\CommentTok{#>  9 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha    56      -0.1 }
\CommentTok{#> 10 YAL00~ TFC3     Subunit of RNA polymerase III t~ alpha    63      NA}
\end{Highlighting}
\end{Shaded}

\hypertarget{using-your-tidy-data}{%
\section{Using your tidy data}\label{using-your-tidy-data}}

Whew -- that was a fair amount of work to tidy our data! But having done
so we can now carry out a wide variety of very powerful analyses.

\hypertarget{visualizing-gene-expression-time-series}{%
\subsection{Visualizing gene expression time
series}\label{visualizing-gene-expression-time-series}}

Let's start by walking through a series of visualizations of gene
expression time series. Each plot will show the expression of one or
more genes, at different time points, in one or more experimental
conditions. Our initial visualizations exploit the ``long'' versions of
the tidy data.

First a single gene in a single experimental condition:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.final }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(expt }\OperatorTok{==}\StringTok{ "alpha"}\NormalTok{, gene }\OperatorTok{==}\StringTok{ "YAL022C"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time (mins)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Expression of YAL022C"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-272-1.pdf}

We can easily modify the above code block to visualize the expression of
multiple genes of interest:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{genes.of.interest <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"YAL022C"}\NormalTok{, }\StringTok{"YAR018C"}\NormalTok{, }\StringTok{"YGR188C"}\NormalTok{)}

\NormalTok{spellman.final }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{genes.of.interest, expt }\OperatorTok{==}\StringTok{ "alpha"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression, }\DataTypeTok{color =}\NormalTok{ gene)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time (mins)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Normalized expression"}\NormalTok{,}
         \DataTypeTok{title =} \StringTok{"Expression of multiple genes}\CharTok{\textbackslash{}n}\StringTok{following synchronization by alpha factor"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-273-1.pdf}

By employing \texttt{facet\_wrap()} we can visualize the relationship
between this set of genes in each of the experiment types:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.final }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{genes.of.interest) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression, }\DataTypeTok{color =}\NormalTok{ gene)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{expt) }\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time (mins)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Normalized expression"}\NormalTok{,}
         \DataTypeTok{title =} \StringTok{"Expression of Multiple Genes}\CharTok{\textbackslash{}n}\StringTok{Across experiments"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-274-1.pdf}

The different experimental treatments were carried out for varying
lengths of time due to the differences in their physiological effects.
Plotting them all on the same time scale can obscure that patterns of
oscillation we might be interested in, so let's modify our code block so
that plots that share the same y-axis, but have differently scaled
x-axes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.final }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{genes.of.interest) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression, }\DataTypeTok{color =}\NormalTok{ gene)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{expt, }\DataTypeTok{scales =} \StringTok{"free_x"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time (mins)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Normalized expression"}\NormalTok{,}
         \DataTypeTok{title =} \StringTok{"Expression of Multiple Genes}\CharTok{\textbackslash{}n}\StringTok{Across experiments"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-275-1.pdf}

\hypertarget{finding-the-most-variable-genes}{%
\subsection{Finding the most variable
genes}\label{finding-the-most-variable-genes}}

When dealing with vary large data sets, one ad hoc filtering criteria
that is often employed is to focus on those variables that exhibit that
greatest variation (variation is measure of the spread of data; we will
give a precise definition in a later lecture). To do this, we first need
to order our variables (genes) by their variation. Let's see how we can
accomplish this using our long data frame:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{by.variance <-}
\StringTok{  }\NormalTok{spellman.final }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(gene) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{expression.var =} \KeywordTok{var}\NormalTok{(expression, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(expression.var))}

\KeywordTok{head}\NormalTok{(by.variance)}
\CommentTok{#> # A tibble: 6 x 2}
\CommentTok{#>   gene    expression.var}
\CommentTok{#>   <chr>            <dbl>}
\CommentTok{#> 1 YLR286C          2.157}
\CommentTok{#> 2 YNR067C          1.733}
\CommentTok{#> 3 YNL327W          1.653}
\CommentTok{#> 4 YGL028C          1.571}
\CommentTok{#> 5 YHL028W          1.521}
\CommentTok{#> 6 YKL164C          1.515}
\end{Highlighting}
\end{Shaded}

The code above calculates the variance of each gene but ignores the fact
that we have different experimental conditions. To take into account the
experimental design of the data at hand, let's calculate the average
variance across the experimental conditions:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{by.avg.variance <-}
\StringTok{  }\NormalTok{spellman.final }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(gene, expt) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{expression.var =} \KeywordTok{var}\NormalTok{(expression, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(gene) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{avg.expression.var =} \KeywordTok{mean}\NormalTok{(expression.var)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(avg.expression.var))}

\KeywordTok{head}\NormalTok{(by.avg.variance)}
\CommentTok{#> # A tibble: 6 x 2}
\CommentTok{#>   gene    avg.expression.var}
\CommentTok{#>   <chr>                <dbl>}
\CommentTok{#> 1 YFR014C              3.579}
\CommentTok{#> 2 YFR053C              2.377}
\CommentTok{#> 3 YBL032W              2.299}
\CommentTok{#> 4 YDR274C              2.173}
\CommentTok{#> 5 YLR286C              2.128}
\CommentTok{#> 6 YMR206W              1.937}
\end{Highlighting}
\end{Shaded}

Based on the average experession variance across experimental
conditions, let's get the names of the 1000 most variable genes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top.genes}\FloatTok{.1}\NormalTok{k <-}\StringTok{ }\NormalTok{by.avg.variance[}\DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{,]}\OperatorTok{$}\NormalTok{gene}

\KeywordTok{head}\NormalTok{(top.genes}\FloatTok{.1}\NormalTok{k)}
\CommentTok{#> [1] "YFR014C" "YFR053C" "YBL032W" "YDR274C" "YLR286C" "YMR206W"}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-wrangling-part-ii}{%
\chapter{Data wrangling, Part II}\label{data-wrangling-part-ii}}

In our last class session we walked through a complex, data wrangling
pipeline involving a genome-wide gene expression data set. Starting with
the raw data, we demonstrated several cleaning, transformation, and
reshaping steps that resulted in a data set that allowed us to examine
how gene expression changed over time across multiple experimental
conditions. The final form of our data was what we referred to as a
``long'' format. The key variables of the final data frame were
\texttt{gene}, \texttt{expt}, \texttt{time}, and \texttt{expression}.
The structure of this long data frame facilitated the creation of time
series plots, filtering by gene and/or condition, grouping operations by
gene, etc.

In today's session we're going to demonstrate a new type of
visualization called a ``heat map'' that is useful for high dimensional
data. Then we'll show how to go convert our ``long'' data frame to a
``wide'' data frame, and show how this wide data frame facilitates
analyses focused on how gene expression changes in concert (covary).
We'll also show how we can combine our long and wide views of the data
to create new insights into interesting patterns in the data.

\hypertarget{libraries-3}{%
\section{Libraries}\label{libraries-3}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(magrittr)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-1}{%
\section{Data}\label{data-1}}

So we don't have to re-create our previous analysis, I've posted a CSV
file with the ``long'' version of the cleaned Spellman data set at the
link given below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.long <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/spellman-long.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's remind ourselves of the basic structure of this data frame:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(spellman.long)}
\CommentTok{#> # A tibble: 6 x 4}
\CommentTok{#>   gene    expt   time expression}
\CommentTok{#>   <chr>   <chr> <int>      <dbl>}
\CommentTok{#> 1 YAL001C alpha     0      -0.15}
\CommentTok{#> 2 YAL002W alpha     0      -0.11}
\CommentTok{#> 3 YAL003W alpha     0      -0.14}
\CommentTok{#> 4 YAL004W alpha     0      -0.02}
\CommentTok{#> 5 YAL005C alpha     0      -0.05}
\CommentTok{#> 6 YAL007C alpha     0      -0.6}
\KeywordTok{dim}\NormalTok{(spellman.long)}
\CommentTok{#> [1] 450994      4}
\end{Highlighting}
\end{Shaded}

There are just four columns (variables) in this data set, but more than
450,000 rows, representing all the various combinations of genes
(\textgreater{}6000), experimental conditions (4), and time points
(variable across experiments).

\hypertarget{heat-maps}{%
\section{Heat maps}\label{heat-maps}}

In our prior visualizations we've used line plots to depict how gene
expression changes over time. For example here are line plots for 15
genes in the data set, in the cdc28 experimental conditions:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{genes.of.interest <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"YHR084W"}\NormalTok{, }\StringTok{"YBR083W"}\NormalTok{, }\StringTok{"YPL049C"}\NormalTok{, }\StringTok{"YDR480W"}\NormalTok{,}
                       \StringTok{"YGR040W"}\NormalTok{, }\StringTok{"YLR229C"}\NormalTok{, }\StringTok{"YDL159W"}\NormalTok{, }\StringTok{"YBL016W"}\NormalTok{,}
                       \StringTok{"YDR103W"}\NormalTok{, }\StringTok{"YJL157C"}\NormalTok{, }\StringTok{"YNL271C"}\NormalTok{, }\StringTok{"YDR461W"}\NormalTok{,}
                       \StringTok{"YHL007C"}\NormalTok{, }\StringTok{"YHR005C"}\NormalTok{, }\StringTok{"YJR086W"}\NormalTok{)}

\NormalTok{spellman.long }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(expt }\OperatorTok{==}\StringTok{ "cdc28"}\NormalTok{, gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{genes.of.interest) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression, }\DataTypeTok{color=}\NormalTok{gene)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time (min)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Expression"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-282-1.pdf}

Even with just 10 overlapping line plots, this figure is quite busy and
it's hard to make out the individual behavior of each gene.

An alternative approach to depicting such data is a ``heat map'' which
depicts the same information in a grid like form, with the expression
values indicated by color. Heat maps are good for depicting large
amounts of data and providing a coarse ``10,000 foot view''. We can
create a heat map using \texttt{geom\_tile} as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.long }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(expt }\OperatorTok{==}\StringTok{ "cdc28"}\NormalTok{, gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{genes.of.interest) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ gene)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_tile}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ expression)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Time (mins)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-283-1.pdf}

This figure represents the same information as our line plot, but now
there is row for each gene, and the expression of that gene at a given
time point is represented by color (scale given on the right). Missing
data is shown as gray boxes. Unfortunately, the default color scale used
by ggplot is a very subtle gradient from light to dark blue. This make
it hard to distinguish patterns of change. Let's now see how we can
improve that.

\hypertarget{better-color-schemes-with-rcolorbrewer}{%
\subsection{Better color schemes with
RColorBrewer}\label{better-color-schemes-with-rcolorbrewer}}

The \texttt{RColorBrewer} packages provides nice color schemes that are
useful for creating heat maps. RColorBrewer defines a set of color
palettes that have been optimized for color discrimination, many of
which are color blind friendly, etc. Install the RColorBrewer package
using the command line or the RStudio GUI.

Once you've installed the RColorBrewer package you can see the available
color palettes as so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(RColorBrewer)}

\CommentTok{# show representations of the palettes}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{cex =} \FloatTok{0.5}\NormalTok{) }\CommentTok{# reduce size of text in the following plot}
\KeywordTok{display.brewer.all}\NormalTok{()  }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-284-1.pdf}

We'll use the Red-to-Blue (``RdBu'') color scheme defined in
RColorBrewer, however we'll reverse the scheme so blues represent low
expression and reds represent high expression. We'll divide the range of
color values into 9 discrete bins.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# displays the RdBu color scheme divided into a paletee of 9 colors}
\KeywordTok{display.brewer.pal}\NormalTok{(}\DecValTok{9}\NormalTok{, }\StringTok{"RdBu"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-285-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{# assign the reversed (blue to red) RdBu palette}
\NormalTok{color.scheme <-}\StringTok{ }\KeywordTok{rev}\NormalTok{(}\KeywordTok{brewer.pal}\NormalTok{(}\DecValTok{9}\NormalTok{,}\StringTok{"RdBu"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Now let's regenerate the heat map we created previously with this new
color scheme. To do this we specify a gradient color scale using the
\texttt{scale\_fill\_gradientn()} function from ggplot. In addition to
specifying the color scale, we also constrain the limits of the scale to
insure it's symmetric about zero.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.long }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(expt }\OperatorTok{==}\StringTok{ "cdc28"}\NormalTok{, gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{genes.of.interest) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ gene)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_tile}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ expression)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{scale_fill_gradientn}\NormalTok{(}\DataTypeTok{colors=}\NormalTok{color.scheme,}
                         \DataTypeTok{limits =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\FloatTok{2.5}\NormalTok{, }\FloatTok{2.5}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Time (mins)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-286-1.pdf}

\hypertarget{looking-for-patterns-using-sorted-data-and-heat-maps}{%
\subsection{Looking for patterns using sorted data and heat
maps}\label{looking-for-patterns-using-sorted-data-and-heat-maps}}

The real power of heat maps becomes apparent when you you rearrange the
rows of the heat map to emphasize patterns of interest.

For example, let's create a heat map in which we sort genes by the time
of their maximal expression. This is one way to identify genes that
reach their peak expression at similar times, which is one criteria one
might use to identify genes acting in concert.

For simplicities sake we will restrict our attention to the cdc28
experiment, and only consider the 1000 most variables genes with no more
than one missing observation in this experimental condition.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cdc28 <-}
\StringTok{  }\NormalTok{spellman.long }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(expt }\OperatorTok{==}\StringTok{ "cdc28"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(gene) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(expression)) }\OperatorTok{<=}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{ungroup   }\CommentTok{# removes grouping information from data frame}

\NormalTok{top1k.genes <-}
\StringTok{  }\NormalTok{cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(gene) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{expression.var =} \KeywordTok{var}\NormalTok{(expression, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(expression.var)) }\OperatorTok{%$%}
\StringTok{  }\NormalTok{gene[}\DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{]}
    
\NormalTok{top1k.cdc28 <-}\StringTok{ }
\StringTok{  }\NormalTok{cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{top1k.genes)}
\end{Highlighting}
\end{Shaded}

To find the time of maximum expression we'll employ the function
\texttt{which.max} (\texttt{which.min}), which finds the index of the
maximum (minimum) element of a vector. For example to find the index of
the maximum expression measurement for YAR018C we could do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top1k.cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{==}\StringTok{ "YAR018C"}\NormalTok{) }\OperatorTok{%$%}\StringTok{  }\CommentTok{# note the exposition pipe operator!}
\StringTok{  }\KeywordTok{which.max}\NormalTok{(expression)}
\CommentTok{#> [1] 8}
\end{Highlighting}
\end{Shaded}

From the code above we find that the index of the observation at which
YAR018C is maximal at 8. To get the corresponding time point we can do
something like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top1k.cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{==}\StringTok{ "YAR018C"}\NormalTok{) }\OperatorTok{%$%}\StringTok{  }\CommentTok{# again note the exposition pipe operator!}
\StringTok{  }\NormalTok{time[}\KeywordTok{which.max}\NormalTok{(expression)]}
\CommentTok{#> [1] 70}
\end{Highlighting}
\end{Shaded}

Thus YAR018C expression peaks at 70 minutes in the cdc28 experiment.

To find the index of maximal expression of all genes we can apply the
\texttt{dplyr::group\_by()} and \texttt{dplyr::summarize()} functions

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{peak.expression.cdc28 <-}\StringTok{ }
\StringTok{  }\NormalTok{top1k.cdc28 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(gene) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{peak =} \KeywordTok{which.max}\NormalTok{(expression))}

\KeywordTok{head}\NormalTok{(peak.expression.cdc28)}
\CommentTok{#> # A tibble: 6 x 2}
\CommentTok{#>   gene       peak}
\CommentTok{#>   <chr>     <int>}
\CommentTok{#> 1 YAL003W      10}
\CommentTok{#> 2 YAL005C       2}
\CommentTok{#> 3 YAL022C      17}
\CommentTok{#> 4 YAL028W       5}
\CommentTok{#> 5 YAL035C-A    12}
\CommentTok{#> 6 YAL038W      15}
\end{Highlighting}
\end{Shaded}

Let's sort the order of genes by their peak expression:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{peak.expression.cdc28 }\OperatorTok{%<>%}\StringTok{ }\KeywordTok{arrange}\NormalTok{(peak)}
\end{Highlighting}
\end{Shaded}

We can then generate a heatmap where we sort the rows (genes) of the
heatmap by their time of peak expression. We introduce a new geom --
\texttt{geom\_raster} -- which is like \texttt{geom\_tile} but better
suited for large data (hundreds to thousands of rows)

The explicit sorting of the data by peak expression is carried out in
the call to \texttt{scale\_y\_discrete()} where the limits (and order)
of this axis are set with the \texttt{limits} argument (see
\texttt{scale\_y\_discrete} and \texttt{discrete\_scale} in the ggplot2
docs).

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{# we reverse the ordering because geom_raster (and geom_tile)}
\CommentTok{# draw from the bottom row up, whereas we want to depict the}
\CommentTok{# earliest peaking genes at the top of the figure}
\NormalTok{gene.ordering <-}\StringTok{ }\KeywordTok{rev}\NormalTok{(peak.expression.cdc28}\OperatorTok{$}\NormalTok{gene)}

\NormalTok{top1k.cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ gene)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_raster}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ expression)) }\OperatorTok{+}\StringTok{  }\CommentTok{# }
\StringTok{  }\KeywordTok{scale_fill_gradientn}\NormalTok{(}\DataTypeTok{limits=}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\FloatTok{2.5}\NormalTok{, }\FloatTok{2.5}\NormalTok{),}
                       \DataTypeTok{colors=}\NormalTok{color.scheme) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_y_discrete}\NormalTok{(}\DataTypeTok{limits=}\NormalTok{gene.ordering) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time (mins)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Genes"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"1000 most variable genes"}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"Sorted by time of peak expression"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\CommentTok{# the following line suppresses tick and labels on y-axis}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.text.y =} \KeywordTok{element_blank}\NormalTok{(), }\DataTypeTok{axis.ticks.y =} \KeywordTok{element_blank}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{bio304-book_files/figure-latex/unnamed-chunk-292-1} 

}

\caption{A Heatmap showing genes in the cdc28 experiment, sorted by peak expression}\label{fig:unnamed-chunk-292}
\end{figure}

The brightest red regions in each row of the heat map correspond to the
times of peak expression, and the sorting of the rows helps to highlight
those gene whose peak expression times are similar.

\hypertarget{long-to-wide-conversion-using-tidyrspread}{%
\section{\texorpdfstring{Long-to-wide conversion using
\texttt{tidyr::spread}}{Long-to-wide conversion using tidyr::spread}}\label{long-to-wide-conversion-using-tidyrspread}}

Our long data frame consists of four variables -- \texttt{gene},
\texttt{expt}, \texttt{time}, and \texttt{expression}. This made it easy
to create visualizations and summaries where time and expression were
the primaries variables of interest, and gene and experiment type were
categories we could condition on.

To facilitate analyses that emphasize comparison between genes, we want
to create a new data frame in which each gene is itself treated as a
variable of interest along with time, and experiment type remains a
categorical variable. In this new data frame rather than just four
columns in our data frame, we'll have several thousand columns -- one
for each gene.

To accomplish this reshaping of data, we'll use the function
\texttt{tidyr::spread()}. \texttt{tidyr::spread()} is the inverse of
\texttt{tidyr::gather()}. \texttt{gather()} took multiple columns and
collapsed them together into a smaller number of new columns. The
\texttt{tidyr} documentation calls this ``collapsing into key-value
pairs''. By contrast, \texttt{spread()} creates new columns by spreading
``key-value pairs'' (a column representing the ``keys'' and a column
reprsenting the ``values'') into multiple columns.

Here let's use \texttt{spread()} to use the gene names (the ``key'') and
expression measures (the ``values'') to create a new data frame where
the genes are the primary variables (columns) of the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.wide <-}
\StringTok{  }\NormalTok{spellman.long }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{spread}\NormalTok{(gene, expression)}
\end{Highlighting}
\end{Shaded}

Now let's examine the dimensions of this wide version of the data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(spellman.wide)}
\CommentTok{#> [1]   73 6180}
\end{Highlighting}
\end{Shaded}

And here's a visual view of the first few rows and columns of the wide
data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.wide[}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{8}\NormalTok{]}
\CommentTok{#> # A tibble: 5 x 8}
\CommentTok{#>   expt   time YAL001C YAL002W YAL003W YAL004W YAL005C YAL007C}
\CommentTok{#>   <chr> <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>}
\CommentTok{#> 1 alpha     0   -0.15   -0.11   -0.14   -0.02   -0.05   -0.6 }
\CommentTok{#> 2 alpha     7   -0.15    0.1    -0.71   -0.48   -0.53   -0.45}
\CommentTok{#> 3 alpha    14   -0.21    0.01    0.1    -0.11   -0.47   -0.13}
\CommentTok{#> 4 alpha    21    0.17    0.06   -0.32    0.12   -0.06    0.35}
\CommentTok{#> 5 alpha    28   -0.42    0.04   -0.4    -0.03    0.11   -0.01}
\end{Highlighting}
\end{Shaded}

From this view we infer that the rows of the data set represent the
various combination of experimental condition and time points, and the
columns represents the 6178 genes in the data set plus the two columns
for \texttt{expt} and \texttt{time}.

\hypertarget{exploring-bivariate-relationships-using-wide-data}{%
\section{Exploring bivariate relationships using ``wide''
data}\label{exploring-bivariate-relationships-using-wide-data}}

The ``long'' version of our data frame proved useful for exploring how
gene expression changed over time. By contrast, our ``wide'' data frame
is more convient for exploring how pairs of genes covary together. For
example, we can generate bivariate scatter plots depicting the
relationship between two genes of interest:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{two.gene.plot <-}
\StringTok{  }\NormalTok{spellman.wide }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(YAR018C) }\OperatorTok{&}\StringTok{ }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(YAL022C)) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# remove NAs}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ YAR018C, }\DataTypeTok{y =}\NormalTok{ YAL022C)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{aspect.ratio =} \DecValTok{1}\NormalTok{)}

\NormalTok{two.gene.plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-296-1.pdf}

From the scatter plot we infer that the two genes are ``positively
correlated'' with each other, meaning that high values of one tend to be
associated with high values of the other (and the same for low values).

We can easily extend this visualization to facet the plot based on the
experimental conditions:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{two.gene.plot }\OperatorTok{+}\StringTok{ }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{expt, }\DataTypeTok{nrow =} \DecValTok{2}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-297-1.pdf}

A statistic we use to measure the degree of association between pairs of
continuous variables is called the ``correlation coefficient''. Briefly,
correlation is a measure of linear association between a pair of
variables, and ranges from -1 to 1. A value near zero indicates the
variables are uncorrelated (no linear association), while values
approaching +1 indicate a strong positive association (the variables
tend to get bigger or smaller together) while values near -1 indicate
strong negative association (when one variable is larger, the other
tends to be small).

Let's calculate the correlation between YAR018C and YAL022C:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.wide }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(YAR018C) }\OperatorTok{&}\StringTok{ }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(YAL022C)) }\OperatorTok{%>%}\StringTok{  }
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{cor =} \KeywordTok{cor}\NormalTok{(YAR018C, YAL022C))}
\CommentTok{#> # A tibble: 1 x 1}
\CommentTok{#>      cor}
\CommentTok{#>    <dbl>}
\CommentTok{#> 1 0.6915}
\end{Highlighting}
\end{Shaded}

The value of the correlation coefficient for YAR018C and YAL022C,
\textasciitilde{}0.69, indicates a fairly strong association between the
two genes.

As we did for our visualization, we can also calculate the correlation
coefficients for the two genes under each experimental condition:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spellman.wide }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(YAR018C) }\OperatorTok{&}\StringTok{ }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(YAL022C)) }\OperatorTok{%>%}\StringTok{  }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(expt) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{cor =} \KeywordTok{cor}\NormalTok{(YAR018C, YAL022C))}
\CommentTok{#> # A tibble: 4 x 2}
\CommentTok{#>   expt     cor}
\CommentTok{#>   <chr>  <dbl>}
\CommentTok{#> 1 alpha 0.6341}
\CommentTok{#> 2 cdc15 0.5751}
\CommentTok{#> 3 cdc28 0.8474}
\CommentTok{#> 4 elu   0.7867}
\end{Highlighting}
\end{Shaded}

This table suggests that the the strength of correlation between YAR018C
and YAL022C may depend on the experimental conditions, with the highest
correlations evident in the cdc28 and elu experiments.

\hypertarget{large-scale-patterns-of-correlations}{%
\subsection{Large scale patterns of
correlations}\label{large-scale-patterns-of-correlations}}

Now we'll move from considering the correlation between two specific
genes to looking at the correlation between many pairs of genes. As we
did in the previous section, we'll focus specifically onthe 1000 most
variable genes in the cdc28 experiment.

First we filter our wide data set to only consider the cdc28 experiment
and those genes in the top 1000 most variable genes in cdc28:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top1k.cdc28.wide <-}\StringTok{ }
\StringTok{  }\NormalTok{top1k.cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{spread}\NormalTok{(gene, expression)}
\end{Highlighting}
\end{Shaded}

With this restricted data set, we can then calculate the correlations
between every pair of genes as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cdc28.correlations <-}\StringTok{ }
\StringTok{  }\NormalTok{top1k.cdc28.wide }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{expt, }\OperatorTok{-}\NormalTok{time)  }\OperatorTok{%>%}\StringTok{ }\CommentTok{# drop expt and time}
\StringTok{  }\KeywordTok{cor}\NormalTok{(}\DataTypeTok{use =} \StringTok{"pairwise.complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The argument \texttt{use\ =\ "pairwise.complete.obs"} tells the
correlation function that for each pair of genes to use only the pariwse
where there is a value for both genes (i.e.~neither one can be NA).

Given \(n\) genes, there are \(n \times n\) pairs of correlations, as
seen by the dimensions of the correlation matrix.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(cdc28.correlations)}
\CommentTok{#> [1] 1000 1000}
\end{Highlighting}
\end{Shaded}

To get the correlations with a gene of interest, we can index with the
gene name on the rows of the correlation matrix. For example, to get the
correlations between the gene YAR018C and the first 10 genes in the top
1000 set:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cdc28.correlations[}\StringTok{"YAR018C"}\NormalTok{,}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]  }
\CommentTok{#>     YAL003W     YAL005C     YAL022C     YAL028W   YAL035C-A     YAL038W }
\CommentTok{#>  0.07100626 -0.53315493  0.84741624  0.33379901 -0.22316755 -0.03984599 }
\CommentTok{#>     YAL044C     YAL048C     YAL060W     YAL062W }
\CommentTok{#>  0.32253692  0.12220221  0.49445700 -0.60972118}
\end{Highlighting}
\end{Shaded}

In the next statement we extract the names of the genes that have
correlations with YAR018C greater than 0.6. First we test genes to see
if they have a correlation with YAR018C greater than 0.6, which returns
a vector of TRUE or FALSE values. This vector of Boolean values is than
used to index into the rownames of the correlation matrix, pulling out
the gene names where the statement was true.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pos.corr.YAR018C <-}\StringTok{ }\KeywordTok{rownames}\NormalTok{(cdc28.correlations)[cdc28.correlations[}\StringTok{"YAR018C"}\NormalTok{,] }\OperatorTok{>}\StringTok{ }\FloatTok{0.6}\NormalTok{]}
\KeywordTok{length}\NormalTok{(pos.corr.YAR018C)}
\CommentTok{#> [1] 65}
\end{Highlighting}
\end{Shaded}

We then return to our long data to show this set of genes that are
strongly positively correlated with YAR018C.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top1k.cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{pos.corr.YAR018C) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression, }\DataTypeTok{group =}\NormalTok{ gene)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.33}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-305-1.pdf}

As is expected, genes with strong positive correlations with YAR018C.
show similar temporal patterns with YAR018C.

We can similarly filter for genes that have negative correlations with
YAR018C.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{neg.corr.YAR018C <-}\StringTok{ }\KeywordTok{colnames}\NormalTok{(cdc28.correlations)[cdc28.correlations[}\StringTok{"YAR018C"}\NormalTok{,] }\OperatorTok{<=}\StringTok{ }\FloatTok{-0.6}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

As before we generate a line plot showing these genes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top1k.cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{neg.corr.YAR018C) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression, }\DataTypeTok{group =}\NormalTok{ gene)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.33}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-307-1.pdf}

\hypertarget{adding-new-columns-and-combining-filtered-data-frames}{%
\subsection{Adding new columns and combining filtered data
frames}\label{adding-new-columns-and-combining-filtered-data-frames}}

Now let's create a new data frame by: 1) filtering on our list of genes
that have strong positive and negative correlations with YAR018C; and 2)
creating a new variable, ``corr.with.YAR018C'', which indicates the sign
of the correlation. We'll use this new variable to group genes when we
create the plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pos.corr.df <-}\StringTok{ }
\StringTok{  }\NormalTok{top1k.cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{pos.corr.YAR018C) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{corr.with.YAR018C =} \StringTok{"positive"}\NormalTok{)}

\NormalTok{neg.corr.df <-}\StringTok{ }
\StringTok{  }\NormalTok{top1k.cdc28 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{neg.corr.YAR018C) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{corr.with.YAR018C =} \StringTok{"negative"}\NormalTok{)}

\NormalTok{combined.pos.neg <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(pos.corr.df, neg.corr.df)}
\end{Highlighting}
\end{Shaded}

Finally, we plot the data, colored according to the correlation with
YAR018C:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(combined.pos.neg, }
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression,  }\DataTypeTok{group =}\NormalTok{ gene,}
           \DataTypeTok{color =}\NormalTok{ corr.with.YAR018C)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{alpha=}\FloatTok{0.25}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression),}
            \DataTypeTok{data =} \KeywordTok{filter}\NormalTok{(top1k.cdc28, gene }\OperatorTok{==}\StringTok{ "YAR018C"}\NormalTok{),}
            \DataTypeTok{color =} \StringTok{"DarkRed"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{2}\NormalTok{,}\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\CommentTok{# changes legend title and values for color sclae}
\StringTok{  }\KeywordTok{scale_color_manual}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Correlation with YAR018C"}\NormalTok{,}
                       \DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{))  }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Genes strongly positively and negatively correlated with YAR018C"}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"YAR018C shown in dark red"}\NormalTok{,}
       \DataTypeTok{x =} \StringTok{"Time (mins)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Expression"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-309-1.pdf}

\hypertarget{a-heat-mapped-sorted-by-correlations}{%
\subsection{A heat mapped sorted by
correlations}\label{a-heat-mapped-sorted-by-correlations}}

In our previous heat map example figure, we sorted genes according to
peak expression. Now let's generate a heat map for the genes that are
strongly correlated (both positive and negative) with YAR018C. We will
sort the genes according to the sign of their correlation.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# re-factor gene names so positive and negative genes are spatially distinct in plot}
\NormalTok{combined.pos.neg}\OperatorTok{$}\NormalTok{gene <-}\StringTok{ }
\StringTok{  }\KeywordTok{factor}\NormalTok{(combined.pos.neg}\OperatorTok{$}\NormalTok{gene, }
         \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(pos.corr.YAR018C, neg.corr.YAR018C))}

\NormalTok{combined.pos.neg }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ gene)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_tile}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ expression)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{scale_fill_gradientn}\NormalTok{(}\DataTypeTok{colors=}\NormalTok{color.scheme) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Time (mins)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-310-1.pdf}

The breakpoint between the positively and negatively correlated sets of
genes is quite obvious in this figure.

\hypertarget{a-fancy-figure}{%
\subsection{A ``fancy'' figure}\label{a-fancy-figure}}

Recall that we introduced the \texttt{cowplot} library in Chapter 6, as
a way to combine different ggplot outputs into subfigures such as you
might find in a published paper. Here we'll make further use cowplot to
combine our heat map and line plot visualizations of genes that covary
with YAR018C.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(cowplot)}
\end{Highlighting}
\end{Shaded}

cowplot's \texttt{draw\_plot()} function allows us to place plots at
arbitrary locations and with arbitrary sizes onto the canvas. The
coordinates of the canvas run from 0 to 1, and the point (0, 0) is in
the lower left corner of the canvas. We'll use \texttt{draw\_plot} to
draw a complex figure with a heatmap on the left, and two smaller line
plots on the right.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pos.corr.lineplot <-}\StringTok{  }
\StringTok{  }\NormalTok{combined.pos.neg }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{pos.corr.YAR018C) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression, }\DataTypeTok{group =}\NormalTok{ gene)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.33}\NormalTok{, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time (mins)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Expression"}\NormalTok{, }
      \DataTypeTok{title =} \StringTok{"Genes Positively correlated}\CharTok{\textbackslash{}n}\StringTok{with YAR018C"}\NormalTok{)}

\NormalTok{neg.corr.lineplot <-}\StringTok{ }
\StringTok{  }\NormalTok{combined.pos.neg }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gene }\OperatorTok{%in%}\StringTok{ }\NormalTok{neg.corr.YAR018C) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ expression, }\DataTypeTok{group =}\NormalTok{ gene)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.33}\NormalTok{, }\DataTypeTok{color =} \StringTok{'blue'}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time (mins)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Expression"}\NormalTok{, }
      \DataTypeTok{title =} \StringTok{"Genes negatively correlated}\CharTok{\textbackslash{}n}\StringTok{with YAR018C"}\NormalTok{)}


\NormalTok{heat.map <-}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(combined.pos.neg, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time, }\DataTypeTok{y =}\NormalTok{ gene)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_tile}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ expression)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{scale_fill_gradientn}\NormalTok{(}\DataTypeTok{colors=}\NormalTok{color.scheme) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time (mins)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Gene"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The coordinates of the canvas run from 0 to 1, and the point (0, 0) is
in the lower left corner of the canvas. We'll use \texttt{draw\_plot} to
draw a complex figure with a heatmap on the left, and two smaller line
plots on the right.

I determined the coordinates below by experimentation to create a
visually pleasing layout.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fancy.plot <-}\StringTok{ }\KeywordTok{ggdraw}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{draw_plot}\NormalTok{(heat.map, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DataTypeTok{width =} \FloatTok{0.6}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{draw_plot}\NormalTok{(neg.corr.lineplot, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DataTypeTok{width =} \FloatTok{0.4}\NormalTok{, }\DataTypeTok{height =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{draw_plot}\NormalTok{(pos.corr.lineplot, }\FloatTok{0.6}\NormalTok{, }\DecValTok{0}\NormalTok{,   }\DataTypeTok{width =} \FloatTok{0.4}\NormalTok{, }\DataTypeTok{height =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{draw_plot_label}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.6}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\DataTypeTok{size =} \DecValTok{15}\NormalTok{)}

\NormalTok{fancy.plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-313-1.pdf}

\hypertarget{functions-and-control-flow-statements}{%
\chapter{Functions and control flow
statements}\label{functions-and-control-flow-statements}}

\hypertarget{writing-your-own-functions}{%
\section{Writing your own functions}\label{writing-your-own-functions}}

So far we've been using a variety of built in functions in R. However
the real power of a programming language is the ability to write your
own functions. Functions are a mechanism for organizing and abstracting
a set of related computations. We usually write functions to represent
sets of computations that we apply frequently, or to represent some
conceptually coherent set of manipulations to data.

The general form of an R function is as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{funcname <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(arg1, arg2) \{}
 \CommentTok{# one or more expressions that operate on the fxn arguments}
 \CommentTok{# last expression is the object returned}
 \CommentTok{# or you can explicitly return an object}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

To make this concrete, here's an example where we define a function to
calculate the area of a circle:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{area.of.circle <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(r)\{}
  \KeywordTok{return}\NormalTok{(pi }\OperatorTok{*}\StringTok{ }\NormalTok{r}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Since R returns the value of the last expression in the function, the
\texttt{return} call is optional and we could have simply written:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{area.of.circle <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(r)\{}
\NormalTok{  pi }\OperatorTok{*}\StringTok{ }\NormalTok{r}\OperatorTok{^}\DecValTok{2}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Very short and concise functions are often written as a single line. In
practice I'd probably write the above function as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{area.of.circle <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(r) \{pi }\OperatorTok{*}\StringTok{ }\NormalTok{r}\OperatorTok{^}\DecValTok{2}\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The \texttt{area.of.circle} function takes one argument, \texttt{r}, and
calculates the area of a circle with radius r. Having defined the
function we can immediately put it to use:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{area.of.circle}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{#> [1] 28.27433}

\NormalTok{radius <-}\StringTok{ }\DecValTok{4}
\KeywordTok{area.of.circle}\NormalTok{(radius)}
\CommentTok{#> [1] 50.26548}
\end{Highlighting}
\end{Shaded}

If you type a function name without parentheses R shows you the
function's definition. This works for built-in functions as well
(thought sometimes these functions are defined in C code in which case R
will tell you that the function is a \texttt{.Primitive}).

\hypertarget{function-arguments}{%
\subsection{Function arguments}\label{function-arguments}}

Function arguments can specify the data that a function operates on or
parameters that the function uses. Function arguments can be either
required or optional. In the case of optional arguments, a default value
is assigned if the argument is not given.

Take for example the \texttt{log} function. If you examine the help file
for the \texttt{log} function (type \texttt{?log} now) you'll see that
it takes two arguments, refered to as \texttt{x} and \texttt{base}. The
argument \texttt{x} represents the numeric vector you pass to the
function and is a required argument (see what happens when you type
\texttt{log()} without giving an argument). The argument \texttt{base}
is optional. By default the value of \texttt{base} is
\(e = 2.71828\ldots\). Therefore by default the \texttt{log} function
returns natural logarithms. If you want logarithms to a different base
you can change the \texttt{base} argument as in the following examples:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\CommentTok{# log of 2, base e}
\CommentTok{#> [1] 0.6931472}
\KeywordTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{) }\CommentTok{# log of 2, base 2}
\CommentTok{#> [1] 1}
\KeywordTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{) }\CommentTok{# log of 2, base 4}
\CommentTok{#> [1] 0.5}
\end{Highlighting}
\end{Shaded}

Because base 2 and base 10 logarithms are fairly commonly used, there
are convenient aliases for calling \texttt{log} with these bases.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{log2}\NormalTok{(}\DecValTok{8}\NormalTok{)}
\CommentTok{#> [1] 3}
\KeywordTok{log10}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\CommentTok{#> [1] 2}
\end{Highlighting}
\end{Shaded}

\hypertarget{writing-functions-with-optional-arguments}{%
\subsection{Writing functions with optional
arguments}\label{writing-functions-with-optional-arguments}}

To write a function that has an optional argument, you can simply
specify the optional argument and its default value in the function
definition as so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# a function to substitute missing values in a vector}
\NormalTok{sub.missing <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, }\DataTypeTok{sub.value =} \DecValTok{-99}\NormalTok{)\{}
\NormalTok{  x[}\KeywordTok{is.na}\NormalTok{(x)] <-}\StringTok{ }\NormalTok{sub.value}
  \KeywordTok{return}\NormalTok{(x)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

You can then use this function as so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\KeywordTok{sub.missing}\NormalTok{(m, }\DecValTok{-999}\NormalTok{)  }\CommentTok{# explicitly define sub.value}
\CommentTok{#> [1]    1    2 -999    4}
\KeywordTok{sub.missing}\NormalTok{(m, }\DataTypeTok{sub.value =} \DecValTok{-333}\NormalTok{) }\CommentTok{# more explicit syntax}
\CommentTok{#> [1]    1    2 -333    4}
\KeywordTok{sub.missing}\NormalTok{(m)   }\CommentTok{# use default sub.value}
\CommentTok{#> [1]   1   2 -99   4}
\NormalTok{m  }\CommentTok{# notice that m wasn't modified within the function}
\CommentTok{#> [1]  1  2 NA  4}
\end{Highlighting}
\end{Shaded}

Notice that when we called \texttt{sub.missing} with our vector
\texttt{m}, the vector did \emph{not} get modified in the function body.
Rather a new vector, \texttt{x} was created within the function and
returned. However, if you did the missing value subsitute outside of a
function call, then the vector would be modified:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{n[}\KeywordTok{is.na}\NormalTok{(n)] <-}\StringTok{ }\DecValTok{-99}
\NormalTok{n}
\CommentTok{#> [1]   1   2 -99   4}
\end{Highlighting}
\end{Shaded}

\hypertarget{putting-r-functions-in-scripts}{%
\subsection{Putting R functions in
Scripts}\label{putting-r-functions-in-scripts}}

When you define a function at the interactive prompt and then close the
interpreter your function definition will be lost. The simple way around
this is to define your R functions in a script that you can than access
at any time.

In RStudio choose
\texttt{File\ \textgreater{}\ New\ File\ \textgreater{}\ R\ Script}.
This will bring up a blank editor window. Type your function(s) into the
editor. Everything in this file will be interpretted as R code, so you
should not use the code block notation that is used in Markdown
notebooks. Save the source file in your R working directory with a name
like \texttt{myfxns.R}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# functions defined in myfxns.R}

\NormalTok{area.of.circle <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(r) \{pi }\OperatorTok{*}\StringTok{ }\NormalTok{r}\OperatorTok{^}\DecValTok{2}\NormalTok{\}}

\NormalTok{area.of.rectangle <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(l, w) \{l }\OperatorTok{*}\StringTok{ }\NormalTok{w\}}

\NormalTok{area.of.triangle <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(b, h) \{}\FloatTok{0.5} \OperatorTok{*}\StringTok{ }\NormalTok{b }\OperatorTok{*}\StringTok{ }\NormalTok{h \}}
\end{Highlighting}
\end{Shaded}

Once your functions are in a script file you can make them accesible by
using the \texttt{source} function, which reads the named file as input
and evaluates any definitions or statements in the input file (See also
the \texttt{Source} button in the R Studio GUI):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{source}\NormalTok{(}\StringTok{"myfxns.R"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Having sourced the file you can now use your functions like so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{radius <-}\StringTok{ }\DecValTok{3}
\NormalTok{len <-}\StringTok{ }\DecValTok{4}
\NormalTok{width <-}\StringTok{ }\DecValTok{5}
\NormalTok{base <-}\StringTok{ }\DecValTok{6}
\NormalTok{height <-}\StringTok{ }\DecValTok{7}

\KeywordTok{area.of.circle}\NormalTok{(radius)}
\CommentTok{#> [1] 28.27433}
\KeywordTok{area.of.rectangle}\NormalTok{(len, width)}
\CommentTok{#> [1] 20}
\KeywordTok{area.of.triangle}\NormalTok{(base, height)}
\CommentTok{#> [1] 21}
\end{Highlighting}
\end{Shaded}

Note that if you change the source file, such as correcting a mistake or
adding a new function, you need to call the \texttt{source} function
again to make those changes available.

\hypertarget{control-flow-statements}{%
\section{Control flow statements}\label{control-flow-statements}}

Control flow statements control the order of execution of different
pieces of code. They can be used to do things like make sure code is
only run when certain conditions are met, to iterate through data
structures, to repeat something until a specified event happens, etc.
Control flow statements are frequently used when writing functions or
carrying out complex data transformation.

\hypertarget{if-and-if-else-statements}{%
\subsection{\texorpdfstring{\texttt{if} and \texttt{if-else}
statements}{if and if-else statements}}\label{if-and-if-else-statements}}

\texttt{if} and \texttt{if-else} blocks allow you to structure the flow
of execution so that certain expressions are executed only if particular
conditions are met.

The general form of an \texttt{if} expression is:

\begin{verbatim}
if (Boolean expression) {
  Code to execute if 
  Boolean expression is true
}
\end{verbatim}

Here's a simple \texttt{if} expression in which we check whether a
number is less than 0.5, and if so assign a values to a variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{)  }\CommentTok{# runif generates a random number between 0 and 1}
\NormalTok{face <-}\StringTok{ }\OtherTok{NULL}  \CommentTok{# set face to a NULL value}

\ControlFlowTok{if}\NormalTok{ (x }\OperatorTok{<}\StringTok{ }\FloatTok{0.5}\NormalTok{) \{}
\NormalTok{  face <-}\StringTok{ "heads"}
\NormalTok{\}}
\NormalTok{face}
\CommentTok{#> NULL}
\end{Highlighting}
\end{Shaded}

The \texttt{else} clause specifies what to do in the event that the
\texttt{if} statement is \emph{not} true. The combined general for of an
\texttt{if-else} expression is:

\begin{verbatim}
if (Boolean expression) {
  Code to execute if 
  Boolean expression is true
} else {
  Code to execute if 
  Boolean expression is false
}
\end{verbatim}

Our previous example makes more sense if we include an \texttt{else}
clause.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\ControlFlowTok{if}\NormalTok{ (x }\OperatorTok{<}\StringTok{ }\FloatTok{0.5}\NormalTok{) \{}
\NormalTok{  face <-}\StringTok{ "heads"}
\NormalTok{\} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{  face <-}\StringTok{ "tails"}
\NormalTok{\}}

\NormalTok{face}
\CommentTok{#> [1] "heads"}
\end{Highlighting}
\end{Shaded}

With the addition of the \texttt{else} statement, this simple code block
can be thought of as simulating the toss of a coin.

\hypertarget{if-else-in-a-function}{%
\subsubsection{\texorpdfstring{\texttt{if-else} in a
function}{if-else in a function}}\label{if-else-in-a-function}}

Let's take our ``if-else'' example above and turn it into a function
we'll call \texttt{coin.flip}. A literal re-interpretation of our
previous code in the context of a function is something like this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# coin.flip.literal takes no arguments}
\NormalTok{coin.flip.literal <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{  x <-}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  \ControlFlowTok{if}\NormalTok{ (x }\OperatorTok{<}\StringTok{ }\FloatTok{0.5}\NormalTok{) \{}
\NormalTok{    face <-}\StringTok{ "heads"}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    face <-}\StringTok{ "tails"}
\NormalTok{  \}}
\NormalTok{  face}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\texttt{coin.flip.literal} is pretty long for what it does --- we
created a temporary variable \texttt{x} that is only used once, and we
created the variable \texttt{face} to hold the results of our
\texttt{if-else} statement, but then immediately returned the result.
This is inefficient and decreases readability of our function. A much
more compact implementation of this function is as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coin.flip <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{() \{}
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{<}\StringTok{ }\FloatTok{0.5}\NormalTok{) \{}
    \KeywordTok{return}\NormalTok{(}\StringTok{"heads"}\NormalTok{)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \KeywordTok{return}\NormalTok{(}\StringTok{"tails"}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Note that in our new version of \texttt{coin.flip} we don't bother to
create temporary the variables \texttt{x} and \texttt{face} and we
immediately return the results within the \texttt{if-else} statement.

\hypertarget{multiple-if-else-statements}{%
\subsubsection{\texorpdfstring{Multiple \texttt{if-else}
statements}{Multiple if-else statements}}\label{multiple-if-else-statements}}

When there are more than two possible outcomes of interest, multiple
\texttt{if-else} statements can be chained together. Here is an example
with three outcomes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\OperatorTok{-}\DecValTok{5}\OperatorTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{)  }\CommentTok{# sample a random integer between -5 and 5}

\ControlFlowTok{if}\NormalTok{ (x }\OperatorTok{<}\StringTok{ }\DecValTok{0}\NormalTok{) \{}
\NormalTok{  sign.x <-}\StringTok{ "Negative"}
\NormalTok{\} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (x }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{) \{}
\NormalTok{  sign.x <-}\StringTok{ "Positive"}
\NormalTok{\} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{  sign.x <-}\StringTok{ "Zero"}
\NormalTok{\}}

\NormalTok{sign.x}
\CommentTok{#> [1] "Negative"}
\end{Highlighting}
\end{Shaded}

\hypertarget{for-loops}{%
\subsection{for loops}\label{for-loops}}

A \texttt{for} statement iterates over the elements of a sequence (such
as vectors or lists). A common use of for statements is to carry out a
calculation on each element of a sequence (but see the discussion of
\texttt{map} below) or to make a calculation that involves all the
elements of a sequence.

The general form of a for loop is:

\begin{verbatim}
for (elem in sequence) {
  Do some calculations or
  Evaluate one or more expressions
}
\end{verbatim}

As an example, say we wanted to call our \texttt{coin.flip} function
multiple times. We could use a for loop to do so as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flips <-}\StringTok{ }\KeywordTok{c}\NormalTok{() }\CommentTok{# empty vector to hold outcomes of coin flips}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{20}\NormalTok{) \{}
\NormalTok{  flips <-}\StringTok{ }\KeywordTok{c}\NormalTok{(flips, }\KeywordTok{coin.flip}\NormalTok{())  }\CommentTok{# flip coin and add to our vector}
\NormalTok{\}}
\NormalTok{flips}
\CommentTok{#>  [1] "tails" "tails" "heads" "tails" "tails" "tails" "tails" "heads"}
\CommentTok{#>  [9] "heads" "heads" "tails" "tails" "heads" "tails" "tails" "heads"}
\CommentTok{#> [17] "heads" "heads" "heads" "heads"}
\end{Highlighting}
\end{Shaded}

Let's use a \texttt{for} loop to create a \texttt{multi.coin.flip}
function thats accepts an optional argument \texttt{n} that specifies
the number of coin flips to carry out:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{multi.coin.flip <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(}\DataTypeTok{n =} \DecValTok{1}\NormalTok{) \{}
  \CommentTok{# create an empty character vector of length n}
\NormalTok{  flips <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\DataTypeTok{mode=}\StringTok{"character"}\NormalTok{, }\DataTypeTok{length=}\NormalTok{n)  }
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n) \{}
\NormalTok{    flips[i] <-}\StringTok{ }\KeywordTok{coin.flip}\NormalTok{()}
\NormalTok{  \}}
\NormalTok{  flips}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

With this new definition, a single call of \texttt{coin.flip} returns a
single outcome:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{multi.coin.flip}\NormalTok{()}
\CommentTok{#> [1] "tails"}
\end{Highlighting}
\end{Shaded}

And calling \texttt{multi.coin.flip} with a numeric argument returns
multiple coin flips:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{multi.coin.flip}\NormalTok{(}\DataTypeTok{n=}\DecValTok{10}\NormalTok{)}
\CommentTok{#>  [1] "heads" "tails" "heads" "heads" "tails" "tails" "tails" "tails"}
\CommentTok{#>  [9] "tails" "tails"}
\end{Highlighting}
\end{Shaded}

\hypertarget{efficiency-tip}{%
\subsubsection{Efficiency tip}\label{efficiency-tip}}

An alternate way to write the \texttt{multi.coin.flip} function above
would be:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## This is inefficient, see description eblow}
\NormalTok{multi.coin.flip.alt <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(}\DataTypeTok{n =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  flips <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n) \{}
\NormalTok{    flips <-}\StringTok{ }\KeywordTok{c}\NormalTok{(flips, }\KeywordTok{coin.flip}\NormalTok{())}
\NormalTok{  \}}
\NormalTok{  flips}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

If you know the final length of your vector, it is much faster to create
an empty vector of the needed length:

e.g., \texttt{vector(mode="character",\ length=n)\ \#\ runs\ fast}

than it is to create an empty vector of zero elength, and then extend it
sequentially:

e.g.,
\texttt{flips\ \textless{}-\ c(flips,\ coin.flip())\ \#\ runs\ slow}

\hypertarget{break-statement}{%
\subsection{\texorpdfstring{\texttt{break}
statement}{break statement}}\label{break-statement}}

A \texttt{break} statement allows you to exit a loop even if it hasn't
completed. This is useful for ending a control statement when some
criteria has been satisfied. \texttt{break} statements are usually
nested in \texttt{if} statements.

In the following example we use a \texttt{break} statement inside a
\texttt{for} loop. In this example, we pick random real numbers between
0 and 1, accumulating them in a vector (\texttt{random.numbers}). The
\texttt{for} loop insures that we never pick more than 20 random numbers
before the loop ends. However, the \texttt{break} statement allows the
loop to end prematurely if the number picked is greater than 0.95.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{random.numbers <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{20}\NormalTok{) \{}
\NormalTok{  x <-}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{  random.numbers <-}\StringTok{ }\KeywordTok{c}\NormalTok{(random.numbers, x)}
  \ControlFlowTok{if}\NormalTok{ (x }\OperatorTok{>}\StringTok{ }\FloatTok{0.95}\NormalTok{) \{}
    \ControlFlowTok{break}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{random.numbers}
\CommentTok{#>  [1] 0.49017818 0.16224965 0.40936666 0.79296667 0.05298049 0.70821049}
\CommentTok{#>  [7] 0.93746360 0.12307803 0.64256986 0.19413841 0.01367272 0.82446620}
\CommentTok{#> [13] 0.60485234 0.39682428 0.28413612 0.48721146 0.54119176 0.59512634}
\CommentTok{#> [19] 0.57009194 0.81468425}
\end{Highlighting}
\end{Shaded}

\hypertarget{repeat-loops}{%
\subsection{\texorpdfstring{\texttt{repeat}
loops}{repeat loops}}\label{repeat-loops}}

A \texttt{repeat} loop will loop indefinitely until we explicitly break
out of the loop with a \texttt{break} statement. For example, here's an
example of how we can use \texttt{repeat} and \texttt{break} to simulate
flipping coins until we get a head:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ct <-}\StringTok{ }\DecValTok{0}
\ControlFlowTok{repeat}\NormalTok{ \{}
\NormalTok{  flip <-}\StringTok{ }\KeywordTok{coin.flip}\NormalTok{()}
\NormalTok{  ct <-}\StringTok{ }\NormalTok{ct }\OperatorTok{+}\StringTok{ }\DecValTok{1}
  \ControlFlowTok{if}\NormalTok{ (flip }\OperatorTok{==}\StringTok{ "heads"}\NormalTok{)\{}
    \ControlFlowTok{break}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{ct}
\CommentTok{#> [1] 2}
\end{Highlighting}
\end{Shaded}

\hypertarget{next-statement}{%
\subsection{\texorpdfstring{\texttt{next}
statement}{next statement}}\label{next-statement}}

A \texttt{next} satement allows you to halt the processing of the
current iteration of a loop and immediately move to the next item of the
loop. This is useful when you want to skip calculations for certain
elements of a sequence:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sum.not.div3 <-}\StringTok{ }\DecValTok{0}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{20}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (i }\OperatorTok{%%}\StringTok{ }\DecValTok{3} \OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{) \{ }\CommentTok{# skip summing values that are evenly divisible by three}
    \ControlFlowTok{next}
\NormalTok{  \}}
\NormalTok{  sum.not.div3 <-}\StringTok{ }\NormalTok{sum.not.div3 }\OperatorTok{+}\StringTok{ }\NormalTok{i}
\NormalTok{\}}
\NormalTok{sum.not.div3}
\CommentTok{#> [1] 147}
\end{Highlighting}
\end{Shaded}

\hypertarget{while-statements}{%
\subsection{while statements}\label{while-statements}}

A \texttt{while} statement iterates as long as the condition statement
it contains is true. In the following example, the \texttt{while} loop
calls \texttt{coin.flip} until ``heads'' is the result, and keeps track
of the number of flips. Note that this represents the same logic as the
\texttt{repeat-break} example we saw earlier, but in a a more compact
form.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{first.head <-}\StringTok{ }\DecValTok{1}

\ControlFlowTok{while}\NormalTok{(}\KeywordTok{coin.flip}\NormalTok{() }\OperatorTok{==}\StringTok{ "tails"}\NormalTok{)\{}
\NormalTok{  first.head <-}\StringTok{ }\NormalTok{first.head }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{\}}

\NormalTok{first.head}
\CommentTok{#> [1] 1}
\end{Highlighting}
\end{Shaded}

\hypertarget{ifelse}{%
\subsection{\texorpdfstring{\texttt{ifelse}}{ifelse}}\label{ifelse}}

The \texttt{ifelse} function is equivalent to a \texttt{for}-loop with a
nested \texttt{if-else} statement. \texttt{ifelse} applies the specified
test to each element of a vector, and returns different values depending
on if the test is true or false.

Here's an example of using \texttt{ifelse} to replace \texttt{NA}
elements in a vector with zeros.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{9}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{newx <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(x), }\DecValTok{0}\NormalTok{, x)}
\NormalTok{newx}
\CommentTok{#>  [1] 3 1 4 5 9 0 2 6 5 4}
\end{Highlighting}
\end{Shaded}

The equivalent for-loop could be written as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{9}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{newx <-}\StringTok{ }\KeywordTok{c}\NormalTok{()  }\CommentTok{# create an empty vector}
\ControlFlowTok{for}\NormalTok{ (elem }\ControlFlowTok{in}\NormalTok{ x) \{}
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is.na}\NormalTok{(elem)) \{}
\NormalTok{    newx <-}\StringTok{ }\KeywordTok{c}\NormalTok{(newx, }\DecValTok{0}\NormalTok{)  }\CommentTok{# append zero to newx}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    newx <-}\StringTok{ }\KeywordTok{c}\NormalTok{(newx, elem)  }\CommentTok{# append elem to newx}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{newx}
\CommentTok{#>  [1] 3 1 4 5 9 0 2 6 5 4}
\end{Highlighting}
\end{Shaded}

The \texttt{ifelse} function is clearly a more compact and readable way
to accomplish this.

\hypertarget{map-and-related-tools}{%
\section{\texorpdfstring{\texttt{map} and related
tools}{map and related tools}}\label{map-and-related-tools}}

Another common situation is applying a function to every element of a
list or vector. Again, we could use a \texttt{for} loop, but the
\texttt{map} functions often are better alternatives.

NOTE: \texttt{map} is a relative newcomer to R and must be loaded with
the \texttt{purrr} package (\texttt{purrr} is loaded when we load
\texttt{tidyverse}). Although base R has a complicated series of
``apply'' functions (\texttt{apply}, \texttt{lapply}, \texttt{sapply},
\texttt{vapply}, \texttt{mapply}), \texttt{map} provides similar
functionality with a more consistent interface. We won't use the
\texttt{apply} functions in this class, but you may see them in older
code.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{basic-map}{%
\subsection{\texorpdfstring{basic
\texttt{map}}{basic map}}\label{basic-map}}

Typically, \texttt{map} takes two arguments -- a sequence (a vector,
list, or data frame) and a function. It then applies the function to
each element of the sequence, returning the results as a list.

To illustrate \texttt{map}, let's consider an example with a list of
2-vectors, where each vector gives the min and max values of some
variable of interest for individuals in a sample (e.g.~resting heart
rate and maximum heart rate during exercise). We can use the
\texttt{map} function to quickly generate the difference between the
resting and maximum heart rates:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heart.rates <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{bob =} \KeywordTok{c}\NormalTok{(}\DecValTok{60}\NormalTok{, }\DecValTok{120}\NormalTok{), }\DataTypeTok{fred =} \KeywordTok{c}\NormalTok{(}\DecValTok{79}\NormalTok{, }\DecValTok{150}\NormalTok{), }\DataTypeTok{jim =} \KeywordTok{c}\NormalTok{(}\DecValTok{66}\NormalTok{, }\DecValTok{110}\NormalTok{))}
\NormalTok{diff.fxn <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{x[}\DecValTok{2}\NormalTok{] }\OperatorTok{-}\StringTok{ }\NormalTok{x[}\DecValTok{1}\NormalTok{]\}}

\KeywordTok{map}\NormalTok{(heart.rates, diff.fxn)}
\CommentTok{#> $bob}
\CommentTok{#> [1] 60}
\CommentTok{#> }
\CommentTok{#> $fred}
\CommentTok{#> [1] 71}
\CommentTok{#> }
\CommentTok{#> $jim}
\CommentTok{#> [1] 44}
\end{Highlighting}
\end{Shaded}

As a second example, here's how we could use \texttt{map} to get the
class of each object in a list:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\KeywordTok{list}\NormalTok{(}\DataTypeTok{lead =} \StringTok{"Michael"}\NormalTok{, }\DataTypeTok{keyboard =} \StringTok{"Jermaine"}\NormalTok{))}
\KeywordTok{map}\NormalTok{(x, class)}
\CommentTok{#> [[1]]}
\CommentTok{#> [1] "numeric"}
\CommentTok{#> }
\CommentTok{#> [[2]]}
\CommentTok{#> [1] "character"}
\CommentTok{#> }
\CommentTok{#> [[3]]}
\CommentTok{#> [1] "character"}
\CommentTok{#> }
\CommentTok{#> [[4]]}
\CommentTok{#> [1] "list"}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{map_if-and-map_at}{%
\subsection{\texorpdfstring{\texttt{map\_if} and
\texttt{map\_at}}{map\_if and map\_at}}\label{map_if-and-map_at}}

\texttt{map\_if} is a variant of \texttt{map} that takes a predicate
function (a function that evaluates to TRUE or FALSE) to determine which
elements of the input sequence are transformed by the map function. All
elements of the sequence that do not meet the predicate are left
un-transformed. Like \texttt{map}, \texttt{map\_if} always returns a
list.

Here's an example where we use \texttt{map\_if} to apply the
\texttt{stringr::str\_to\_upper} function to those columns of a data
frame that are character vectors, and apply \texttt{abs} to obtain the
absolute value of a numeric column:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{6}\NormalTok{)}
\NormalTok{b <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"d"}\NormalTok{, }\StringTok{"e"}\NormalTok{, }\StringTok{"f"}\NormalTok{)}
\NormalTok{c <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"u"}\NormalTok{, }\StringTok{"v"}\NormalTok{, }\StringTok{"w"}\NormalTok{, }\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{, }\StringTok{"z"}\NormalTok{)}
\NormalTok{df <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(a, b, c)}
\KeywordTok{head}\NormalTok{(df)}
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>         a b     c    }
\CommentTok{#>     <dbl> <chr> <chr>}
\CommentTok{#> 1  0.3854 a     u    }
\CommentTok{#> 2 -1.468  b     v    }
\CommentTok{#> 3  0.6795 c     w    }
\CommentTok{#> 4  0.4681 d     x    }
\CommentTok{#> 5  1.645  e     y    }
\CommentTok{#> 6  1.289  f     z}

\NormalTok{df2 <-}\StringTok{ }\KeywordTok{map_if}\NormalTok{(df, is.character, str_to_upper)}
\NormalTok{df2 <-}\StringTok{ }\KeywordTok{map_if}\NormalTok{(df2, is.numeric, abs)}
\KeywordTok{head}\NormalTok{(df2)}
\CommentTok{#> $a}
\CommentTok{#> [1] 0.3854417 1.4683696 0.6794608 0.4681072 1.6448192 1.2885668}
\CommentTok{#> }
\CommentTok{#> $b}
\CommentTok{#> [1] "A" "B" "C" "D" "E" "F"}
\CommentTok{#> }
\CommentTok{#> $c}
\CommentTok{#> [1] "U" "V" "W" "X" "Y" "Z"}
\end{Highlighting}
\end{Shaded}

Note that \texttt{df2} is a list, not a data frame. We can convert
\texttt{df2} to a data frame \texttt{df3}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Next, create data frame df3 }
\NormalTok{df3 <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(df2}\OperatorTok{$}\NormalTok{a, df2}\OperatorTok{$}\NormalTok{b, df2}\OperatorTok{$}\NormalTok{c)}
\KeywordTok{head}\NormalTok{(df3)}
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>   `df2$a` `df2$b` `df2$c`}
\CommentTok{#>     <dbl> <chr>   <chr>  }
\CommentTok{#> 1  0.3854 A       U      }
\CommentTok{#> 2  1.468  B       V      }
\CommentTok{#> 3  0.6795 C       W      }
\CommentTok{#> 4  0.4681 D       X      }
\CommentTok{#> 5  1.645  E       Y      }
\CommentTok{#> 6  1.289  F       Z}
\end{Highlighting}
\end{Shaded}

But it requires an extra step to rename the columns:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Check column names, then rename }
\KeywordTok{names}\NormalTok{(df3)}
\CommentTok{#> [1] "df2$a" "df2$b" "df2$c"}
\KeywordTok{names}\NormalTok{(df3) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(df3)}
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>        a b     c    }
\CommentTok{#>    <dbl> <chr> <chr>}
\CommentTok{#> 1 0.3854 A     U    }
\CommentTok{#> 2 1.468  B     V    }
\CommentTok{#> 3 0.6795 C     W    }
\CommentTok{#> 4 0.4681 D     X    }
\CommentTok{#> 5 1.645  E     Y    }
\CommentTok{#> 6 1.289  F     Z}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

If our goal is to apply functions to the columns of a data frame, it may
be easier with \texttt{mutate}:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{df4 <-}\StringTok{ }\NormalTok{df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as_tibble}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{a =} \KeywordTok{abs}\NormalTok{(a),}
         \DataTypeTok{b =} \KeywordTok{str_to_upper}\NormalTok{(b),}
         \DataTypeTok{c =} \KeywordTok{str_to_upper}\NormalTok{(c))}

\KeywordTok{head}\NormalTok{(df4)}
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>        a b     c    }
\CommentTok{#>    <dbl> <chr> <chr>}
\CommentTok{#> 1 0.3854 A     U    }
\CommentTok{#> 2 1.468  B     V    }
\CommentTok{#> 3 0.6795 C     W    }
\CommentTok{#> 4 0.4681 D     X    }
\CommentTok{#> 5 1.645  E     Y    }
\CommentTok{#> 6 1.289  F     Z}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{mapping-in-parallel-using-map2}{%
\subsection{\texorpdfstring{mapping in parallel using
\texttt{map2}}{mapping in parallel using map2}}\label{mapping-in-parallel-using-map2}}

The \texttt{map2} function applies a transformation function to two
sequences in parallel. The following example illustrates this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{first.names <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"John"}\NormalTok{, }\StringTok{"Mary"}\NormalTok{, }\StringTok{"Fred"}\NormalTok{)}
\NormalTok{last.names <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Smith"}\NormalTok{, }\StringTok{"Hernandez"}\NormalTok{, }\StringTok{"Kidogo"}\NormalTok{)}

\KeywordTok{map2}\NormalTok{(first.names, last.names, str_c, }\DataTypeTok{sep=}\StringTok{" "}\NormalTok{)}
\CommentTok{#> [[1]]}
\CommentTok{#> [1] "John Smith"}
\CommentTok{#> }
\CommentTok{#> [[2]]}
\CommentTok{#> [1] "Mary Hernandez"}
\CommentTok{#> }
\CommentTok{#> [[3]]}
\CommentTok{#> [1] "Fred Kidogo"}
\end{Highlighting}
\end{Shaded}

Note how we can specify arguments to the transformation function as
additional arguments to \texttt{map2} (i.e., the \texttt{sep} argument
gets passed to \texttt{str\_c})

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{map-variants-that-return-vectors}{%
\subsection{\texorpdfstring{\texttt{map} variants that return
vectors}{map variants that return vectors}}\label{map-variants-that-return-vectors}}

\texttt{map}, \texttt{map\_if}, and \texttt{map\_at} \emph{always return
lists}. The \texttt{purrr} library also has a series of \texttt{map}
variants that \emph{return vectors}:

\begin{itemize}
\tightlist
\item
  \texttt{map\_lgl} (for logical vectors)
\item
  \texttt{map\_chr} (for character vectors)
\item
  \texttt{map\_int} (integer vectors)
\item
  \texttt{map\_dbl} (double vectors)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# compare the outputs of map and map_chr}
\NormalTok{a <-}\StringTok{ }\KeywordTok{map}\NormalTok{(letters[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{], str_to_upper)}
\KeywordTok{str}\NormalTok{(a)}
\CommentTok{#> List of 6}
\CommentTok{#>  $ : chr "A"}
\CommentTok{#>  $ : chr "B"}
\CommentTok{#>  $ : chr "C"}
\CommentTok{#>  $ : chr "D"}
\CommentTok{#>  $ : chr "E"}
\CommentTok{#>  $ : chr "F"}

\NormalTok{b <-}\StringTok{ }\KeywordTok{map_chr}\NormalTok{(letters[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{], str_to_upper)}
\KeywordTok{str}\NormalTok{(b) }\CommentTok{# a vector}
\CommentTok{#>  chr [1:6] "A" "B" "C" "D" "E" "F"}
\end{Highlighting}
\end{Shaded}

Here's an example using \texttt{map\_dbl}, where we create a data frame
with three columns, and compute the median of each column:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Make data frame for analysis}
\NormalTok{df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}\DataTypeTok{a =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{), }\DataTypeTok{b =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{),}\DataTypeTok{c =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{))}

\KeywordTok{map_dbl}\NormalTok{(df, median) }\CommentTok{# median of each column of df}
\CommentTok{#>          a          b          c }
\CommentTok{#>  0.1430839 -0.0463604  0.1669213}
\end{Highlighting}
\end{Shaded}

\hypertarget{frequency-distributions-and-descriptive-statistics}{%
\chapter{Frequency Distributions and Descriptive
Statistics}\label{frequency-distributions-and-descriptive-statistics}}

See the lecture slides.

\hypertarget{joint-frequency-distributions-and-measures-of-association}{%
\chapter{Joint Frequency Distributions and Measures of
Association}\label{joint-frequency-distributions-and-measures-of-association}}

See the lecture slides.

\hypertarget{introduction-to-probability}{%
\chapter{Introduction to
Probability}\label{introduction-to-probability}}

The exposition here largely follows that in Chapter 5 of Whitlock \&
Schluter.

\hypertarget{terms}{%
\section{Terms}\label{terms}}

\begin{itemize}
\item
  \emph{Outcome} -- the result of a process or experiment
\item
  \emph{Random Trial} -- a process or experiment that has two or more
  possible outcomes whose occurence can not be predicted with certainty
\item
  \emph{Event} -- a subset of the possible outcomes of a random trial
\end{itemize}

\hypertarget{examples-of-random-trials-outcomes-and-events}{%
\subsection{Examples of random trials, outcomes, and
events}\label{examples-of-random-trials-outcomes-and-events}}

\hypertarget{random-trials}{%
\subsubsection{Random trials}\label{random-trials}}

Classic examples of random trials

\begin{itemize}
\tightlist
\item
  flipping a coin
\item
  rolling a die
\item
  choosing a shuffled deck
\item
  picking three balls, without replacement, from an urn filled with 3
  white and 2 black balls
\end{itemize}

Biological examples of random trials

\begin{itemize}
\tightlist
\item
  Determining the sex of offspring in a genetic cross
\item
  Weight loss/gain following treatment with a drug
\item
  Count the plant species in one acre of forest
\end{itemize}

\hypertarget{outcomes}{%
\subsubsection{Outcomes}\label{outcomes}}

Classic examples:

\begin{itemize}
\tightlist
\item
  Coins: heads or tails
\item
  Dice: The numbers \(1\) to \(n\), where \(n\) is the number of sides
  on the die that was thrown
\item
  Cards: Any of the numbered or face cards and their suits
\item
  Balls and urns: the number of black and white balls drawn
\end{itemize}

Biological examples:

\begin{itemize}
\tightlist
\item
  Sex of offspring: male and female
\item
  Weight loss/gain: positive and negative real numbers in an interval
\item
  Species: integers values \(\geq 0\)
\end{itemize}

\hypertarget{events}{%
\subsubsection{Events}\label{events}}

Classic examples:

\begin{itemize}
\tightlist
\item
  Coins: heads or tails (the events are the outcomes when the experiment
  is a single flip)
\item
  Dice: rolled a specific number, rolled an event number, rolled a
  number greater than three, etc
\item
  Cards: drew a face card, drew a heart, drew an ace of hearts, etc
\item
  Balls and urns: all white balls, only one white ball, etc
\end{itemize}

Biological examples:

\begin{itemize}
\tightlist
\item
  Sex of offspring: male or female
\item
  Weight loss/gain: lost weight, lost more than 5 lbs, gained between 10
  and 20 lbs, etc
\item
  Species: counted 10 species, counted more than 25 species, etc
\end{itemize}

\hypertarget{frequentist-definition-of-probability}{%
\section{Frequentist definition of
probability}\label{frequentist-definition-of-probability}}

\emph{Probability} of an event -- the proportion of times the event
would occur if we repeated a random trial an infinite (or very large)
number of times under the same conditions.

\begin{itemize}
\item
  To indicate the probability of an event \(A\), we write \(P(A)\)
\item
  The probability of all possible outcomes of a random trial must sum to
  one.
\item
  The \emph{complement} of an event is all the possible outcomes of a
  random trial that are \emph{not} the event. Let \(A^c\) indicate the
  complement of the event \(A\). Then \(P(A^c) = 1 - P(A)\)
\end{itemize}

\hypertarget{examples-probability}{%
\subsection{Examples: Probability}\label{examples-probability}}

\hypertarget{classic-examples}{%
\subsubsection{Classic examples}\label{classic-examples}}

In classic probabilistic examples, where we understand (approximately)
the physical constraints and symmetries of a random trial, we can often
assign theoretical probabilities:

\begin{itemize}
\item
  Coins: With a fair coin, the probability of each face is 0.5
\item
  Dice: Given a fair 20-side die, the probability of rolling a 15 or
  better is 6/20 = 0.3
\item
  Cards: In randomly shuffled standard (French) 52-card deck, the
  probability of drawing a heart is 13/54 = 0.25; the probability of
  getting an ace is 4/52 = \textasciitilde{}0.077; the probability of
  drawing the ace of hearts is 1/52 = \textasciitilde{}0.0192 The
  probability of not drawing an ace is 1 - 1/52 =
  \textasciitilde{}0.9808
\item
  Balls and urns: If you make three draws (without replacement) from an
  urn filled with three white and two black balls, the probability of
  drawing three white balls is 0.1. We'll illustrate how to calculate
  this below.
\end{itemize}

\hypertarget{biological-examples}{%
\subsubsection{Biological examples}\label{biological-examples}}

For real-world examples, we can not usually invoke physical symmetries
to assign theoretical probabilities \emph{a prioiri} to an event (though
sometimes we'll use such symmetries when stating ``null hypotheses'';
more on this in a later lecture),

\begin{itemize}
\tightlist
\item
  Sex of offspring in humans: In human populations, the \emph{sex ratio
  at birth} is \emph{not} 1:1. The probability of a child being male is
  \textasciitilde{}0.512, and the probability of having a female child
  is \textasciitilde{}0.488. This surprising deviation from the 1:1
  ratio is well documented. Additional factors contributes to further
  deviations in actual human populations. See for example Hesketh and
  Xing (2006), Abnormal sex ratios in human populations: causes and
  consequences. PNAS 103(36):13271-5.
\end{itemize}

\hypertarget{probability-distribution}{%
\section{Probability distribution}\label{probability-distribution}}

\emph{Probability distribution} -- A list, or equivalent representation,
of the probabilities of all mutually exclusive outcomes of a random
trial. Two events are mutually exclusive if than cannot both occur at
the same time. The total probabilities in a probability distribution
sums to 1.

For most cases of biological interest, probability distributions are
unknowable and thus we use relative frequency distributions to estimate
the underlying probability distributions of interest (relative
frequencies are sometimes referred to as empirical probabilities).

Referring back to our earlier ``frequentist definition'', another way of
thinking about a probability distribution is as relative frequency
distribution as the number of observations approaches the size (in some
cases infinite) of the population under study (using the broad
definition of ``population'' discussed several lectures ago)

\hypertarget{discrete-probability-distribution}{%
\subsection{Discrete probability
distribution}\label{discrete-probability-distribution}}

\emph{Discrete probability distribution} -- the probability of each
possible value of a discrete variable. Discrete probability
distributions apply to categorical variables, ordinal variables, and
discrete numerical variables. The total probabilities must sum to one.

\begin{figure}

{\centering \includegraphics{bio304-book_files/figure-latex/unnamed-chunk-353-1} 

}

\caption{Discrete probability distributions. A) Probability distribution for a single roll of a fair 6-sided die; B) Probability distribution for the number of white balls observed in three draws, without replacement, from an urn filled with 3 white balls and 2 black balls.}\label{fig:unnamed-chunk-353}
\end{figure}

\hypertarget{continuous-probability-distribution}{%
\subsection{Continuous probability
distribution}\label{continuous-probability-distribution}}

\emph{Continuous probability distribution} -- for continuous numerical
variables we do not assign probability to specific numerical values, but
rather to numerical intervals. We represent a continuous probability
distribution using a ``Probability Density Function'' (PDF). The
integral of a PDF over an interval gives the probability that the
variable represented by that PDF lies within the specified interval.

\begin{figure}

{\centering \includegraphics{bio304-book_files/figure-latex/unnamed-chunk-354-1} 

}

\caption{Figure 2. Distribution of total SAT scores for 2017 high school graduates. Assuming a normal distribution with mean = 1060, standard deviation = 195, based on data  reported in the [2017 SAT annual report](https://reports.collegeboard.org/pdf/2017-total-group-sat-suite-assessments-annual-report.pdf). The probability that a randomly chosen student got a score better than 1255 is represented by the shaded area; P(Score > 1255) = 0.1587.}\label{fig:unnamed-chunk-354}
\end{figure}

\hypertarget{mutually-exclusive-events}{%
\section{Mutually exclusive events}\label{mutually-exclusive-events}}

\emph{Mutually exclusive events} are events that can \emph{not} both
occur \emph{simultaneously} in the same random trial.

\hypertarget{addition-rule-mutually-exclusive-events}{%
\subsection{Addition rule, mutually exclusive
events}\label{addition-rule-mutually-exclusive-events}}

If A and B are mutually exclusive, then the probability of either event
occuring is the sum of their individual probabilities: \[
P(A\ \text{or}\ B) = P(A) + P(B)
\]

\hypertarget{independence}{%
\section{Independence}\label{independence}}

\begin{itemize}
\item
  \emph{Independence} -- two events are independent if the occurence of
  one does not inform us about the probability that the second.
\item
  \emph{Dependence} -- any events that are not independent are
  considered to be \emph{dependent}.
\end{itemize}

\hypertarget{multiplication-rule-independent-events}{%
\subsection{Multiplication rule, independent
events}\label{multiplication-rule-independent-events}}

The simple version of the multiplication rules states that if events A
and B are independent than: \[
P(A\ \text{and}\ B) = P(A)P(B) 
\]

\hypertarget{general-addition-rule}{%
\section{General addition rule}\label{general-addition-rule}}

The general form of the addition rule states: \[
  P(A\ \text{or}\ B) = P(A) + P(B) - P(A\ \text{and}\ B)
\]

Graphically, this can be represented as:

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{./figures/fig-probability-addition-rule} 

}

\caption{Graphical illustration of the general addition rule for probababilities.}\label{fig:unnamed-chunk-355}
\end{figure}

\hypertarget{conditional-probability}{%
\section{Conditional probability}\label{conditional-probability}}

\emph{Conditional probability} -- is the probability that an event
occurs given that a condition is met.

\begin{itemize}
\tightlist
\item
  Denoted: \(P(A|B)\). Read this as ``the probability of A given B''or
  ``the probability of A conditioned on B''.
\end{itemize}

\hypertarget{example-conditional-probability}{%
\subsection{Example: Conditional
probability}\label{example-conditional-probability}}

Consider our urns and balls example, in which we make three draws
(without replacement) from an urn filled with three white balls and two
black balls.

\begin{itemize}
\item
  The initial probability of drawing a black ball, P(B) = 2/5 = 0.4
\item
  If the first draw was a white ball, the probability of drawing a black
  ball is now, P(B\textbar{}1st ball was white) = 2/4 = 0.5
\end{itemize}

\hypertarget{general-multiplication-rule}{%
\section{General multiplication
rule}\label{general-multiplication-rule}}

The general form of the multiplication rule is: \[
P(A\ \text{and}\ B) = P(A)P(B|A)
\]

\hypertarget{example-general-multiplication-rule}{%
\subsection{Example: General multiplication
rule}\label{example-general-multiplication-rule}}

Consider our urns and balls example again. What is the probability that
you draw, without replacement, three balls and they're all white?

\begin{itemize}
\tightlist
\item
  The initial probability of drawing a white ball in the first draw is
  P(W) = 3/5
\item
  The probability of drawing a white ball in the second draw,
  conditional on the first ball being white is P(W\textbar{}1st White) =
  1/2
\item
  Therefore the P(1st White and 2nd White) = P(W)P(W\textbar{}first
  White) = 3/10
\item
  The probability of drawing a white ball in the third draw, conditional
  on the first two balls being white is P(W\textbar{}1st White and 2nd
  White) = 1/3
\item
  Therefore the P(1st White and 2nd White and 3rd White) = P(1st White
  and 2nd White)P(W\textbar{}1st White and 2nd White) = (3/10)(1/3) =
  1/10
\end{itemize}

\hypertarget{probability-trees}{%
\section{Probability trees}\label{probability-trees}}

Probability trees are diagrams that help calculate the probabilities of
combinations of events across multiple random trials. A probability tree
for the urns and balls example follows below.

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{./figures/fig-urns-probability-tree} 

}

\caption{Probability tree for the urns and balls example}\label{fig:unnamed-chunk-356}
\end{figure}

The nodes in a probability tree represent the possible outcomes of each
random trial. A path from the root node to one of the tips of the
probability tree represents a sequence of outcomes resulting from the
successive random trials. Along the edges of the probability tree we
write the probability of each outcome for each trial. The probability of
a specific sequence of outcomes is calculated by multiplying the
probabilities along the path that represents that sequence.

To solve the problem we looked at previously -- the probability of
getting all white balls in three draws from the urn without replacement
-- we find all the sequences that yield this outcome. In this case there
is only one sequence that results in three white balls. The product of
the probabilities along the path representing this sequence is
\(3/5 \times 2/4 \times 1/3 = 1/10\).

Another way to think about a probability tree is that values along the
branches at a given point in the tree represent the conditional
probabilities of the next possible outcomes, given all the previous
outcomes.

\hypertarget{law-of-total-probability}{%
\section{Law of total probability}\label{law-of-total-probability}}

The law of total probability states: \[
P(A) = \sum_{\mbox{all values of B}} P(B)P(A|B)
\]

\hypertarget{introduction-to-sampling-distributions-part-i}{%
\chapter{Introduction to Sampling Distributions, Part
I}\label{introduction-to-sampling-distributions-part-i}}

\hypertarget{libraries-4}{%
\section{Libraries}\label{libraries-4}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{20181019}\NormalTok{)  }\CommentTok{# initializes RNG}
\end{Highlighting}
\end{Shaded}

\hypertarget{in-class-experiments}{%
\section{In class experiments}\label{in-class-experiments}}

\hypertarget{experiment-1}{%
\subsection{Experiment 1}\label{experiment-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sample 10 grains of rice from the large population provided by the
  instructor
\item
  Count the number of brown grains in your sample
\item
  Enter your counts in this
  \href{https://docs.google.com/spreadsheets/d/1nlg-oarr0_1xcKPsfIiUF8UGAsDXXmTmIJMH-Wj9P70/edit?usp=sharing}{Google
  Sheets spreadsheet}
\item
  Once all the entire class has entered their data, download the
  spreadsheet as as CSV file, load it into R as a data frame
  (\texttt{rice})
\item
  Add a new column to the data frame that gives the proportion (relative
  frequency) of brown rice in each students sample
\item
  Generate a frequency distribution plot for the proportion of brown
  rice
\item
  Discuss as a class
\end{enumerate}

Key points:

\begin{itemize}
\tightlist
\item
  We all did the same experiment
\item
  We all sampled from the same population
\item
  We all came up with slightly different estimates of the proportion of
  brown rice grains
\item
  If we take all of our individual estimates and combine, we have a
  distribution of estimated proportions
\end{itemize}

\hypertarget{experiment-2}{%
\subsection{Experiment 2}\label{experiment-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sample 30 grains of rice from the large population provided by the
  instructor
\item
  Count the number of brown grains in your sample
\item
  Add your new counts as additional rows to the
  \href{https://docs.google.com/spreadsheets/d/1nlg-oarr0_1xcKPsfIiUF8UGAsDXXmTmIJMH-Wj9P70/edit?usp=sharing}{Google
  Sheets spreadsheet}
\item
  Re-download and re-load the data, again estimating the proportion of
  brown rice for each student's sample
\item
  Generate a facetted plot giving the frequencing distribution for the
  proportion of brown rice in samples of size 10 and samples of size 30.
\item
  Discuss as a class
\end{enumerate}

Key points: - With larger sample sizes our estimates still very - But
the spread of our estimates has decreased

\hypertarget{simulating-sampling-in-r}{%
\section{Simulating sampling in R}\label{simulating-sampling-in-r}}

Before we can simulate a sampling experiment in a computer we have to
make some assumptions about the probability distribution of the
variables we're simulating.

To illustrate this let's make explicit what's going on in our rice grain
experiment:

\begin{itemize}
\tightlist
\item
  We have a large population of rice grains
\item
  A fraction, \(p\), of grains in that population are brown
\item
  We draw \(n\) grains of rice from the population; all of the draws are
  independent
\item
  We count the number of brown rice grains, recording the value as \(k\)
\end{itemize}

\hypertarget{binomial-distribution}{%
\subsection{Binomial distribution}\label{binomial-distribution}}

Under this scenario, what is the probability the we drew \(k\) brown
grains from a sample of size \(n\), if the true proportion of brown
grains is \(p\)?

It turns out we can solve this problem for a the following formula:

\[
P(k; n, p) = {n \choose k} p^k (1-p)^{n-k}
\]

Where:

\begin{itemize}
\tightlist
\item
  \({n \choose k}\) is called the ``binomial coefficient'' and it gives
  the different combinations that would result in \(k\) successes (brown
  grains) in \(n\) draws. For example, in our rice experiment one
  combination for \(k=2\) would be: (brown, brown, white,
  white\ldots{}); a second combination could be (brown, white, brown,
  white, white, \ldots{})
\item
  \(p^k(1-p)^{n-k}\) is the probability of \(k\) successes (brown
  grains) and \((n-k)\) failures (white grains) for each of the
  combinations
\end{itemize}

The above formula is the ``Probability Mass Function'' (pmf) for the
\textbf{Binomial Distribution} -- it gives the probability of a
particular outcome. The complete binomial distribution for \(n\) trials
given a probability of success \(p\) is written as \(B(n,p)\) and is
calculated by evaluating the probability mass function for all values of
\(k\) from \(0,\ldots,n\).

\hypertarget{binomial-distribution-in-r}{%
\subsubsection{Binomial distribution in
R}\label{binomial-distribution-in-r}}

R has a built-in function, \texttt{dbinom()} that calculates the
probabability mass function of the binomial distribution at given values
of \(k\). Tkae a moment to read the help on the \texttt{dbinom()}
function in R.

To calculate the Binomial pmf for \(k=5, n = 10, p = 0.3\) we call
\texttt{dbinom()} as so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dbinom}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FloatTok{0.3}\NormalTok{)}
\CommentTok{#> [1] 0.1029193}
\end{Highlighting}
\end{Shaded}

This tells us that if the true proportion of brown rice in the
population is 0.3, about 10\% of samples of size 10 will have 5 brown
grains in them.

The \texttt{dbinom()} function can also take a vector of values of \(k\)
as it's first argument. Here we evaluate all values of \(k\) between 0
and 10, for the same scenario (\(n=10\) draws; probability of success
\(p = 0.3\)), storing the results in a data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k <-}\StringTok{ }\DecValTok{0}\OperatorTok{:}\DecValTok{10}
\NormalTok{binomial.ex1 <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{k =}\NormalTok{ k,}
                           \DataTypeTok{probability =} \KeywordTok{dbinom}\NormalTok{(k, }\DecValTok{10}\NormalTok{, }\FloatTok{0.3}\NormalTok{))}
\NormalTok{binomial.ex1}
\CommentTok{#> # A tibble: 11 x 2}
\CommentTok{#>        k probability}
\CommentTok{#>    <int>       <dbl>}
\CommentTok{#>  1     0 0.02825    }
\CommentTok{#>  2     1 0.1211     }
\CommentTok{#>  3     2 0.2335     }
\CommentTok{#>  4     3 0.2668     }
\CommentTok{#>  5     4 0.2001     }
\CommentTok{#>  6     5 0.1029     }
\CommentTok{#>  7     6 0.03676    }
\CommentTok{#>  8     7 0.009002   }
\CommentTok{#>  9     8 0.001447   }
\CommentTok{#> 10     9 0.0001378  }
\CommentTok{#> 11    10 0.000005905}
\end{Highlighting}
\end{Shaded}

And now plotting the distribution, using \texttt{geom\_col()} which is
like \texttt{geom\_bar()} but that derives the height of the bars to
plot directly from thes specified \texttt{y} aesthetic.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binomial.ex1 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ k, }\DataTypeTok{y =}\NormalTok{ probability)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_col}\NormalTok{(}\DataTypeTok{width=}\FloatTok{0.25}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{breaks=}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-360-1.pdf}

\hypertarget{sampling-from-the-binomial-distribution-in-r}{%
\subsection{Sampling from the binomial distribution in
R}\label{sampling-from-the-binomial-distribution-in-r}}

To simulate sampling from the binomial distribution in R we can use the
\texttt{rbinom()} function.

The arguments to \texttt{rbinom()} the number of samples, the number of
draws in each sample, and the probability of success. For example, to
simulate the single sample of size 10 that you generated at the
beginning of class (making an assumption about the actual probability in
the population) you would call \texttt{rbinom()} like so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# draw 1 sample of size 10, where P(success) = 0.3}
\KeywordTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FloatTok{0.3}\NormalTok{)}
\CommentTok{#> [1] 2}
\end{Highlighting}
\end{Shaded}

The value returned by \texttt{rbinom()} is the number of successes.

You can also specify more than one sample to be generated. For example,
there are roughly 20 students in today's class session. To simulate all
of our 20 samples we can call \texttt{rbinom()} as so:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 20 samples of size 10, where P(success) = 0.3}
\KeywordTok{rbinom}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FloatTok{0.3}\NormalTok{)}
\CommentTok{#>  [1] 1 3 3 2 5 6 2 1 3 2 3 3 3 3 5 3 6 2 5 2}
\end{Highlighting}
\end{Shaded}

Let's repeat that, but for several thousand samples of size 10, and then
plot the results in terms of the proportion of successes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsamples =}\StringTok{ }\DecValTok{5000}
\NormalTok{ssize =}\StringTok{ }\DecValTok{10}
\NormalTok{p =}\StringTok{ }\FloatTok{0.3}

\NormalTok{df10 <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{ssize =} \KeywordTok{rep}\NormalTok{(ssize, nsamples),}
                   \DataTypeTok{k =} \KeywordTok{rbinom}\NormalTok{(nsamples, ssize, p),}
                   \DataTypeTok{estimated.p =}\NormalTok{ k}\OperatorTok{/}\NormalTok{ssize)}

\NormalTok{df10 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ estimated.p)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-363-1.pdf}

Here we're plotting a distribution of the estimates of the proportion of
successes (e.g.~relative frequency of brown rice grains) in many samples
of size 10.

\hypertarget{distribution-of-estimates-of-the-proportion}{%
\section{Distribution of estimates of the
proportion}\label{distribution-of-estimates-of-the-proportion}}

Repeat the simulation,but for samples of size 30:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsamples =}\StringTok{ }\DecValTok{5000}
\NormalTok{ssize =}\StringTok{ }\DecValTok{30}
\NormalTok{p =}\StringTok{ }\FloatTok{0.3}

\NormalTok{df30 <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{ssize =} \KeywordTok{rep}\NormalTok{(ssize, nsamples),}
                   \DataTypeTok{k =} \KeywordTok{rbinom}\NormalTok{(nsamples, ssize, p),}
                   \DataTypeTok{estimated.p =}\NormalTok{ k}\OperatorTok{/}\NormalTok{ssize)}
\end{Highlighting}
\end{Shaded}

Repeat the simulation, but for samples of size 100:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsamples =}\StringTok{ }\DecValTok{5000}
\NormalTok{ssize =}\StringTok{ }\DecValTok{100}
\NormalTok{p =}\StringTok{ }\FloatTok{0.3}

\NormalTok{df100 <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{ssize =} \KeywordTok{rep}\NormalTok{(ssize, nsamples),}
                   \DataTypeTok{k =} \KeywordTok{rbinom}\NormalTok{(nsamples, ssize, p),}
                   \DataTypeTok{estimated.p =}\NormalTok{ k}\OperatorTok{/}\NormalTok{ssize)}
\end{Highlighting}
\end{Shaded}

Combine the three data frames:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.combined <-}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{(df10, df30, df100)}
\end{Highlighting}
\end{Shaded}

Plot distributions of estimates of \(p\) for different sample sizes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.combined }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{ssize.category =} \KeywordTok{as.factor}\NormalTok{(ssize)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ estimated.p, }\DataTypeTok{fill =}\NormalTok{ ssize.category)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{10}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{ssize.category, }\DataTypeTok{ncol=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-367-1.pdf}

\hypertarget{introduction-to-sampling-distributions-part-ii}{%
\chapter{Introduction to Sampling Distributions, Part
II}\label{introduction-to-sampling-distributions-part-ii}}

Usually when we collect biological data, it's because we're trying to
learn about some underlying ``population'' of interest. Population here
could refer to an actual population (e.g.~all males over 20 in the
United States; brushtail possums in the state of Victoria, Australia),
an abstract population (e.g.~corn plants grown from Monsanto ``round up
ready'' seed; yeast cells with genotypes identical to the reference
strain S288c), outcomes of a stochastic process we can observe and
measure (e.g.~meiotic recombination in flies; hadrons detected at the
LHC during a particle collision experiment), etc.

It is often impractical or impossible to measure all objects/individuals
in a population of interest, so we take a \textbf{sample} from the
population and make measurements on the variables of interest in that
sample. We do so with the hope that the various statistics we calculate
on the variables of interest in that sample will be useful estimates of
those same statistics in the underlying population.

However, we must always keep in mind that the statistics we calculate
from our sample will almost never exactly match those of the underlying
population. That is when we collect a sample, and measure a statistic
(e.g.~mean) on variable X in the sample, there is a degree of
\emph{uncertainty} about how well our estimate matches the true value of
that statistic for X in the underlying population.

\emph{Statistical inference} is about quantifying the uncertainty
associated with statistics and using that information to test hypotheses
and evaluate models.

Today we're going to review a fundamental concept in statistical
inference, the notion of a \emph{sampling distribution} for a statistic
of interest. A sampling distribution is the probability distribution of
a given statistic for samples of a given size. Traditionally sampling
distributions were derived analytically. In this class session we'll see
how to approximate sampling distributions for any a statistic using
computer simulation.

\hypertarget{libraries-5}{%
\section{Libraries}\label{libraries-5}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(magrittr)}
\KeywordTok{library}\NormalTok{(stringr)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-set-simulated-male-heights}{%
\section{Data set: Simulated male
heights}\label{data-set-simulated-male-heights}}

To illustrate the concept of sampling distributions, we'll use a
simulated data set to represent the underlying population we're trying
to estimate statistics for. This will allow us to compare the various
statistics we calculate and their sampling distributions to their
``true'' values.

Let's simulate a population consisting of 25,000 individuals with a
single trait of interest -- height (measured in centimeters). We will
simulate this data set based on information about the distribution of
the heights of adult males in the US from a study carried out from
2011-2014 by the US Department of Health and Human Services\footnote{US
  Dept. of Health and Human Services; et al. (August 2016).
  ``Anthropometric Reference Data for Children and Adults: United
  States, 2011--2014'' (PDF). National Health Statistics Reports. 11.
  \url{https://www.cdc.gov/nchs/data/series/sr_03/sr03_039.pdf}}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# male mean height and sd in centimeters from USDHHS report}
\NormalTok{true.mean <-}\StringTok{ }\FloatTok{175.7}
\NormalTok{true.sd <-}\StringTok{ }\FloatTok{15.19}
\end{Highlighting}
\end{Shaded}

\hypertarget{properties-of-the-underlying-population}{%
\subsection{Properties of the underlying
population}\label{properties-of-the-underlying-population}}

Heights in human populations are approximately normally distributed, so
we'll assume that the distribution of our simulated variable is also
normally distributed. Let's take a moment to visualize the probability
distribution of of a normal distribution with a mean and standard
deviation as given above. Here we use the \texttt{dnorm()} function to
generate the probability density for different heights.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pop.distn <-}\StringTok{ }
\StringTok{  }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{height =}  \KeywordTok{seq}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{250}\NormalTok{, }\FloatTok{0.5}\NormalTok{),}
             \DataTypeTok{density =} \KeywordTok{dnorm}\NormalTok{(height,}\DataTypeTok{mean =}\NormalTok{ true.mean, }\DataTypeTok{sd =}\NormalTok{ true.sd))}

\KeywordTok{ggplot}\NormalTok{(pop.distn) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(height, density)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\CommentTok{# vertical line at mean}
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.mean, }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{"dashed"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\CommentTok{# vertical line at mean + 1SD}
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.mean }\OperatorTok{+}\StringTok{ }\NormalTok{true.sd,}
              \DataTypeTok{color =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{"dashed"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\CommentTok{# vertical line at mean - 1SD}
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.mean }\OperatorTok{-}\StringTok{ }\NormalTok{true.sd,}
              \DataTypeTok{color =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{"dashed"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Height (cm)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Density"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of Heights in the Population of Interest"}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"Red and blue lines indicate the mean }\CharTok{\textbackslash{}n}\StringTok{and 1 standard deviation respectively."}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-370-1.pdf}

\hypertarget{other-r-functions-related-to-the-normal-distribution}{%
\subsection{Other R functions related to the normal
distribution}\label{other-r-functions-related-to-the-normal-distribution}}

As shown above \texttt{dnorm()} function calculates the probability
density at given values of a variable \texttt{x}, given the specified
mean and standard deviation.

\texttt{pnorm()} gives the cumulative density function (also known as
the distribution function) for the normal distribution, as shown below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cdf <-}
\StringTok{  }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{height =} \KeywordTok{seq}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{250}\NormalTok{, }\FloatTok{0.5}\NormalTok{),}
             \DataTypeTok{cum.prob =} \KeywordTok{pnorm}\NormalTok{(height, true.mean, true.sd))}

\KeywordTok{ggplot}\NormalTok{(cdf) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(height, cum.prob)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Height"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Cumulative probability"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-371-1.pdf}

\texttt{qnorm()} is the quantile function for the normal distribution.
The input is the probabilities of interest (single value or vector), and
the mean and standard deviation of the distribution. The output is the
corresponding value of the variable corresponding to the given
percentiles.

For example, to estimate the lower 30th percentile of heights in adult
males in the US we can use \texttt{qnorm()} as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.3}\NormalTok{, true.mean, true.sd)}
\CommentTok{#> [1] 167.7344}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perc}\FloatTok{.30}\NormalTok{ <-}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.3}\NormalTok{, true.mean, true.sd)}

\NormalTok{label.offset <-}\StringTok{ }\DecValTok{18} \CommentTok{# determined by trial and error to make a }
                   \CommentTok{# nice looking figure}

\NormalTok{heights.less.perc}\FloatTok{.30}\NormalTok{ <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{100}\NormalTok{, perc}\FloatTok{.30}\NormalTok{, }\DataTypeTok{by=}\FloatTok{0.5}\NormalTok{)}
\NormalTok{density.less.perc}\FloatTok{.30}\NormalTok{ <-}\StringTok{ }\KeywordTok{dnorm}\NormalTok{(heights.less.perc}\FloatTok{.30}\NormalTok{, true.mean, true.sd)}

\KeywordTok{ggplot}\NormalTok{(pop.distn) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ height, }\DataTypeTok{y =}\NormalTok{ density)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ perc}\FloatTok{.30}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{'dashed'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_area}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ heights.less.perc}\FloatTok{.30}\NormalTok{, }\DataTypeTok{y =}\NormalTok{ density.less.perc}\FloatTok{.30}\NormalTok{),}
            \DataTypeTok{fill =} \StringTok{"gray"}\NormalTok{, }\DataTypeTok{data =} \KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ heights.less.perc}\FloatTok{.30}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\DataTypeTok{x =}\NormalTok{ perc}\FloatTok{.30} \OperatorTok{-}\StringTok{ }\NormalTok{label.offset, }\DataTypeTok{y =} \FloatTok{0.025}\NormalTok{, }
           \DataTypeTok{label =} \StringTok{"30th percentile"}\NormalTok{, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Probability distribution as calculated by dnorm()}\CharTok{\textbackslash{}n}\StringTok{and the 30th percentile as calculated by qnorm()}\CharTok{\textbackslash{}n}\StringTok{for a normal distribution with mean and sd as given in the text."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-373-1.pdf}

\hypertarget{seeding-the-pseudo-random-number-generator}{%
\section{Seeding the pseudo-random number
generator}\label{seeding-the-pseudo-random-number-generator}}

When carrying out simulations, we employ random number generators
(e.g.~to choose random samples). Most computers can not generate true
random numbers -- instead they use algorithms that approximate the
generation of random numbers (pseudo-random number generators). One
important difference between a true random number generator and a
pseudo-random number generator is that we can regenerate a series of
pseudo-random numbers if we know the ``seed'' value that initialized the
algorithm. We can specifically set this seed value, so that we can
guarantee that two different people evaluating this notebook get the
same results, even though we're using (pseudo)random numbers in our
simulation.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# make our simulation repeatable by seeding RNG}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{20180321}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{random-sampling-from-the-simulated-population}{%
\section{Random sampling from the simulated
population}\label{random-sampling-from-the-simulated-population}}

Let's simulate the process of taking a single sample of 30 individuals
from our population, using the \texttt{rnorm()} function which takes
samples if size \texttt{n} from a normal distribution with the given
mean and standard deviation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample.a <-}
\StringTok{  }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{height =} \KeywordTok{rnorm}\NormalTok{(}\DataTypeTok{n =} \DecValTok{30}\NormalTok{, }\DataTypeTok{mean =}\NormalTok{ true.mean, }\DataTypeTok{sd =}\NormalTok{ true.sd))}
\end{Highlighting}
\end{Shaded}

Now we'll create a histogram of the height variable in our sample. For
reference we'll also plot the probability for the true population (but
remember, in the typical case you don't know what the true population
looks like)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample.a }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ height)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ ..density..), }
                 \DataTypeTok{fill =} \StringTok{'steelblue'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.75}\NormalTok{, }\DataTypeTok{bins=}\DecValTok{10}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{data=}\NormalTok{pop.distn, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ height, }\DataTypeTok{y =}\NormalTok{ density), }
            \DataTypeTok{alpha=}\FloatTok{0.25}\NormalTok{,}\DataTypeTok{size=}\FloatTok{1.5}\NormalTok{) }\OperatorTok{+}\StringTok{   }
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.mean, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =} \KeywordTok{mean}\NormalTok{(sample.a}\OperatorTok{$}\NormalTok{height), }\DataTypeTok{linetype =} \StringTok{"solid"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Height (cm)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Density"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Distribution of heights in the underlying population (line)}\CharTok{\textbackslash{}n}\StringTok{and a single sample of size 30 (blue)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-376-1.pdf}

The dashed vertical line represent the true mean of the population, the
solid line represents the sample mean. Comparing the two distributions
we see that while our sample of 30 observations is relatively small,its
location (center) and spread that are roughly similar to those of the
underlying population.

Let's create a table giving the estimates of the mean and standard
deviation in our sample:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample.a }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sample.mean =} \KeywordTok{mean}\NormalTok{(height), }
            \DataTypeTok{sample.sd =} \KeywordTok{sd}\NormalTok{(height))}
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>   sample.mean sample.sd}
\CommentTok{#>         <dbl>     <dbl>}
\CommentTok{#> 1       177.1     14.08}
\end{Highlighting}
\end{Shaded}

Based on our sample, we estimate that the mean height of males in our
population of interest is 177.0519552cm with a standard deviation of
14.0770991cm.

\hypertarget{another-random-sample}{%
\subsection{Another random sample}\label{another-random-sample}}

Let's step back and think about our experiment. We took a random sample
of 30 individuals from the population. The very nature of a ``random
sample'' means we could just as well have gotten a different collection
of individuals in our sample. Let's take a second random sample of 25
individuals and see what the data looks like this time:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample.b <-}
\StringTok{  }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{height =} \KeywordTok{rnorm}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DataTypeTok{mean =}\NormalTok{ true.mean, }\DataTypeTok{sd =}\NormalTok{ true.sd))}

\NormalTok{sample.b }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ height)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ ..density..), }
                 \DataTypeTok{fill =} \StringTok{'steelblue'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.75}\NormalTok{, }\DataTypeTok{bins=}\DecValTok{10}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{data=}\NormalTok{pop.distn, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ height, }\DataTypeTok{y =}\NormalTok{ density), }
            \DataTypeTok{alpha=}\FloatTok{0.25}\NormalTok{,}\DataTypeTok{size=}\FloatTok{1.5}\NormalTok{) }\OperatorTok{+}\StringTok{   }
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.mean, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =} \KeywordTok{mean}\NormalTok{(sample.a}\OperatorTok{$}\NormalTok{height), }\DataTypeTok{linetype =} \StringTok{"solid"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Height (cm)"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Density"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Distribution of heights in the underlying population (line)}\CharTok{\textbackslash{}n}\StringTok{and a single sample of size 30 (blue)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-378-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample.b }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sample.mean =} \KeywordTok{mean}\NormalTok{(height), }
            \DataTypeTok{sample.sd =} \KeywordTok{sd}\NormalTok{(height))}
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>   sample.mean sample.sd}
\CommentTok{#>         <dbl>     <dbl>}
\CommentTok{#> 1       174.4     16.88}
\end{Highlighting}
\end{Shaded}

This time we estimated the mean height to be 174.3783114 cm and the
standard deviation to be 16.883491 cm.

\hypertarget{simulating-the-generation-of-many-random-samples}{%
\subsection{Simulating the generation of many random
samples}\label{simulating-the-generation-of-many-random-samples}}

When we estimate population parameters, like the mean and standard
deviation, based on a \emph{sample}, our estimates will differ from the
true population values by some amount. Any given random sample might
provide better or worse estimates than another sample.

We can't know how good our estimates of statistics like the mean and
standard deviation are from any specific sample, but we we can study the
behavior of such estimates \emph{across many simulated samples} and
learn something about how well our estimates do on average, as well the
spread of these estimates.

\hypertarget{a-function-to-estimate-statistics-of-interest-in-a-random-sample}{%
\subsection{A function to estimate statistics of interest in a random
sample}\label{a-function-to-estimate-statistics-of-interest-in-a-random-sample}}

First we're going to write a function called \texttt{rnorm.stats} that
carries out the following steps:

\begin{itemize}
\tightlist
\item
  Take a random sample of size \texttt{n} from a distribution with a
  given mean (\texttt{mu}) and standard deviation (\texttt{sigma})
\item
  Calculate the mean and standard deviation of the random sample
\item
  Return a table giving the sample size, sample mean, and sample
  standard deviation, represented as a data frame
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rnorm.stats <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, mu, sigma) \{}
\NormalTok{  the.sample <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(n, mu, sigma)}
  \KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{sample.size =}\NormalTok{ n, }
             \DataTypeTok{sample.mean =} \KeywordTok{mean}\NormalTok{(the.sample), }
             \DataTypeTok{sample.sd =} \KeywordTok{sd}\NormalTok{(the.sample))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Let's test \texttt{rsample.stats()} for a sample of size 30, drawn from
a popultion with a mean and standard deviation corresponding to our
height exmaple:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rnorm.stats}\NormalTok{(}\DecValTok{30}\NormalTok{, true.mean, true.sd)}
\CommentTok{#> # A tibble: 1 x 3}
\CommentTok{#>   sample.size sample.mean sample.sd}
\CommentTok{#>         <dbl>       <dbl>     <dbl>}
\CommentTok{#> 1          30       176.4     15.08}
\end{Highlighting}
\end{Shaded}

\hypertarget{generating-statistics-for-many-random-samples}{%
\subsection{Generating statistics for many random
samples}\label{generating-statistics-for-many-random-samples}}

Now we'll see how to combine \texttt{rnorm.stats} with two additional
functions to repeatedly run the \texttt{rsample.stats} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.samples.of}\FloatTok{.30}\NormalTok{ <-}
\StringTok{  }\KeywordTok{rerun}\NormalTok{(}\DecValTok{2500}\NormalTok{,  }\KeywordTok{rnorm.stats}\NormalTok{(}\DecValTok{30}\NormalTok{, true.mean, true.sd)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

The function \texttt{rerun} is defined in the \texttt{purrr} library
(automatically loaded with tidyverse). \texttt{purrr:rerun()} re-runs an
expression(s) multiple times. The first argument to \texttt{rerun()} is
the number of times you want to re-run, and the following arguments are
the expressions to be re-run. Thus the second line of the code block
above re-runs the \texttt{rnorm.stats} function 2500 times, generating
sample statistics for samples of size 30 each time it's run.
\texttt{rerun} returns a list whose length is the specified number of
runs.

The third line includes a call the \texttt{dplyr::bind\_rows()}. This
simply takes the list that \texttt{rerun} returns and collapses the list
into a single data frame. \texttt{df.samples.of.30} is thus a data frame
in which each row gives the sample size, sample mean, and sample
standard deviation for a random sample of 30 individuals drawn from our
underlying population with a normally distributed variable.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(df.samples.of}\FloatTok{.30}\NormalTok{)}
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>   sample.size sample.mean sample.sd}
\CommentTok{#>         <dbl>       <dbl>     <dbl>}
\CommentTok{#> 1          30       170.8     15.36}
\CommentTok{#> 2          30       174.6     14.93}
\CommentTok{#> 3          30       175.7     16.79}
\CommentTok{#> 4          30       176.5     13.94}
\CommentTok{#> 5          30       175.3     13.10}
\CommentTok{#> 6          30       176.6     15.49}
\end{Highlighting}
\end{Shaded}

\hypertarget{simulated-sampling-distribution-of-the-mean}{%
\section{Simulated sampling distribution of the
mean}\label{simulated-sampling-distribution-of-the-mean}}

Let's review what we just did:

\begin{itemize}
\tightlist
\item
  We generated 2500 samples of size 30, sampling a variable with an
  underlying normal distribution
\item
  For each of the samples we calculated the mean and standard deviation
  \emph{in that sample}
\item
  We combined each of those estimates of the mean and standard deviation
  into a data frame
\end{itemize}

The 2500 estimates of the mean we generated represents a new
distribution -- what we will call a \textbf{sampling distribution of the
mean for samples of size 30}. Let's plot this sampling distribution:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.samples.of}\FloatTok{.30}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.mean, }\DataTypeTok{y =}\NormalTok{ ..density..)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{25}\NormalTok{, }\DataTypeTok{fill =} \StringTok{'firebrick'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.mean, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Sample means"}\NormalTok{, }\DataTypeTok{y  =} \StringTok{"Density"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of mean heights for 2500 samples of size 30"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-384-1.pdf}

\hypertarget{differences-between-sampling-distribution-and-samplepopulation-distributions}{%
\subsection{Differences between sampling distribution and
sample/population
distributions}\label{differences-between-sampling-distribution-and-samplepopulation-distributions}}

Note that this is \emph{not} a sample distribution of the variable of
interest (``heights''), but rather the distribution of \emph{means of
the variable of interest} (``mean heights'') you would get if you took
many random samples (in one sample you'd estimate the mean height as
180cm, in another you'd estimate it as 172 cm, etc). To emphasize this
point, let's compare the simulated sampling distribution to the
population distribution of the the variable:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.samples.of}\FloatTok{.30}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.mean, }\DataTypeTok{y =}\NormalTok{ ..density..)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{50}\NormalTok{, }\DataTypeTok{fill =} \StringTok{'firebrick'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{data=}\NormalTok{sample.a, }
                 \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ height, }\DataTypeTok{y =}\NormalTok{ ..density..),}
                 \DataTypeTok{bins=}\DecValTok{11}\NormalTok{, }\DataTypeTok{fill=}\StringTok{'steelblue'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.25}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.mean, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\DataTypeTok{color=}\StringTok{'red'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{data=}\NormalTok{pop.distn, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ height, }\DataTypeTok{y =}\NormalTok{ density), }\DataTypeTok{alpha=}\FloatTok{0.25}\NormalTok{,}\DataTypeTok{size=}\FloatTok{1.5}\NormalTok{) }\OperatorTok{+}\StringTok{   }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"height or mean(height) in cm"}\NormalTok{, }\DataTypeTok{y  =} \StringTok{"Density"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of mean heights for 2500 samples of size 30 (red )}\CharTok{\textbackslash{}n}\StringTok{compared to the distribution of  single sample (blue)}\CharTok{\textbackslash{}n}\StringTok{and the population distribution of heights (gray line)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-385-1.pdf}

\hypertarget{use-sampling-distributions-to-understand-the-behavior-of-statistics-of-interest}{%
\subsection{Use sampling distributions to understand the behavior of
statistics of
interest}\label{use-sampling-distributions-to-understand-the-behavior-of-statistics-of-interest}}

The particular sampling distribution of the mean, as simulated above, is
a probability distribution that we can use to estimate the probability
that a sample mean falls within a given interval, assuming our sample is
a random sample of size 30 drawn from our underlying population.

From our visualization, we see that the distribution of sample mean
heights is approximately centered around the true mean height. Most of
the sample estiamtes of the mean height are within 5 cm of the true
population mean height, but a small number of estimates of the sample
mean as off by nearly 10cm.

Let's make this more precise by calculating the mean and standard
deviation of the sampling distribution of means:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.samples.of}\FloatTok{.30} \OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{mean.of.means =} \KeywordTok{mean}\NormalTok{(sample.mean),}
            \DataTypeTok{sd.of.means =} \KeywordTok{sd}\NormalTok{(sample.mean))}
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>   mean.of.means sd.of.means}
\CommentTok{#>           <dbl>       <dbl>}
\CommentTok{#> 1         175.7       2.740}
\end{Highlighting}
\end{Shaded}

\hypertarget{sampling-distributions-for-different-sample-sizes}{%
\subsection{Sampling distributions for different sample
sizes}\label{sampling-distributions-for-different-sample-sizes}}

In the example above we simulated the sampling distribution of the mean
for samples of size 30. How would the sampling distribution change if we
increased the sample size? In the next code block we generate sampling
distributions of the mean (and standard deviation) for samples of size
50, 100, 250, and 500.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.samples.of}\FloatTok{.50}\NormalTok{ <-}
\StringTok{  }\KeywordTok{rerun}\NormalTok{(}\DecValTok{2500}\NormalTok{,  }\KeywordTok{rnorm.stats}\NormalTok{(}\DecValTok{50}\NormalTok{, true.mean, true.sd)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{()}

\NormalTok{df.samples.of}\FloatTok{.100}\NormalTok{ <-}
\StringTok{  }\KeywordTok{rerun}\NormalTok{(}\DecValTok{2500}\NormalTok{,  }\KeywordTok{rnorm.stats}\NormalTok{(}\DecValTok{100}\NormalTok{, true.mean, true.sd)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{()}

\NormalTok{df.samples.of}\FloatTok{.250}\NormalTok{ <-}
\StringTok{  }\KeywordTok{rerun}\NormalTok{(}\DecValTok{2500}\NormalTok{,  }\KeywordTok{rnorm.stats}\NormalTok{(}\DecValTok{250}\NormalTok{, true.mean, true.sd)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{()}

\NormalTok{df.samples.of}\FloatTok{.500}\NormalTok{ <-}
\StringTok{  }\KeywordTok{rerun}\NormalTok{(}\DecValTok{2500}\NormalTok{,  }\KeywordTok{rnorm.stats}\NormalTok{(}\DecValTok{500}\NormalTok{, true.mean, true.sd)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

To make plotting and comparison easier we will combine each of the
individual data frames, representing the different sampling
distributions for samples of a given size, into a single data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.combined <-}\StringTok{ }
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{(df.samples.of}\FloatTok{.30}\NormalTok{,}
\NormalTok{            df.samples.of}\FloatTok{.50}\NormalTok{,}
\NormalTok{            df.samples.of}\FloatTok{.100}\NormalTok{,}
\NormalTok{            df.samples.of}\FloatTok{.250}\NormalTok{,}
\NormalTok{            df.samples.of}\FloatTok{.500}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# create a factor version of sample size to facilitate plotting}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sample.sz =} \KeywordTok{as.factor}\NormalTok{(sample.size))}
\end{Highlighting}
\end{Shaded}

We then plot each of the individual sampling distributions, faceting on
sample size.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.combined, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.mean, }\DataTypeTok{y =}\NormalTok{ ..density.., }\DataTypeTok{fill =}\NormalTok{ sample.sz)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{25}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.mean, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{)  }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{sample.sz, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_fill_brewer}\NormalTok{(}\DataTypeTok{palette=}\StringTok{"Set1"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\CommentTok{# change color palette}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Sample means"}\NormalTok{, }\DataTypeTok{y  =} \StringTok{"Density"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Distribution of mean heights for samples of varying size"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-389-1.pdf}

\hypertarget{discussion-of-trends-for-sampling-distributions-of-different-sample-sizes}{%
\subsection{Discussion of trends for sampling distributions of different
sample
sizes}\label{discussion-of-trends-for-sampling-distributions-of-different-sample-sizes}}

The key trend we see when comparing the sampling distributions of the
mean for samples of different size is that as the sample size gets
larger, the spread of the sampling distribution of the mean becomes
narrower around the true mean. This means that \emph{as sample size
increases, the uncertainty associated with our estimates of the mean
decreases}.

Let's create a table, grouped by sample size, to help quantify this
pattern:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sampling.distn.mean.table <-}
\StringTok{  }\NormalTok{df.combined }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(sample.size) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{mean.of.means =} \KeywordTok{mean}\NormalTok{(sample.mean),}
            \DataTypeTok{sd.of.means =} \KeywordTok{sd}\NormalTok{(sample.mean))}

\NormalTok{sampling.distn.mean.table}
\CommentTok{#> # A tibble: 5 x 3}
\CommentTok{#>   sample.size mean.of.means sd.of.means}
\CommentTok{#>         <dbl>         <dbl>       <dbl>}
\CommentTok{#> 1          30         175.7      2.740 }
\CommentTok{#> 2          50         175.7      2.173 }
\CommentTok{#> 3         100         175.7      1.509 }
\CommentTok{#> 4         250         175.7      0.9756}
\CommentTok{#> 5         500         175.7      0.6656}
\end{Highlighting}
\end{Shaded}

\hypertarget{standard-error-of-the-mean}{%
\section{Standard Error of the Mean}\label{standard-error-of-the-mean}}

We see from the graph and table above that our estimates of the mean
cluster more tightly about the true mean as our sample size increases.
This is obvious when we compare the standard deviation of our mean
estimates as a function of sample size.

The standard deviation of the sampling distribution of a statistic of
interest is called the \textbf{Standard Error} of that statistic. Here,
through simulation, we are approximating the \textbf{Standard Error of
the Mean}.

One can show mathematically that the expected Standard Error of the Mean
as a function of sample size and the standard deviation of the
underlying population distribution is:

\[
\mbox{Standard Error of Mean} = \frac{\sigma}{\sqrt{n}}
\] where \(\sigma\) is the population standard deviation (i.e.~the
``true'' standard deviation), and \(n\) is the sample size. This result
for the standard error of the mean is true regardless of the form of the
underlying population distribution.

Let's compare that theoretical expectation to our simulated results:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{se.mean.theory <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{500}\NormalTok{,}\DecValTok{10}\NormalTok{), }
                         \ControlFlowTok{function}\NormalTok{(n)\{ true.sd}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n) \})}

\NormalTok{df.se.mean.theory <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{sample.size =} \KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{500}\NormalTok{,}\DecValTok{10}\NormalTok{),}
                                \DataTypeTok{std.error =}\NormalTok{ se.mean.theory)}

\KeywordTok{ggplot}\NormalTok{(sampling.distn.mean.table, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.size, }\DataTypeTok{y =}\NormalTok{ sd.of.means)) }\OperatorTok{+}
\StringTok{   }\CommentTok{# plot standard errors of mean based on our simulations}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{  }
\StringTok{  }\CommentTok{# plot standard errors of the mean based on theory}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.size, }\DataTypeTok{y =}\NormalTok{ std.error), }\DataTypeTok{data =}\NormalTok{ df.se.mean.theory, }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Sample size"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Std Error of Mean"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"A comparison of theoretical (red line) and simulated (points) estimates of}\CharTok{\textbackslash{}n}\StringTok{the standard error of the mean for samples of different size"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-391-1.pdf}

We see that as sample sizes increase, the standard error of the mean
decreases. This means that as our samples get larger, our uncertainty in
our sample estimate of the mean (our best guess for the population mean)
gets smaller.

\hypertarget{sampling-distribution-of-the-standard-deviation}{%
\section{Sampling Distribution of the Standard
Deviation}\label{sampling-distribution-of-the-standard-deviation}}

Above we explored how the sampling distribution of the mean changes with
sample size. We can similarly explore the sampling distribution of any
other statistic, such as the standard deviation, or the median, or the
the range, etc.

Recall that when we drew random samples we calculated the standard
deviation of each of those samples in addition to the mean. We can look
at the location and spread of the estimates of the standard deviation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sampling.distn.sd.table <-}
\StringTok{  }\NormalTok{df.combined }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(sample.size) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{mean.of.sds =} \KeywordTok{mean}\NormalTok{(sample.sd),}
            \DataTypeTok{sd.of.sds =} \KeywordTok{sd}\NormalTok{(sample.sd))}

\NormalTok{sampling.distn.sd.table}
\CommentTok{#> # A tibble: 5 x 3}
\CommentTok{#>   sample.size mean.of.sds sd.of.sds}
\CommentTok{#>         <dbl>       <dbl>     <dbl>}
\CommentTok{#> 1          30       15.02    2.046 }
\CommentTok{#> 2          50       15.12    1.500 }
\CommentTok{#> 3         100       15.16    1.089 }
\CommentTok{#> 4         250       15.17    0.6873}
\CommentTok{#> 5         500       15.19    0.4957}
\end{Highlighting}
\end{Shaded}

As we did for the sampling distribution of the mean, we can visualize
the sampling distribution of the standard deviation as shown below:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.combined, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.sd, }\DataTypeTok{y =}\NormalTok{ ..density.., }\DataTypeTok{fill =}\NormalTok{ sample.sz)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{25}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.sd, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{)  }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{sample.sz, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_fill_brewer}\NormalTok{(}\DataTypeTok{palette=}\StringTok{"Set1"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Sample standard deviations"}\NormalTok{, }\DataTypeTok{y  =} \StringTok{"Density"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Sampling distribution of standard deviation of height for samples of varying size"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-393-1.pdf}

The key trend we saw when examining the sampling distribution of the
mean is also apparent for standard deviation -- bigger samples lead to
tighter sampling distributions and hence less uncertainty in the sample
estimates of the standard deviation.

\hypertarget{standard-error-of-standard-deviations}{%
\subsection{Standard error of standard
deviations}\label{standard-error-of-standard-deviations}}

For normally distributed data the expected Standard Error of the
Standard Deviation (i.e.~the standard deviation of standard deviations!)
is approximately:

\[
\mbox{Standard Error of Standard Deviation} \approx \frac{\sigma}{\sqrt{2(n-1)}}
\] where \(\sigma\) is the population standard deviation, and \(n\) is
the sample size.

As before, let's visually compare the theoretical expectation to our
simulated estimates.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{se.sd.theory <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{10}\NormalTok{), }
                       \ControlFlowTok{function}\NormalTok{(n)\{ true.sd}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{(n}\DecValTok{-1}\NormalTok{))\})}

\NormalTok{df.se.sd.theory <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{sample.size =} \KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{500}\NormalTok{,}\DecValTok{10}\NormalTok{), }
                              \DataTypeTok{std.error =}\NormalTok{ se.sd.theory)}

\KeywordTok{ggplot}\NormalTok{(sampling.distn.sd.table, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.size, }\DataTypeTok{y =}\NormalTok{ sd.of.sds)) }\OperatorTok{+}
\StringTok{   }\CommentTok{# plot standard errors of mean based on our simulations}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{  }
\StringTok{  }\CommentTok{# plot standard errors of the mean based on theory}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.size, }\DataTypeTok{y =}\NormalTok{ std.error), }\DataTypeTok{data =}\NormalTok{ df.se.sd.theory, }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Sample size"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Std Error of Standard Deviation"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"A comparison of theoretical (red line) and simulated (points) estimates of}\CharTok{\textbackslash{}n}\StringTok{the standard error of the standard deviation for samples of different size"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-394-1.pdf}

\hypertarget{what-happens-to-the-sampling-distribution-of-the-mean-and-standard-deviation-when-our-sample-size-is-small}{%
\section{What happens to the sampling distribution of the mean and
standard deviation when our sample size is
small?}\label{what-happens-to-the-sampling-distribution-of-the-mean-and-standard-deviation-when-our-sample-size-is-small}}

We would hope that, regardless of sample size, the sampling
distributions of both the mean and standard deviation should be centered
around the true population value, \(\mu\) and \(\sigma\) respectively.
That seemed to be the case for the modest to large sample sizes we've
looked at so far (30 to 500 observations). Does this also hold for small
samples? Let's use simulation to explore how well this is expectation is
met for small samples.

As we've done before, we simulate the sampling distribution of the mean
and standard deviation for samples of varying size.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# sample sizes we'll conside}
\NormalTok{ssizes <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{50}\NormalTok{)}

\CommentTok{# number of samples to draw *for each sample size*}
\NormalTok{nsamples <-}\StringTok{ }\DecValTok{2500}

\CommentTok{# create a data frame with empty columns}
\NormalTok{df.combined.small <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{sample.size =} \KeywordTok{double}\NormalTok{(), }
                          \DataTypeTok{sample.mean =} \KeywordTok{double}\NormalTok{(), }
                          \DataTypeTok{sample.sd =} \KeywordTok{double}\NormalTok{(),}
                          \DataTypeTok{estimated.SE =} \KeywordTok{double}\NormalTok{(), }
                          \DataTypeTok{sample.zscore =} \KeywordTok{double}\NormalTok{())}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in}\NormalTok{ ssizes) \{}
\NormalTok{  df.samples.of.size.i <-}
\StringTok{    }\KeywordTok{rerun}\NormalTok{(nsamples,  }\KeywordTok{rnorm.stats}\NormalTok{(i, true.mean, true.sd)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{bind_rows}\NormalTok{()  }
  
\NormalTok{  df.combined.small <-}\StringTok{ }
\StringTok{    }\KeywordTok{bind_rows}\NormalTok{(df.combined.small, df.samples.of.size.i)}

\NormalTok{\}}

\NormalTok{df.combined.small }\OperatorTok{%<>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sample.sz =} \KeywordTok{as.factor}\NormalTok{(sample.size))}
\end{Highlighting}
\end{Shaded}

\hypertarget{for-small-samples-sample-standard-deviations-systematically-underestimate-the-population-standard-deviation}{%
\subsection{For small samples, sample standard deviations systematically
underestimate the population standard
deviation}\label{for-small-samples-sample-standard-deviations-systematically-underestimate-the-population-standard-deviation}}

Let's examine how the well centered the sampling distributions of the
mean and standard deviation are around their true values, as a function
of sample size.

First a table summarizing this information:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{by.sample.size <-}
\StringTok{  }\NormalTok{df.combined.small }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(sample.size) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{mean.of.means =} \KeywordTok{mean}\NormalTok{(sample.mean),}
            \DataTypeTok{mean.of.sds =} \KeywordTok{mean}\NormalTok{(sample.sd))}

\NormalTok{by.sample.size}
\CommentTok{#> # A tibble: 9 x 3}
\CommentTok{#>   sample.size mean.of.means mean.of.sds}
\CommentTok{#>         <dbl>         <dbl>       <dbl>}
\CommentTok{#> 1           2         175.2       11.93}
\CommentTok{#> 2           3         175.8       13.51}
\CommentTok{#> 3           4         175.7       13.99}
\CommentTok{#> 4           5         175.7       14.15}
\CommentTok{#> 5           7         175.8       14.52}
\CommentTok{#> 6          10         175.7       14.78}
\CommentTok{#> 7          20         175.7       14.98}
\CommentTok{#> 8          30         175.6       15.07}
\CommentTok{#> 9          50         175.7       15.12}
\end{Highlighting}
\end{Shaded}

We see that the sampling distributions of means are well centered around
the true mean for both small and medium, and there is no systematic bias
one way or the other. By contrast the sampling distribution of standard
deviations tends to underestimate the true standard deviation when the
samples are small (less than 30 observations).

We can visualize this bias as shown here:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(by.sample.size, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.size, }\DataTypeTok{y =}\NormalTok{ mean.of.sds)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{color =} \StringTok{'red'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{color =} \StringTok{'red'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =}\NormalTok{ true.sd, }\DataTypeTok{color =} \StringTok{'black'}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{'dashed'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Sample Size"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Mean of Sampling Distn of Std Dev"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-397-1.pdf}

The source of this bias is clear if we look at the sampling distribution
of the standard deviation for samples of size 3, 5, and 30.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filtered.df <-}\StringTok{ }
\StringTok{  }\NormalTok{df.combined.small }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(sample.size }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{30}\NormalTok{))}

\KeywordTok{ggplot}\NormalTok{(filtered.df, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sample.sd, }\DataTypeTok{y =}\NormalTok{ ..density.., }\DataTypeTok{fill =}\NormalTok{ sample.sz)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{50}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.65}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{sample.size, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ true.sd, }\DataTypeTok{linetype =} \StringTok{'dashed'}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Std Deviations"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Density"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Sampling distributions of the standard deviation}\CharTok{\textbackslash{}n}\StringTok{As a function of sample size"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-398-1.pdf}

There's very clear indication that the the sampling distribution of
standard deviations is not centered around the true value for \(n=3\)
and for \(n=5\), however with samples of size 30 the sampling
distribution of the standard deviation appears fairly well centered
around the true value of the underlying population.

\hypertarget{underestimates-of-the-standard-deviation-given-small-n-lead-to-understimates-of-the-se-of-the-mean}{%
\subsection{\texorpdfstring{Underestimates of the standard deviation
given small \(n\) lead to understimates of the SE of the
mean}{Underestimates of the standard deviation given small n lead to understimates of the SE of the mean}}\label{underestimates-of-the-standard-deviation-given-small-n-lead-to-understimates-of-the-se-of-the-mean}}

When sample sizes are small, sample estimates of the standard deviation,
\(s_x\), tend to underestimate the true standard deviation, \(\sigma\),
then it follows that sample estimates of the standard error of the mean,
\(SE_{\overline{x}} = \frac{s_x}{\sqrt{n}}\), must tend to understimate
the true standard error of the mean,
\(SE_\mu = \frac{\sigma}{\sqrt{n}}\).

\hypertarget{introduction-to-hypothesis-testing}{%
\chapter{Introduction to hypothesis
testing}\label{introduction-to-hypothesis-testing}}

In hypothesis testing we compare statistical properties of our observed
data to the same properties we would expect to see under a \emph{null
hypothesis}.

More specifically we compare our point estimate of a statistic of
interest, based on our data, to the \emph{sampling distribution of that
statistic} under a given null hypothesis.

\hypertarget{libraries-6}{%
\section{Libraries}\label{libraries-6}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(magrittr)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

\hypertarget{null-and-alternative-hypotheses}{%
\section{Null and Alternative
Hypotheses}\label{null-and-alternative-hypotheses}}

When carrying out statistical hypothesis testing we must formulate a
``null hypothesis'' and an ``alternative hypothesis'' (these always come
as a pair) that jointly describe the set of possible values for a
statistic of interest. We must also make some assumptions, either based
on theory or inferred from the data, about the distributional properties
of the sampling distribution of the statistic of interest.

NOTE: statistical hypotheses are not scientific hypotheses, but rather
statistical statements about a population. Statistical hypotheses can
help us to determine which predictions stemming from scientific
hypotheses are consistent with the data, but statistical hypotheses are
not ``statements about the existence and possible causes of natural
phenomena'' (Whitlock \& Schluter 2014).

\hypertarget{null-hypotheses}{%
\subsection{Null hypotheses}\label{null-hypotheses}}

Whitlock \& Schuluter: ``A \textbf{null hypothesis} is a specific
statement about a population parameter made for the purpose of argument.
A good null hypothesis is a statement that would be interesting to
reject.''

\begin{itemize}
\tightlist
\item
  Null hypotheses typically correspond to outcomes that would suggest
  ``no difference'' or ``no effect'' of the treatment, grouping, or
  other types of comparisons one makes with data
\item
  Sometimes a null expectation is based on prior observation or from
  theoretical considerations
\item
  A null hypothesis is always \emph{specific} -- specifies on particular
  value of the parameter being studied (though sometimes this is
  implicit when written in words)
\item
  The standard mathematical notation to indicate a null hypothesis is to
  write \(H_0\) (``H-zero'' or ``H-naught'')
\end{itemize}

Examples of null hypotheses:

\begin{itemize}
\tightlist
\item
  \(H_0\): The density of dolphins is the same in areas with and without
  drift-net fishing
\item
  \(H_0\) :The effect of ACE inhibitors on blood pressure does not
  differ from administering a placebo
\item
  \(H_0\): There is no correlation between maternal smoking and the
  probability of premature births
\end{itemize}

\hypertarget{alternative-hypotheses}{%
\subsection{Alternative hypotheses}\label{alternative-hypotheses}}

Whitlock \& Schluter: ``The \textbf{alternative hypothesis} includes all
other feasible values for the population parameter besides the value
stated in the null hypothesis''

\begin{itemize}
\tightlist
\item
  Alternative hypotheses usually include parameter values that are
  predicted by a scientific hypothesis, but often include other feasible
  values as well
\item
  The standard mathematical notation to indicate a null hypothesis is to
  write \(H_A\)
\end{itemize}

Examples of alternative hypotheses:

\begin{itemize}
\tightlist
\item
  \(H_A\): The density of dolphins differs in areas with and without
  drift-net fishing
\item
  \(H_A\) :The effect of ACE inhibitors on blood pressure differs from
  administration of a placebo
\item
  \(H_A\): There is a non-zero correlation between maternal smoking and
  the probability of premature births
\end{itemize}

\hypertarget{rejecting-failing-to-reject-null-hypotheses}{%
\section{Rejecting / failing to reject null
hypotheses}\label{rejecting-failing-to-reject-null-hypotheses}}

When carrying out statistical hypothesis testing \textbf{the null
hypothesis is the only statement being tested with the data}.

\begin{itemize}
\item
  If the data are consistent with the null hypothesis, we have ``failed
  to reject the null hypothesis''. This is \emph{not} the same as
  accepting the null hypothesis.
\item
  If the data are inconsistent with the null hypothesis, we ``reject the
  null hypothesis'' and say the data support the alternative hypothesis
\item
  Note that because the alternative hypothesis is usually formulated in
  terms of all other possible values of a parameter of interest,
  rejecting the null hypothesis does not allow us to make a
  probabilistic statement about the value of that parameter.
\end{itemize}

\hypertarget{outcomes-of-hypothesis-tests}{%
\section{Outcomes of hypothesis
tests}\label{outcomes-of-hypothesis-tests}}

In reality, a null hypothesis is either true or false. When you carry
out a hypothesis test, there are two possible test outcomes -- you
reject the null hypothesis or you fail to reject the null hypothesis. It
is typical to represent the different combinations of the reality /
statistical tests in a table like the following:

\begin{longtable}[]{@{}lcc@{}}
\toprule
& do not reject \(H_0\) & reject \(H_0\)\tabularnewline
\midrule
\endhead
\(H_0\) true & okay & Type 1 error (false positive),
\(\alpha\)\tabularnewline
\(H_A\) true & Type 2 error (false negative), \(\beta\) &
okay\tabularnewline
\bottomrule
\end{longtable}

When we specify a significance threshold, \(\alpha\), for hypothesis
testing, this controls the false positive rate (also called Type I
error) of our test. The false negative rate (also calledType II error)
is often referred to as \(\beta\). In general, there is a tradeoff
between the false positive and false negative rate -- the lower the
false positive rate the higher the false negative rate, and vice versa.

\hypertarget{using-p-values-to-assess-the-strength-of-evidence-against-the-null-hypothesis}{%
\section{Using p-values to assess the strength of evidence against the
null
hypothesis}\label{using-p-values-to-assess-the-strength-of-evidence-against-the-null-hypothesis}}

To assess the strength of the evidence against the null hypothesis, we
can ask ``what is the probability of observing a statistic of interest
that is \textbf{at least as favorable} to the alternative hypothesis,
\textbf{if the null hypothesis were true}?''

Mathematically, we pose this question with respect to the expected
\emph{sampling distribution of the statistic of interest} under the null
hypothesis (this is called the \emph{null distribution}). For example,
when testing a hypothesis involving means, we would ask ``What is the
probability of observing my sample mean, with respect to the expected
distribution of sample means, if the null hypothesis was true.''

\begin{description}
\tightlist
\item[P-value]
The p-value is the probability of observing data at least as favorable
to the alternative hypothesis as our current data set, if the null
hypothesis is true.
\end{description}

\textbf{Small p-values} give us evidence to support the \emph{rejection}
of the null hypothesis. Conventionally p-values of less than 0.05 or
0.01 are used in many scientific fields, though recently there have been
calls in some fields to redefine this convention (see for example
Benjamin et al.~2017,
\url{https://www.nature.com/articles/s41562-017-0189-z.pdf}).

\hypertarget{example-comparing-a-sample-mean-to-an-hypothesized-normal-distribution}{%
\section{Example: Comparing a sample mean to an hypothesized normal
distribution}\label{example-comparing-a-sample-mean-to-an-hypothesized-normal-distribution}}

Occasionally one wishes to ask whether a sample mean, from a sample of
size \(n\), is consistent with having been drawn from a normal
distribution with a specified mean and standard deviation,
\(N(\mu,\sigma)\).

\hypertarget{null-and-alternative-hypotheses-1}{%
\subsection{Null and alternative
hypotheses}\label{null-and-alternative-hypotheses-1}}

\begin{itemize}
\tightlist
\item
  \(H_0\): the sample mean, \(\overline{x}\) is from a normal
  distribution with a mean \(\mu\) and standard deviation \(\sigma\)
\item
  \(H_A\): the sample mean is not from such a distribution
\end{itemize}

\hypertarget{sampling-distribution-of-the-mean}{%
\subsection{Sampling distribution of the
mean}\label{sampling-distribution-of-the-mean}}

For a normal distribution with parameters, \(N(\mu,\sigma)\), the
sampling distribution of the mean is itself normally distributed, with
parameters \(N(\mu,\sigma/\sqrt{n})\).\\
A reminder that the standard deviation of the sampling distribution of
the mean, \(\sigma/\sqrt{n}\), is usually referred to as the ``standard
error of the mean''

\hypertarget{calculating-a-p-value}{%
\subsection{Calculating a p-value}\label{calculating-a-p-value}}

Since the sampling distribution of the mean is normally distributed, as
described above we can use the \texttt{pnorm()} function to

Let's apply this to the comparison we made in last class, involving a
comparison of the sample mean of tail length in Victoria possums to a
hypothesized normal distribution based on Queensland possum. In that
example, our hypothesized normal distribution had parameters
\(N(37.9\ \text{cm}, 1.71\ \text{cm})\). Our Victoria possum sample size
was \(n=5\), with a mean \(x = 35.9\ \text{cm}\).

Our null hypothesis is framed in a manner that requires a two-tailed
test, as under the alternative hypothesis the sample could be drawn from
a distribution with either a higher or lower mean.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# parameters of null}
\NormalTok{null.mu <-}\StringTok{ }\FloatTok{37.9}
\NormalTok{null.sigma <-}\StringTok{ }\FloatTok{1.71}

\CommentTok{# sample statistics}
\NormalTok{observed.mean <-}\StringTok{ }\FloatTok{35.9}
\NormalTok{n <-}\StringTok{ }\DecValTok{5}

\NormalTok{diff.mean <-}\StringTok{ }\KeywordTok{abs}\NormalTok{(null.mu }\OperatorTok{-}\StringTok{ }\NormalTok{observed.mean)}

\CommentTok{# standard deviation of sampling distribution under null hypotheses}
\NormalTok{null.SE.mean <-}\StringTok{ }\NormalTok{null.sigma}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)  }

\CommentTok{# calculate p-value }
\NormalTok{p.value <-}\StringTok{ }
\StringTok{  }\KeywordTok{pnorm}\NormalTok{(null.mu }\OperatorTok{-}\StringTok{ }\NormalTok{diff.mean, null.mu, null.SE.mean, }\DataTypeTok{lower.tail =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{pnorm}\NormalTok{(null.mu }\OperatorTok{+}\StringTok{ }\NormalTok{diff.mean, null.mu, null.SE.mean, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{)}

\NormalTok{p.value}
\CommentTok{#> [1] 0.008915324}
\end{Highlighting}
\end{Shaded}

The p-value given above should be very close to the estimate you
generated via simulation in the previous assignment.

\hypertarget{example-handedness-of-toads}{%
\section{Example: Handedness of
toads}\label{example-handedness-of-toads}}

From Whitlock \& Schluter:

Most humans are right handed. Do animals besides human exhibit biased
handedness? Bisazza et al. (1996) tested the possiblity of biased
handedness in European toads, \emph{Bufo bufo}. They sampled 18 toads
and used a behavioral assay to determine the preferred hand each
individual frog used to perform a task.

\hypertarget{null-and-alternative-hypotheses-2}{%
\subsection{Null and alternative
hypotheses}\label{null-and-alternative-hypotheses-2}}

\begin{itemize}
\tightlist
\item
  \(H_0\): toads do not exhibit any bias towards right or left
  handedness, i.e.~p(right handed) = 0.5
\item
  \(H_A\): right and left handedness are not equally frequent in the
  population, i.e.~p(right haned) \(\neq\) 0.5
\end{itemize}

\hypertarget{data-2}{%
\subsection{Data}\label{data-2}}

Of the 18 toads tested, 14 were right-handed and 4 were left handed.
Therefore, the observed proportion of right-handed toads was 0.778

\hypertarget{sampling-distribution-for-proportions-binomial-distribution}{%
\subsection{Sampling distribution for proportions: Binomial
distribution}\label{sampling-distribution-for-proportions-binomial-distribution}}

To assess how likely it would be to observe the proportion 0.778 of
right-handed toads, \emph{if the null hypothesis of equal probability of
right- and left-handed toads was true}, we need to know the appropriate
sampling distribution.

Here we're dealing with binary outcomes for each outcome -- each frog is
either right or left handed. For data with binary outcomes we can
arbitrary call one outcome a ``success''. If we assume that there is a
fixed probability of getting a success, and each observation is
independent, than the \textbf{binomial distribution} provides the
probability distribution for the number of ``successes'' in a given
number of trails (observations).

Let's call the outcome ``right-handed'' the successful outcome and let's
generate the expected counts of successes under the null hypothesis
(i.e.~p(right handed) = 0.5). As we saw in a previous lecture, we can
use \texttt{dbinom()} function, which is the probability mass function
for the binomial distribution. Given a vector of outcome of interest,
the number of trails, and the probability of a success, \texttt{dbinom}
calculates the probability of each outcome.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possible.outcomes <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{18}\NormalTok{)}
\NormalTok{H0.prob =}\StringTok{ }\FloatTok{0.5}
\NormalTok{prob.distn <-}\StringTok{ }\KeywordTok{dbinom}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ possible.outcomes, }\DataTypeTok{size =} \DecValTok{18}\NormalTok{, }\DataTypeTok{prob =}\NormalTok{ H0.prob)}

\NormalTok{null.df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{outcomes =}\NormalTok{ possible.outcomes, }\DataTypeTok{probs =}\NormalTok{ prob.distn)}

\KeywordTok{ggplot}\NormalTok{(null.df) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_col}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ outcomes, }\DataTypeTok{y =}\NormalTok{ probs), }\DataTypeTok{width=}\FloatTok{0.25}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{breaks =}\NormalTok{ possible.outcomes) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"# of right-handed toads"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"probability"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"The null distribution for the observed number of right handed toads}\CharTok{\textbackslash{}n}\StringTok{Binomial distribution, p = 0.5, n = 18"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-401-1.pdf}

\hypertarget{calculating-a-p-value-for-the-binomial-test}{%
\subsection{Calculating a p-value for the binomial
test}\label{calculating-a-p-value-for-the-binomial-test}}

Our alternative hypothesis was stated as ``right and left handedness are
not equally frequent in the population''. This reflects the fact that we
did not have a strong a priori prediction about the direction of a
potential bias in handedness among toads.

Recall that a p-value represents the probability of observing the
parameter of interest (counts in this case) \emph{at least as extreme}
as that in our data, under the null distribution. There are two ways to
deviate from the null hypothesis -- observing more right-handed toads
than we expect OR observing fewer right-handed toads than we expect. To
calculate an appropriate p-value in this case we must consider
deviations in both directions. This is what we call a \textbf{two-tailed
test} because we must consider both tails of the sampling distribution.

In the present case, we need to add up the probability of observing 14
or more right-handed toads (right tail of the null distribution) and the
probability of observing 4 or fewer right-handed toads (left tail of the
null distribution).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{left.tail <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(null.df, outcomes }\OperatorTok{<=}\StringTok{ }\DecValTok{4}\NormalTok{) }\OperatorTok{%$%}\StringTok{ }\NormalTok{probs }\OperatorTok{%>%}\StringTok{ }\NormalTok{sum}
\NormalTok{right.tail <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(null.df, outcomes }\OperatorTok{>=}\StringTok{ }\DecValTok{14}\NormalTok{) }\OperatorTok{%$%}\StringTok{ }\NormalTok{probs }\OperatorTok{%>%}\StringTok{ }\NormalTok{sum}

\NormalTok{p.value <-}\StringTok{ }\NormalTok{left.tail }\OperatorTok{+}\StringTok{ }\NormalTok{right.tail}
\NormalTok{p.value}
\CommentTok{#> [1] 0.03088379}
\end{Highlighting}
\end{Shaded}

Our calculated p-value is approximately 0.031. If we the conventional
significance threshold of \(\alpha = 0.05\), our conclusion would be
``we reject the null hypothesis of equal probability of right- and
left-handed toads''.

\hypertarget{the-binom.test-function}{%
\subsection{\texorpdfstring{The \texttt{binom.test()}
function}{The binom.test() function}}\label{the-binom.test-function}}

The previous calculations can be conveniently carried out using the R
function \texttt{binom.test()}. The arguments to \texttt{binom.test()}
are the number of successes (\texttt{x}), the number of trials
(\texttt{n}), and the hypothesized probability of success (\texttt{p}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b.test <-}\StringTok{ }\KeywordTok{binom.test}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DataTypeTok{p=}\FloatTok{0.5}\NormalTok{, }\DataTypeTok{alternative=}\StringTok{"two.sided"}\NormalTok{)}
\NormalTok{b.test}
\CommentTok{#> }
\CommentTok{#>  Exact binomial test}
\CommentTok{#> }
\CommentTok{#> data:  4 and 18}
\CommentTok{#> number of successes = 4, number of trials = 18, p-value = 0.03088}
\CommentTok{#> alternative hypothesis: true probability of success is not equal to 0.5}
\CommentTok{#> 95 percent confidence interval:}
\CommentTok{#>  0.06409205 0.47637277}
\CommentTok{#> sample estimates:}
\CommentTok{#> probability of success }
\CommentTok{#>              0.2222222}
\end{Highlighting}
\end{Shaded}

As shown above, display the results of \texttt{binom.test()} provides a
simple written summary. You can retrieve specific values using named
fields (see the documentation fo the full list):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b.test}\OperatorTok{$}\NormalTok{p.value  }\CommentTok{# gives the p-value under null}
\CommentTok{#> [1] 0.03088379}
\NormalTok{b.test}\OperatorTok{$}\NormalTok{estimate }\CommentTok{# gives the estimated probability from the data}
\CommentTok{#> probability of success }
\CommentTok{#>              0.2222222}
\end{Highlighting}
\end{Shaded}

\hypertarget{example-measuring-the-association-between-maternal-smoking-and-premature-births}{%
\section{Example: Measuring the association between maternal smoking and
premature
births}\label{example-measuring-the-association-between-maternal-smoking-and-premature-births}}

We've previously explored the
\href{https://raw.githubusercontent.com/Bio204-class/bio204-datasets/master/births.txt}{NC
Births} data set which includes information on mothers age, smoking
status, weight gained, birth weight, premature status, etc. We'll use
this data to explore the relationship between maternal smoking and
premature births:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{births <-}\StringTok{ }\KeywordTok{read_tsv}\NormalTok{(}\StringTok{"https://raw.githubusercontent.com/Bio204-class/bio204-datasets/master/births.txt"}\NormalTok{)}
\CommentTok{#> Parsed with column specification:}
\CommentTok{#> cols(}
\CommentTok{#>   fAge = col_integer(),}
\CommentTok{#>   mAge = col_integer(),}
\CommentTok{#>   weeks = col_integer(),}
\CommentTok{#>   premature = col_character(),}
\CommentTok{#>   visits = col_integer(),}
\CommentTok{#>   gained = col_integer(),}
\CommentTok{#>   weight = col_double(),}
\CommentTok{#>   sexBaby = col_character(),}
\CommentTok{#>   smoke = col_character()}
\CommentTok{#> )}

\KeywordTok{xtabs}\NormalTok{(}\OperatorTok{~}\NormalTok{premature }\OperatorTok{+}\StringTok{ }\NormalTok{smoke, births)}
\CommentTok{#>            smoke}
\CommentTok{#> premature   nonsmoker smoker}
\CommentTok{#>   full term        87     42}
\CommentTok{#>   premie           13      8}
\end{Highlighting}
\end{Shaded}

\hypertarget{null-and-alternative-hypotheses-3}{%
\subsection{Null and alternative
hypotheses:}\label{null-and-alternative-hypotheses-3}}

\begin{itemize}
\tightlist
\item
  \(H_0\): there is no association between maternal smoking and
  premature birth
\item
  \(H_A\): there is an association between maternal smoking and
  premature birth
\end{itemize}

\hypertarget{contingency-table-analysis-using-the-chi2-statistic}{%
\subsection{\texorpdfstring{Contingency table analysis using the
\(\chi^2\)
statistic}{Contingency table analysis using the \textbackslash{}chi\^{}2 statistic}}\label{contingency-table-analysis-using-the-chi2-statistic}}

In our class session on contingency analysis we introduced the
\(\chi^2\) statistic as a measure of association between categorical
variables (see
\href{https://github.com/bio304-class/bio304-course-notes/raw/master/slides/bivariate-association.pdf}{previous
notes}).

Giving a contingency table of observed counts, we can calculate the
expected counts under independence of the variables. Based on the
observed and expected counts, the \(\chi^2\) (chi-squared) statistic is
defined as:

\begin{align}
\chi^2 &= \frac{(O_{11} - E_{11})^2}{E_{11}} + \frac{(O_{12} - E_{12})^2}{E_{12}} + \cdots + \frac{(O_{mn} - E_{mn})^2}{E_{mn}} \\
\\
&= \sum_{i=1}^{m}\sum_{j=1}^{n} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}
\end{align}

where \(m\) and \(n\) are the number of categories of the two variables
under consideration. The larger the \(\chi^2\)-statistic the stronger
the evidence that the categorical variables are \emph{not independent}.

\hypertarget{chi2-distribution}{%
\subsection{\texorpdfstring{\(\chi^2\)-distribution}{\textbackslash{}chi\^{}2-distribution}}\label{chi2-distribution}}

This sampling distribution of the \(\chi^2\)-statistic \emph{when the
rows and columns variables of a contingency table are indepdent} is the
\(\chi^2\)-distribution. The shape of the \(\chi^2\)-distribution
depends on a parameter called the ``degrees of freedom'' (abbreviated
df). For contingency table analysis, the degrees of freedom is:
\(df = (m - 1)(n - 1)\) where \(m\) and \(n\) are the number of rows and
columns of the table.

Here is the \(\chi^2\)-distribution with df = 1:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{chi2.values <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DataTypeTok{by =} \FloatTok{0.05}\NormalTok{)}
\NormalTok{chi2.density <-}\StringTok{ }\KeywordTok{dchisq}\NormalTok{(chi2.values, }\DataTypeTok{df =} \DecValTok{1}\NormalTok{)}
\NormalTok{chi2.df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{chi2 =}\NormalTok{ chi2.values, }\DataTypeTok{density =}\NormalTok{ chi2.density)}

\KeywordTok{ggplot}\NormalTok{(chi2.df, }\KeywordTok{aes}\NormalTok{(chi2, density)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Chi2 statistic"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Density"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Probability Distribution for Chi2_df=1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-406-1.pdf}

For \(\chi^2\) analysis of contigency tables, hypothesis tests are
always one-tailed. That is, in contigency analysis were are always
asking ``what is the probability of observing a \(\chi^2\) statistic at
least this large under the null hypothesis of no association?''

\hypertarget{carrying-out-a-hypothesis-test-using-the-chi2}{%
\subsection{\texorpdfstring{Carrying out a hypothesis test using the
\(\chi^2\)}{Carrying out a hypothesis test using the \textbackslash{}chi\^{}2}}\label{carrying-out-a-hypothesis-test-using-the-chi2}}

Under the null distribution, the sampling distribution of the \(\chi^2\)
statistic is given by the \(\chi^2\) distribution with df = 1. We use
the built-in \texttt{chisq.test} function to calculate the \(\chi^2\)
value for the observed data and to calculate a corresponding p-value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{chi2.births <-}\StringTok{ }\KeywordTok{chisq.test}\NormalTok{(births}\OperatorTok{$}\NormalTok{premature, births}\OperatorTok{$}\NormalTok{smoke, }\DataTypeTok{correct =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{chi2.results <-}\StringTok{ }\KeywordTok{glance}\NormalTok{(chi2.births)}
\NormalTok{chi2.results}
\CommentTok{#> # A tibble: 1 x 4}
\CommentTok{#>   statistic p.value parameter method                    }
\CommentTok{#>       <dbl>   <dbl>     <int> <chr>                     }
\CommentTok{#> 1    0.2492  0.6177         1 Pearson's Chi-squared test}
\end{Highlighting}
\end{Shaded}

\hypertarget{interpretation-of-the-chi2-test}{%
\subsection{\texorpdfstring{Interpretation of the
\(\chi^2\)-test}{Interpretation of the \textbackslash{}chi\^{}2-test}}\label{interpretation-of-the-chi2-test}}

Our point estimate of the \(\chi^2\) statistic for the births data is
0.2491694 and the associated p-value is 0.6176605. Given this, we say we
``fail to reject the null hypothesis of no difference the rate of
premature births between smoking and non-smoking mothers''.

For further insight into why the \(\chi^2\) statistic is small in this
case, compare the observed and expected counts. As you'll see, the
values are barely differnt:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{chi2.births}\OperatorTok{$}\NormalTok{observed}
\CommentTok{#>                 births$smoke}
\CommentTok{#> births$premature nonsmoker smoker}
\CommentTok{#>        full term        87     42}
\CommentTok{#>        premie           13      8}
\NormalTok{chi2.births}\OperatorTok{$}\NormalTok{expected}
\CommentTok{#>                 births$smoke}
\CommentTok{#> births$premature nonsmoker smoker}
\CommentTok{#>        full term        86     43}
\CommentTok{#>        premie           14      7}
\end{Highlighting}
\end{Shaded}

As mentioned previously, failing to reject a null hypothesis is not the
same as accepting the null hypothesis. When it comes to human health and
disease and environmental exposures, the magnitude of effects is often
very small and you often need thousands of samples to detect an effect.
For example, a relationship between maternal smoking and premature
births is well supported by multiple large studies. However, the sample
we're using in this case is rather modest (150 births) and hence not
well powered to detect modest effects. We'll discuss this further when
we talk about the topic of statistical power.

\hypertarget{introduction-to-confidence-intervals}{%
\chapter{Introduction to confidence
intervals}\label{introduction-to-confidence-intervals}}

Recall the concept of the \textbf{sampling distribution of a statistic}
-- this is simply the probability distribution of the statistic of
interest you would observe if you took a large number of random samples
of a given size from a population of interest and calculated that
statistic for each of the samples.

You learned that the standard deviation of the sampling distribution of
a statistic has a special name -- the \textbf{standard error} of that
statistic. The standard error of a statistic provides a way to quantify
the uncertainty of a statistic across random samples. Here we show how
to use information about the standard error of a statistic to calculate
plausible ranges for a statistic of interest that take into account the
uncertainty of our estimates. We call such plausible ranges
\textbf{Confidence Intervals}.

\hypertarget{confidence-intervals}{%
\section{Confidence Intervals}\label{confidence-intervals}}

We know that given a random sample from a population of interest, the
value of a statistic of interest is unlikely to be exactly equally to
the true population value of that statistic. However, our simulations
have taught us a number of things:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  As sample size increases, the \emph{sample estimate} of the given
  statistic is more likely to be close to the true value of that
  statistic
\item
  As sample size increases, the standard error of the statistic
  decreases
\end{enumerate}

We will define an ``X\% percent confidence interval for a statistic of
interest'', as an interval (upper and lower bound) that when calculated
from a random sample, would include the true population value of the
statistic of interest, X\% of the time.

This quote from the
\href{http://www.itl.nist.gov/div898/handbook/eda/section3/eda352.htm}{NIST
page on confidence intervals}, which I've adapted to refer to any
statistic, helps to make this concrete regarding confidence intervals:

\begin{quote}
As a technical note, a 95\% confidence interval does not mean that there
is a 95\% probability that the interval contains the true
{[}statistic{]}. The interval computed from a given sample either
contains the true {[}statistic{]} or it does not. Instead, \textbf{the
level of confidence is associated with the method of calculating the
interval} \ldots{} That is, for a 95\% confidence interval, if many
samples are collected and the confidence interval computed, in the long
run about 95\% of these intervals would contain the true
{[}statistic{]}.
\end{quote}

The idea behind a 95\% confidence interval is illustrated in the
following figure:

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./figures/fig-CIs} 

}

\caption{Point estimates and confidence intervals for a theoretical statistic of interest.}\label{fig:unnamed-chunk-409}
\end{figure}

\hypertarget{generic-formulation-for-confidence-intervals}{%
\section{Generic formulation for confidence
intervals}\label{generic-formulation-for-confidence-intervals}}

We define the \((100\times\beta)\)\% confidence interval for the
statistic \(\phi\) as the interval:

\[
CI_\beta = \phi_{n} \pm (z \times {SE}_{\phi,n})
\]

Where:

\begin{itemize}
\tightlist
\item
  \(\phi_{n}\) is the statistic of interest in a random sample of size
  \(n\)
\item
  \({SE}_{\phi,n}\) is the standard error of the statistic \(\phi\) (via
  simulation or analytical solution)
\end{itemize}

And the value of \(z\) is chosen so that:

\begin{itemize}
\tightlist
\item
  across many different random samples of size \(n\), the true value of
  the \(\phi\) in the population of interest would fall within the
  interval approximately \((100\times\beta)\)\% of the time
\end{itemize}

So rather than estimating a single value of \(\phi\) from our data, we
will use our observed data plus knowledge about the sampling
distribution of \(\phi\) to estimate a range of plausible values for
\(\phi\). The size of this interval will be chosen so that if we
considered many possible random samples, the true population value of
\(\phi\) would be bracketed by the interval in \((100\times\beta)\)\% of
the samples.

\hypertarget{example-confidence-intervals-for-the-mean}{%
\section{Example: Confidence intervals for the
mean}\label{example-confidence-intervals-for-the-mean}}

To make the idea of a confidence interval more concrete, let's consider
confidence intervals for the mean of a normally distributed variable.

Recall that if a variable \(X\) is normally distributed in a population
of interest, \(X \sim N(\mu, \sigma)\), then the sampling distribution
of the mean of \(X\) is also normally distributed with mean \(\mu\), and
standard error \({SE}_{\overline{X}} = \frac{\sigma}{\sqrt{n}}\):

\[
\overline{X} \sim N \left( \mu, \frac{\sigma}{\sqrt{n}}\ \right)
\] In our simulation we will explore how varying the value of \(z\)
changes the percentage of times that the confidence interval brackets
the true population mean.

\hypertarget{simulation-of-means}{%
\subsection{Simulation of means}\label{simulation-of-means}}

In our simulation we're going to generate a large number of samples, and
for each sample we will calculate the sample estimate of the mean, and
then quantify how much each sample mean differs from the true mean in
terms of units of the population standard error of the mean. We'll then
use this information to calibrate the wide of our confidence intervals.

For the sake of simplicity we'll simulate sampling from the ``Standard
Normal Distribution'' -- a normal distribution with mean \(\mu=0\), and
standard deviation \(\sigma=1\).

First we load our standard libraries:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(magrittr)}
\end{Highlighting}
\end{Shaded}

Then we write our basic framework for our simulations:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rnorm.stats <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, mu, sigma) \{}
\NormalTok{  s <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(n, mu, sigma)}
\NormalTok{  df <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{sample.size =}\NormalTok{ n,}
                   \DataTypeTok{sample.mean =} \KeywordTok{mean}\NormalTok{(s),}
                   \DataTypeTok{sample.sd =} \KeywordTok{sd}\NormalTok{(s),}
                   \DataTypeTok{pop.SE =}\NormalTok{ sigma}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And then use this to simulate samples of size 25.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{20180328}\NormalTok{) }\CommentTok{# initialize RNG seed}

\NormalTok{true.mean <-}\StringTok{ }\DecValTok{0}
\NormalTok{true.sd <-}\StringTok{ }\DecValTok{11}
\NormalTok{n <-}\StringTok{ }\DecValTok{25}

\NormalTok{samples}\FloatTok{.25}\NormalTok{ <-}\StringTok{ }
\StringTok{  }\KeywordTok{rerun}\NormalTok{(}\DecValTok{10000}\NormalTok{, }\KeywordTok{rnorm.stats}\NormalTok{(n, true.mean, true.sd)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{distance-between-sample-means-and-true-means}{%
\subsection{Distance between sample means and true
means}\label{distance-between-sample-means-and-true-means}}

We append a new column to our \texttt{samples.25} data frame, which is
the result of calculating the distance of each sample mean from the true
mean, expressed in terms of units of the population standard error of
the mean:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples}\FloatTok{.25}\NormalTok{ <-}
\StringTok{  }\NormalTok{samples}\FloatTok{.25} \OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{z.pop =}\NormalTok{ (sample.mean }\OperatorTok{-}\StringTok{ }\NormalTok{true.mean)}\OperatorTok{/}\NormalTok{pop.SE)}
\end{Highlighting}
\end{Shaded}

Since the sampling distribution of the mean of a normally distributed
variable (\(N(\mu,\sigma)\)) is itself normally distributed
(\(N(\mu, SE_{\overline{X}})\)), then the distribution of
\(z = \frac{\overline{X} - \mu}{SE}\) is \(N(0,1)\). This is illustrated
in the figure below where we compare our simulated z-scores to the
theoretical expectation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SE <-}\StringTok{ }\DecValTok{1}
\KeywordTok{ggplot}\NormalTok{(samples}\FloatTok{.25}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ z.pop, }\DataTypeTok{y=}\NormalTok{..density..), }\DataTypeTok{bins=}\DecValTok{50}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =} \ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{dnorm}\NormalTok{(x, }\DataTypeTok{mean=}\DecValTok{0}\NormalTok{, }\DataTypeTok{sd=}\NormalTok{SE)\}, }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-414-1.pdf}

For a given value of \(z\) we can ask what fraction of our simulated
means fall within \(\pm z\) standard errors of the true mean.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples}\FloatTok{.25} \OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{frac.win.1SE =} \KeywordTok{sum}\NormalTok{(}\KeywordTok{abs}\NormalTok{(z.pop) }\OperatorTok{<=}\StringTok{ }\DecValTok{1}\NormalTok{)}\OperatorTok{/}\KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{frac.win.2SE =} \KeywordTok{sum}\NormalTok{(}\KeywordTok{abs}\NormalTok{(z.pop) }\OperatorTok{<=}\StringTok{ }\DecValTok{2}\NormalTok{)}\OperatorTok{/}\KeywordTok{n}\NormalTok{())}
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>   frac.win.1SE frac.win.2SE}
\CommentTok{#>          <dbl>        <dbl>}
\CommentTok{#> 1       0.6826       0.9549}
\end{Highlighting}
\end{Shaded}

We see that roughly 68\% of our sample means are within 1 SE of the true
mean; \textasciitilde{}95\% are within 2 SEs.

If we wanted to get exact multiples of the SE corresponding to different
percentiles of the distribution of z-scores, based on the theoretical
result (z scores \textasciitilde{} \(N(0,1)\)), we can use the
\texttt{qnorm()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{frac.of.interest <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.68}\NormalTok{, }\FloatTok{0.90}\NormalTok{, }\FloatTok{0.95}\NormalTok{, }\FloatTok{0.99}\NormalTok{)}

\CommentTok{# we use 1 - frac to get left most critical value}
\CommentTok{# we divide by two here two account for area under left and right tails}
\NormalTok{left.critical.value <-}\StringTok{ }\KeywordTok{qnorm}\NormalTok{((}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{frac.of.interest)}\OperatorTok{/}\DecValTok{2}\NormalTok{, }\DataTypeTok{mean =} \DecValTok{0}\NormalTok{, }\DataTypeTok{sd=}\DecValTok{1}\NormalTok{) }

\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{Percentile =}\NormalTok{ frac.of.interest }\OperatorTok{*}\StringTok{ }\DecValTok{100}\NormalTok{,}
           \DataTypeTok{Critical.value =} \KeywordTok{abs}\NormalTok{(left.critical.value))}
\CommentTok{#> # A tibble: 4 x 2}
\CommentTok{#>   Percentile Critical.value}
\CommentTok{#>        <dbl>          <dbl>}
\CommentTok{#> 1         68         0.9945}
\CommentTok{#> 2         90         1.645 }
\CommentTok{#> 3         95         1.960 }
\CommentTok{#> 4         99         2.576}
\end{Highlighting}
\end{Shaded}

\hypertarget{calculating-a-ci}{%
\subsection{Calculating a CI}\label{calculating-a-ci}}

If we knew the standard error of the mean for variable of interest, in
order to a confidence interval we could simply look up the corresponding
critical value for our percentile of interst in a table like the one
above and calculate our CI as:

\[
\overline{X} \pm \text{critical value} \times SE_{\overline{X}}
\]

For example, we see that the critical value for 95\% CIs is
\textasciitilde{}1.96.

\hypertarget{a-problem-arises}{%
\section{A problem arises!}\label{a-problem-arises}}

If you're a critical reader you should have noticed that calculating
confidence intervals using the above formula presumes we know the
standard error of the mean for the variable of interest. If we knew the
standard deviation, \(\sigma\), of our variable, we could calculate this
as \(SE_{\overline{x}} = \frac{\sigma}{\sqrt{n}}\) but in general we do
not know \(\sigma\) either.

Instead we must estimate the standard error of the mean using our sample
standard deviation:

\[
\widehat{SE}_{\overline{x}} = \frac{s_x}{\sqrt{n}}
\]

This introduces another level of uncertainty and also a complication.
The complication is due to the fact that for small samples, sample
estimates of the standard deviation tend to be biased (smaller) relative
to the true population standard deviation (see workbook Chapter 15).

In the assignment for this class session you will explore how we can
deal with the fact of biased estimates of standard deviations for small
samples, and how it effects our calculation of confidence intervals for
the mean.

\hypertarget{normal-distributions}{%
\chapter{Normal distributions}\label{normal-distributions}}

This exposition is based on Diez et al.~2015, OpenIntro Statistics (3rd
Edition) and Whitlock and Schluter, 2015. The Analysis of Biological
Data (2nd Edition).

\hypertarget{basics-about-normal-distributions}{%
\section{Basics about normal
distributions}\label{basics-about-normal-distributions}}

\begin{figure}

{\centering \includegraphics{bio304-book_files/figure-latex/unnamed-chunk-418-1} 

}

\caption{A normal distribution with mean  and standard deviation }\label{fig:unnamed-chunk-418}
\end{figure}

Normal distributions are:

\begin{itemize}
\tightlist
\item
  Unimodal
\item
  Symmetric
\item
  Described by two parameters -- \(\mu\) (mean) and \(\sigma\) (standard
  deviation)
\end{itemize}

\hypertarget{notation}{%
\subsection{Notation}\label{notation}}

\begin{itemize}
\tightlist
\item
  If a variable \(X\) is approximately normally distributed with mean,
  \(\mu\), and standard deviation, \(\sigma\), we write:
  \(X \sim N(\mu,\sigma)\)
\end{itemize}

\hypertarget{normal-distribution-probability-density-function}{%
\section{Normal distribution, probability density
function}\label{normal-distribution-probability-density-function}}

The probability density function for a normal distribution
\(N(\mu,\sigma)\) is described by the following equation:

\[
f(x|\mu,\sigma) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\]

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-419-1.pdf}

\hypertarget{dnorm-calculates-the-normal-pdf}{%
\subsection{\texorpdfstring{\texttt{dnorm()} calculates the normal
pdf}{dnorm() calculates the normal pdf}}\label{dnorm-calculates-the-normal-pdf}}

\begin{itemize}
\tightlist
\item
  In R, the function \texttt{dnorm(x,\ mu,\ sigma)} calculates the
  probability density of \(N(\mu,\sigma)\) at the point \(x\)
\end{itemize}

\hypertarget{approximately-normal-distributions-are-very-common}{%
\section{Approximately normal distributions are very
common}\label{approximately-normal-distributions-are-very-common}}

The normal approximation is a good approximation to patterns of
variation seen in biology, economics, and many other fields.

The following figure, from your texbook, shows distributions for (a)
human body temperature, (b) university undergraduate brain size, and (c)
numbers of abdominal bristles on Drosophila fruit flies:

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./figures/fig-normals-horiz} 

}

\caption{Examples of biological variables that are nearly normal. From Whitlock and Schluter, Chap 10}\label{fig:unnamed-chunk-420}
\end{figure}

\hypertarget{central-limit-theorem}{%
\section{Central limit theorem}\label{central-limit-theorem}}

Why is the normal distribution so ubiquitious? A key reason is the
``Central Limit Theorem''

The \textbf{Central Limit Theorem (CLT)} states the sum or mean of a
large number of random measurements sampled from a population is
approximately normally distributed, \emph{regardless of the shape of the
distribution from which they are drawn.}

Many biological traits can be thought of as being produced by the
summation many small effects. Even if those effect have a non-normal
distribution, the sum of their effects is approximately normal.

\hypertarget{example-continuous-variation-from-discrete-loci}{%
\subsection{Example: Continuous variation from discrete
loci}\label{example-continuous-variation-from-discrete-loci}}

Studies of the genetic basis of traits like height or weight, indicate
that traits like these have a ``multigenic'' basis. That is, there are
many genomic regions (loci) that each contribute a small amount to
difference in height among individuals.

For the sake of illustration let's assume there are 200 loci scattered
across the genome that affect height. And that each locus has an effect
on size that is exponentially distributed with a mean of 0.8cm, and that
an individuals total height is the sum of the effects at each of these
individual loci.

In the figure below, the first plot show what the distribution of effect
sizes looks. This is quite clearly a non-normal distribution. The second
plot show what the distribution of heights of 100 individuals generated
using the additive model above would look like. This second plot is
approximately normal, as predicted by the CLT.

\begin{center}\includegraphics[width=0.9\linewidth]{bio304-book_files/figure-latex/unnamed-chunk-421-1} \end{center}

\hypertarget{visualizing-normal-distributions}{%
\section{Visualizing normal
distributions}\label{visualizing-normal-distributions}}

\begin{itemize}
\tightlist
\item
  Different normal distributions look alike when plotted on their own
  scales
\end{itemize}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-422-1.pdf}

\begin{itemize}
\tightlist
\item
  Must plot normals on a common scale to see the differences
\end{itemize}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-423-1.pdf}

\hypertarget{comparing-values-from-different-normal-distributions}{%
\section{Comparing values from different normal
distributions}\label{comparing-values-from-different-normal-distributions}}

Q: SAT scores are approximately normally distributed with a mean of 1060
and a standard deviation of 195. ACT scores are approximately normal
with a mean of 20.9 and a standard deviation of 5.6. A college
admissions officer wants to determine which of the two applicants scored
better on their standardized test with respect to the other test takers:
Malaika, who earned an 1350 on her SAT, or Jim, who scored a 28 on his
ACT?

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-424-1.pdf}

A: Since the scores are measured on different scales we can not directly
compare them, however we can measure the difference of each score in
terms of units of standard deviation

\hypertarget{standardized-or-z-scores}{%
\subsection{Standardized or Z-scores}\label{standardized-or-z-scores}}

Differences from the mean, measured in units of standard deviation are
called ``standardized scores'' or ``Z-scores''

\begin{itemize}
\item
  The Z score of an observation is the number of standard deviations it
  falls above or below the mean. \[
  Z_i = \frac{x_i - \mu}{\sigma}
  \]
\item
  For our SAT/ACT example above:
\end{itemize}

\begin{align}
Z_\text{Malaika} &= \frac{1350 - 1060}{195} = 1.49\\
\\
Z_\text{Jim} &= \frac{28 - 20.9}{5.6} = 1.27\\
\end{align}

In this case, Malaika's score is 1.49 standard deviation above the mean,
while Jim's is 1.27. Based on this, Malaika scored better than Jim.

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-425-1.pdf}

\hypertarget{standard-normal-distribution}{%
\section{Standard normal
distribution}\label{standard-normal-distribution}}

\begin{itemize}
\item
  If \(X \sim N(\mu,\sigma)\) then the standardized distribution,
  \(Z_X \sim N(0,1)\). If \(X\) is normally distributed, then the
  Z-scores based on \(X\) have a mean of 0 and a standard deviation of
  1.
\item
  \(N(0,1)\) is known as the \textbf{standard normal distribution}
\end{itemize}

\hypertarget{rule}{%
\section{88-95-99.7 Rule}\label{rule}}

If data are approximately normally distributed:

\begin{itemize}
\tightlist
\item
  \textasciitilde{}68\% of observations lie within 1 SD of the mean
\item
  \textasciitilde{}95\% of observations lie within 2 SD of the mean
\item
  \textasciitilde{}99.7\% of observations lie within 3 SD of the mean
\end{itemize}

\begin{center}\includegraphics[width=0.6\linewidth]{bio304-book_files/figure-latex/unnamed-chunk-426-1} \end{center}

\hypertarget{percentiles}{%
\section{Percentiles}\label{percentiles}}

\begin{itemize}
\item
  The \emph{percentile} is the percentage of observations that fall
  below a given point, \(q\)
\item
  In R, for a normal distribution the fraction of observations below a
  given point (the probability that a random observation drawn from the
  distribution is less than the given value) can be calculatedusing the
  \texttt{pnorm(q,\ mu,\ sigma)} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Malaika's z-score was 1.49. What percentile was she in?}
\KeywordTok{pnorm}\NormalTok{(}\FloatTok{1.49}\NormalTok{) }
\CommentTok{#> [1] 0.9318879}
\end{Highlighting}
\end{Shaded}

  Therefore, Malaika is approximately at the 93-percentile. Note that we
  didn't have to include the mean and standard deviation in the call to
  pnorm because we're dealing with standardized scores, and the defaults
  for \texttt{pnorm} are \texttt{mean\ =\ 0} and \texttt{sd\ =\ 1}. A
  similar calculation would show that Jim's percentile is 89.7957685.
\end{itemize}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-428-1.pdf}

Note that if we want the fraction of the data to the right of a value
\(q\), we can subtract the value from one (\texttt{1\ -\ pnorm(1.49)})
or set the \texttt{lower.tail\ =\ FALSE} argument in in \texttt{pnorm}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pnorm}\NormalTok{(}\FloatTok{1.49}\NormalTok{, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{) }\CommentTok{# same as (1 - pnorm(1.49))}
\CommentTok{#> [1] 0.06811212}
\end{Highlighting}
\end{Shaded}

\hypertarget{cutoff-points}{%
\section{Cutoff points}\label{cutoff-points}}

\begin{itemize}
\item
  When we use the \texttt{pnorm()} function we specify a point, \(q\),
  and it gives us the corresponding fraction of values, \(p\), that fall
  below that point in a normal distibution
\item
  If instead we want to specify a fraction \(p\), and get the
  corresponding point, \(q\), on the normal distribution, we use the
  \texttt{qnorm(p,\ mu,\ sigma)} function.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# To get the 75-th percentile (3rd quartile) of SAT scores }
\CommentTok{# based on the parameters provided previously}
\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.75}\NormalTok{, }\DecValTok{1060}\NormalTok{, }\DecValTok{195}\NormalTok{)}
\CommentTok{#> [1] 1191.526}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.6\linewidth]{bio304-book_files/figure-latex/unnamed-chunk-431-1} \end{center}

\hypertarget{assessing-normality}{%
\section{Assessing normality}\label{assessing-normality}}

There are a number of graphical tools we have at our disposal to assess
approximate normality based on observations of a variable of interest.
There are also some formal tests we can apply. Here we focus on the
graphical tools.

\hypertarget{comparing-histograms-to-theoretical-normals}{%
\subsection{Comparing histograms to theoretical
normals}\label{comparing-histograms-to-theoretical-normals}}

One of the simplest approaches to assessing approximate normality for a
variable of interest is to plot a histogram of the observed variable,
and then to overlay on that histogram the probability density function
you would expect for a normal distribution with the same mean and
standard deviation.

In the example below I show a histogram of heights from a sample of 100
men, overlain with the PDF of a normal distribution with the mean and
standard deviation as estimated from the sample.

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-433-1.pdf}

The histogram matches fairly well to the theoretical normal, but
histograms are rather course visualizations when sample sizes are modst.

\hypertarget{normal-probability-plot}{%
\subsection{Normal probability plot}\label{normal-probability-plot}}

A second graphical tool for assessing normality is a ``normal
probability plot''. A normal probability plot is a type of scatter plot
for which the x-axis represents theoretical quantiles of a normal
distribution, and the y-axis represents the observed quantiles of our
observed data. If the observed data perfectly matched the normal
distribution with the same mean and standard deviation, then all the
points should fall on a straight line. Deviations from normality are
represented by runs of points off the line.

The ggplot functions \texttt{geom\_qq()} and \texttt{gome\_qq\_line()}
take care of the necessary calculations required to generate a normal
probability plot. Here is the normal probability plot for the male
height data:

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-434-1.pdf}

This plot suggests that the male heights are approximately normally
distributed, though there are maybe a few more very short men and a few
less very tall men in our sample then we would expect under perfect
normality.

\hypertarget{comparing-the-empirical-cdf-to-the-theoretical-cdf}{%
\subsection{Comparing the empirical CDF to the theoretical
CDF}\label{comparing-the-empirical-cdf-to-the-theoretical-cdf}}

A third visual approach is to estimate a cumulative distribution
function (CDF) for the variable of interest from the data and compare
this to the theoertical cumulative distribution function you'd expected
for a normal distribution (as provided by \texttt{pnorm()}). When you
estimate a cumulative distribution function from data, this is a called
an ``empirical CDF''.

The function \texttt{ggplot::stat\_ecdf} estimates the empirical CDF for
us and plots it, we can combine this with \texttt{stat\_function()} to
plot the theoertical CDF using pnorm, as shown below for the height
data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{male.heights }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ heights)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_ecdf}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun=}\NormalTok{pnorm, }
                \DataTypeTok{args=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{mean =}\NormalTok{ mean.height, }\DataTypeTok{sd =}\NormalTok{ sd.height),}
                \DataTypeTok{color=}\StringTok{'red'}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{'dashed'}\NormalTok{, }\DataTypeTok{n =} \DecValTok{200}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Height, h"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Prob(height < h)"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Emprirical (black) and Theoretical (red) CDFs}\CharTok{\textbackslash{}n}\StringTok{ for a normal distribution estiamted from observed male height data"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{plot.title =}\KeywordTok{element_text}\NormalTok{(}\DataTypeTok{size=}\DecValTok{10}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-435-1} \end{center}

Here the match between the empirical CDF and the theoretical CDF is
pretty good, again suggesting that the data is approximately normal.

\hypertarget{comparing-sample-means}{%
\chapter{Comparing sample means}\label{comparing-sample-means}}

\hypertarget{hypothesis-test-for-the-mean-using-the-t-distribution}{%
\section{Hypothesis test for the mean using the
t-distribution}\label{hypothesis-test-for-the-mean-using-the-t-distribution}}

We consider three different situations for hypothesis tests regarding
means.

\hypertarget{one-sample-t-test}{%
\section{One sample t-test}\label{one-sample-t-test}}

A one sample t-test is appropriate when you want to compare an observed
sample mean to some a priori hypothesis about what the mean should be.

\begin{itemize}
\tightlist
\item
  \(H_0\): The mean of variable \(X\) equals \(\mu_0\) (some a priori
  value for the mean)
\item
  \(H_A\): The mean of variable \(X\) does not equal \(\mu_0\)
\end{itemize}

\hypertarget{one-sample-t-test-test-statistic}{%
\subsection{One sample t-test, test
statistic}\label{one-sample-t-test-test-statistic}}

To carry out a one sample t-test, first calculate the test statistic:

\[
t^{\star} = \frac{\overline{x} - \mu_0}{SE_{\overline{x}}}
\]

where \(\overline{x}\) is the sample mean and \(SE_{\overline{x}}\) is
the sample standard error of the mean
(\(SE_{\overline{x}} = s_x/\sqrt{n}\)). In words, \(t^{\star}\) measures
the difference between the observed mean, and the null hypothesis mean,
in unit of standard error.

To calculate a P-value, we compare the test statistic to the
t-distribution with the appropriate degrees of freedom to calculate the
probability that you'd observe a mean value at least as extreme as
\(\overline{x}\) if the null hypothesis was true. For a two-tailed test
this is:

\[
P = P(t < -|t^\star|) + P(t > |t^\star|)
\]

Since the t-distribution is symmetric, this simplifies to:

\[
P = 2 \times P(t > |t^\star|)
\]

\hypertarget{assumptions-of-one-sample-t-tests}{%
\subsection{Assumptions of one sample
t-tests}\label{assumptions-of-one-sample-t-tests}}

\begin{itemize}
\tightlist
\item
  Data are randomly sampled from the population
\item
  The variable of interest is approximately normally distributed
\end{itemize}

\hypertarget{example-gene-expression-in-mice}{%
\subsection{Example: Gene expression in
mice}\label{example-gene-expression-in-mice}}

You are an investigator studying the effects of various drugs on the
expression of key genes that regulate apoptosis. The gene YFG1 is one
such gene of interest. It has been previously established, using very
sample sizes, that average expression level of the gene YFG1 in
untreated (control) mice is 10 units.

You treat a sample of mice with Drug X, and measure the expression of
the gene YFG1 following treatment. For a sample of five mice you observe
the following expression values:

\begin{itemize}
\tightlist
\item
  YFG1 = \{11.25, 10.5, 12, 11.75, 10\}
\end{itemize}

You wish to determine whether the average expression of YFG1 in mice
treated with the drug differs from control mice. The null and
alternative hypotheses for this hypothesis test are:

\begin{itemize}
\tightlist
\item
  \(H_0\): the mean expression of YFG1 is 10
\item
  \(H_A\): the mean expression of YFG1 does not equal 10
\end{itemize}

It's relatively easy to calculate the various quantities of interest
needed to carry out a one sided t-test:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}

\NormalTok{mu0 =}\StringTok{ }\DecValTok{10}  \CommentTok{# mean under H0}
\NormalTok{mice}\FloatTok{.1}\NormalTok{sample <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{YFG1 =} \KeywordTok{c}\NormalTok{(}\FloatTok{11.25}\NormalTok{, }\FloatTok{10.5}\NormalTok{, }\DecValTok{12}\NormalTok{, }\FloatTok{11.75}\NormalTok{, }\DecValTok{10}\NormalTok{))}

\NormalTok{YFG1.tstats <-}
\StringTok{  }\NormalTok{mice}\FloatTok{.1}\NormalTok{sample }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sample.mean =} \KeywordTok{mean}\NormalTok{(YFG1),}
            \DataTypeTok{sample.sd =} \KeywordTok{sd}\NormalTok{(YFG1),}
            \DataTypeTok{sample.se =}\NormalTok{ sample.sd}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{n}\NormalTok{()),}
            \DataTypeTok{df =} \KeywordTok{n}\NormalTok{() }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{,}
            \DataTypeTok{mu0 =}\NormalTok{ mu0,}
            \DataTypeTok{t.star =}\NormalTok{ (sample.mean }\OperatorTok{-}\StringTok{ }\NormalTok{mu0)}\OperatorTok{/}\NormalTok{sample.se,}
            \DataTypeTok{P.value =} \DecValTok{2} \OperatorTok{*}\StringTok{ }\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(t.star), }\DataTypeTok{df =}\NormalTok{ df, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{))}

\NormalTok{YFG1.tstats}
\CommentTok{#> # A tibble: 1 x 7}
\CommentTok{#>   sample.mean sample.sd sample.se    df   mu0 t.star P.value}
\CommentTok{#>         <dbl>     <dbl>     <dbl> <dbl> <dbl>  <dbl>   <dbl>}
\CommentTok{#> 1        11.1    0.8404    0.3758     4    10  2.927 0.04295}
\end{Highlighting}
\end{Shaded}

Under the conventional \(\alpha = 0.05\), we reject the null hypothesis
that the mean expression of YFG1 in mice treated with the drug is the
same as the mean expression of YFG1 in control mice.

\hypertarget{confidence-intervals-for-the-mean}{%
\subsection{Confidence intervals for the
mean}\label{confidence-intervals-for-the-mean}}

The hypothesis test using a one-side t-test we carried out above is
approximately equivalent to asking if the null mean, \(\mu_0\), falls
within the 95\% confidence intervals estimated for the sample mean.

Recall that the \(100(1-\alpha)\)\% confidence interval for the mean can
be calculated as

\[
CI_\alpha = \overline{x} \pm (t_{\alpha/2,df} \times \widehat{SE}_{\overline{x}})
\]

Let's modify the table of \(t\)-related stats we created in the previous
code block to include the lower and upper limits of the 95\% confidence
interval for the mean:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{YFG1.tstats <-}\StringTok{ }
\StringTok{  }\NormalTok{YFG1.tstats }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{ci95.lower =}\NormalTok{ sample.mean }\OperatorTok{-}\StringTok{ }\KeywordTok{abs}\NormalTok{(}\KeywordTok{qt}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\DataTypeTok{df =}\NormalTok{ df)) }\OperatorTok{*}\StringTok{ }\NormalTok{sample.se,}
         \DataTypeTok{ci95.upper =}\NormalTok{ sample.mean }\OperatorTok{+}\StringTok{ }\KeywordTok{abs}\NormalTok{(}\KeywordTok{qt}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\DataTypeTok{df =}\NormalTok{ df)) }\OperatorTok{*}\StringTok{ }\NormalTok{sample.se)}

\NormalTok{YFG1.tstats}
\CommentTok{#> # A tibble: 1 x 9}
\CommentTok{#>   sample.mean sample.sd sample.se    df   mu0 t.star P.value ci95.lower}
\CommentTok{#>         <dbl>     <dbl>     <dbl> <dbl> <dbl>  <dbl>   <dbl>      <dbl>}
\CommentTok{#> 1        11.1    0.8404    0.3758     4    10  2.927 0.04295      10.06}
\CommentTok{#> # ... with 1 more variable: ci95.upper <dbl>}
\end{Highlighting}
\end{Shaded}

If we wanted to crate a figure illustrating our 95\% CI for the mean of
YFG1 following drug treatment, relative to the mean under the null
hypothesis we can use the \texttt{geom\_pointrange()} function to draw
the interval (for more info on \texttt{geom\_pointrange()} and related
functions see the
\href{https://ggplot2.tidyverse.org/reference/geom_linerange.html}{ggplot2
documentation}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{YFG1.tstats }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_pointrange}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \DecValTok{1}\NormalTok{, }
                      \DataTypeTok{y =}\NormalTok{ sample.mean,}
                      \DataTypeTok{ymin =}\NormalTok{ ci95.lower, }\DataTypeTok{ymax =}\NormalTok{ ci95.upper)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{breaks=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{), }\DataTypeTok{labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"Drug X"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =}\NormalTok{ mu0, }\DataTypeTok{color=}\StringTok{'red'}\NormalTok{, }\DataTypeTok{linetype =} \StringTok{'dashed'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{15}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{""}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Mean(YFG1)"}\NormalTok{, }
       \DataTypeTok{title =} \StringTok{"Sample mean and 95% CI for expression of YFG1 in treated mice"}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"Red line indicates mean expression in control mice."}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_classic}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{plot.title =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{size =} \DecValTok{12}\NormalTok{),}
        \DataTypeTok{plot.subtitle =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{size =} \DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-439-1.pdf}

\hypertarget{the-t.test-function-in-r}{%
\section{\texorpdfstring{The \texttt{t.test} function in
R}{The t.test function in R}}\label{the-t.test-function-in-r}}

The built-in \texttt{t.test()} function will take care of the all the
calcuations we did by hand above.

For a one sample t-test \texttt{t.test} we need to pass in the variable
of interest, and the null hypothoses mean value, \texttt{mu}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{YFG1_t.test <-}\StringTok{ }\KeywordTok{t.test}\NormalTok{(mice}\FloatTok{.1}\NormalTok{sample}\OperatorTok{$}\NormalTok{YFG1, }\DataTypeTok{mu =} \DecValTok{10}\NormalTok{)}
\NormalTok{YFG1_t.test}
\CommentTok{#> }
\CommentTok{#>  One Sample t-test}
\CommentTok{#> }
\CommentTok{#> data:  mice.1sample$YFG1}
\CommentTok{#> t = 2.9268, df = 4, p-value = 0.04295}
\CommentTok{#> alternative hypothesis: true mean is not equal to 10}
\CommentTok{#> 95 percent confidence interval:}
\CommentTok{#>  10.05652 12.14348}
\CommentTok{#> sample estimates:}
\CommentTok{#> mean of x }
\CommentTok{#>      11.1}
\end{Highlighting}
\end{Shaded}

The \texttt{broom::tidye()} function defined in the ``broom'' package is
a convenient way to display the output of many model tests in R. Load
the broom (install it first if need be) and use \texttt{tidy()} to
represent the information returned by \texttt{t.test()} as a data frame:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}

\KeywordTok{tidy}\NormalTok{(YFG1_t.test)}
\CommentTok{#> # A tibble: 1 x 8}
\CommentTok{#>   estimate statistic p.value parameter conf.low conf.high method}
\CommentTok{#>      <dbl>     <dbl>   <dbl>     <dbl>    <dbl>     <dbl> <chr> }
\CommentTok{#> 1     11.1     2.927 0.04295         4    10.06     12.14 One S~}
\CommentTok{#> # ... with 1 more variable: alternative <chr>}
\end{Highlighting}
\end{Shaded}

\hypertarget{two-sample-t-test}{%
\section{Two sample t-test}\label{two-sample-t-test}}

We use a two sample t-test to analyze the difference between the means
of the same variable measured in two different groups or treatments. It
is assumed that the two groups are independent samples from two
populations.

\begin{itemize}
\item
  \(H_0\): The mean of variable \(X\) in group 1 is the same as the mean
  of \(X\) in group 2, i.e., \(\overline{x}_1 = \overline{x}_2\). This
  is equivalent to \(\overline{x}_1 - \overline{x}_2 = 0\).
\item
  \(H_A\): The mean of variable \(X\) in group 1 is not the same as the
  mean of \(X\) in group 2, i.e. \(\overline{x}_1 \neq \overline{x}_2\).
  This is equivalent to \(\overline{x}_1 - \overline{x}_2 \neq 0\).
\end{itemize}

\hypertarget{standard-error-for-the-difference-in-means}{%
\subsection{Standard error for the difference in
means}\label{standard-error-for-the-difference-in-means}}

In a two-sample t-test, we have to account for the uncertainty
associated with the means of both groups, which we express in terms of
the standard error of the difference in the means between the groups:

\[
SE_{\overline{x}_1 - \overline{x}_2}  =  \sqrt{s^2_p\left(\frac{1}{n_1} + \frac{1}{n_2} \right)}
\]

where

\[
s^2_p = \frac{df_1 s_1^2 + df_2 s_2^2}{df_1 + df_2}
\]

\(s^2_p\) is called the ``pooled sample variance'' and is a weighted
average of the sample variances, \(s_1^2\) and \(s_2^2\), of the two
groups.

\hypertarget{two-sample-t-test-test-statistic}{%
\subsection{Two sample t-test, test
statistic}\label{two-sample-t-test-test-statistic}}

Given the standard error for the difference in means between groups as
defined above, we define our test statistic for a two sample t-test as:

\[
t^\star = \frac{(\overline{x}_1 - \overline{x}_2)}{SE_{\overline{x}_1 - \overline{x}_2}}
\]

The degrees of freedom for this test statistic are:

\[
df = df_1 + df_2 = n_1 + n_2 - 2
\]

\hypertarget{assumptions-of-two-sample-t-test}{%
\subsection{Assumptions of two sample
t-test}\label{assumptions-of-two-sample-t-test}}

\begin{itemize}
\tightlist
\item
  Data are randomly sampled from the population
\item
  Paired differences are normally distributed
\item
  Standard deviation is the same in both populations
\end{itemize}

\hypertarget{example-comparing-the-effects-of-two-drugs}{%
\subsection{Example: Comparing the effects of two
drugs}\label{example-comparing-the-effects-of-two-drugs}}

You treat samples of mice with two drugs, X and Y. We want to know if
the two drugs have the same average effect on expression of the gene
\emph{YFG1}. The measurements of \emph{YFG1} in samples treated with X
and Y are as follows:

\begin{itemize}
\tightlist
\item
  X = \{11.25, 10.5, 12, 11.75, 10\}
\item
  Y = \{8.75, 10, 11, 9.75, 10.5\}
\end{itemize}

For simplicity, we skip the ``by-hand'' calculations and simply use the
built-in \texttt{t.test} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mice}\FloatTok{.2}\NormalTok{sample <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{YFG1_X =} \KeywordTok{c}\NormalTok{(}\FloatTok{11.25}\NormalTok{, }\FloatTok{10.5}\NormalTok{, }\DecValTok{12}\NormalTok{, }\FloatTok{11.75}\NormalTok{, }\DecValTok{10}\NormalTok{),}
                           \DataTypeTok{YFG1_Y =} \KeywordTok{c}\NormalTok{(}\FloatTok{8.75}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{11}\NormalTok{, }\FloatTok{9.75}\NormalTok{, }\FloatTok{10.5}\NormalTok{))}

\NormalTok{ttest}\FloatTok{.2}\NormalTok{sample <-}\StringTok{ }
\StringTok{  }\KeywordTok{t.test}\NormalTok{(mice}\FloatTok{.2}\NormalTok{sample}\OperatorTok{$}\NormalTok{YFG1_X, mice}\FloatTok{.2}\NormalTok{sample}\OperatorTok{$}\NormalTok{YFG1_Y)}

\NormalTok{ttest}\FloatTok{.2}\NormalTok{sample}
\CommentTok{#> }
\CommentTok{#>  Welch Two Sample t-test}
\CommentTok{#> }
\CommentTok{#> data:  mice.2sample$YFG1_X and mice.2sample$YFG1_Y}
\CommentTok{#> t = 2.0605, df = 7.9994, p-value = 0.07331}
\CommentTok{#> alternative hypothesis: true difference in means is not equal to 0}
\CommentTok{#> 95 percent confidence interval:}
\CommentTok{#>  -0.1310858  2.3310858}
\CommentTok{#> sample estimates:}
\CommentTok{#> mean of x mean of y }
\CommentTok{#>      11.1      10.0}
\end{Highlighting}
\end{Shaded}

This output provides information on:

\begin{itemize}
\tightlist
\item
  the data vectors used in this analysis
\item
  t, df, and p-value
\item
  the alternative hypothesis
\item
  the 95\% CI for the difference between the group means
\item
  the group means
\end{itemize}

Using a type I error cutoff of \(\alpha = 0.05\), we fail to reject the
null hypothesis that the mean expression of \emph{YFG1} is different in
mice treated with Drug X versus those treated with Drug Y.

As we saw previously, \texttt{broom::tidy()} is a good way to turn the
results of the \texttt{t.test()} function into a convenient table for
further computation or plotting:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(ttest}\FloatTok{.2}\NormalTok{sample)}
\CommentTok{#> # A tibble: 1 x 10}
\CommentTok{#>   estimate estimate1 estimate2 statistic p.value parameter conf.low}
\CommentTok{#>      <dbl>     <dbl>     <dbl>     <dbl>   <dbl>     <dbl>    <dbl>}
\CommentTok{#> 1    1.100      11.1        10     2.060 0.07331     7.999  -0.1311}
\CommentTok{#> # ... with 3 more variables: conf.high <dbl>, method <chr>,}
\CommentTok{#> #   alternative <chr>}
\end{Highlighting}
\end{Shaded}

\hypertarget{specifying-t.test-in-terms-of-a-formula}{%
\subsection{\texorpdfstring{Specifying \texttt{t.test()} in terms of a
formula}{Specifying t.test() in terms of a formula}}\label{specifying-t.test-in-terms-of-a-formula}}

In the example above, our data frame included two columns for YFG1
expression values -- \texttt{YFG1\_X} and \texttt{YFG1\_Y} --
representing the expression measurements under the two drug treatments.
This is not a very ``tidy'' way to organize our data, and is somewhat
limiting when we want to create plots and do other analyses. Let's use
some of the tools we've seen earlier for tidying and restructuring data
frames to unite these into a single column, and create a new column
indicating treatment type:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mice.long <-}
\StringTok{  }\NormalTok{mice}\FloatTok{.2}\NormalTok{sample }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(expt, expression) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{separate}\NormalTok{(expt, }\KeywordTok{c}\NormalTok{(}\StringTok{"gene"}\NormalTok{, }\StringTok{"treatment"}\NormalTok{), }\DataTypeTok{sep=}\StringTok{"_"}\NormalTok{)}

\KeywordTok{head}\NormalTok{(mice.long)}
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>   gene  treatment expression}
\CommentTok{#>   <chr> <chr>          <dbl>}
\CommentTok{#> 1 YFG1  X              11.25}
\CommentTok{#> 2 YFG1  X              10.5 }
\CommentTok{#> 3 YFG1  X              12   }
\CommentTok{#> 4 YFG1  X              11.75}
\CommentTok{#> 5 YFG1  X              10   }
\CommentTok{#> 6 YFG1  Y               8.75}
\end{Highlighting}
\end{Shaded}

Using this ``long'' data frame we can carry out the t.test as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ttest}\FloatTok{.2}\NormalTok{sample <-}\StringTok{ }\KeywordTok{t.test}\NormalTok{(expression }\OperatorTok{~}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{data =}\NormalTok{ mice.long)}
\NormalTok{ttest}\FloatTok{.2}\NormalTok{sample}
\CommentTok{#> }
\CommentTok{#>  Welch Two Sample t-test}
\CommentTok{#> }
\CommentTok{#> data:  expression by treatment}
\CommentTok{#> t = 2.0605, df = 7.9994, p-value = 0.07331}
\CommentTok{#> alternative hypothesis: true difference in means is not equal to 0}
\CommentTok{#> 95 percent confidence interval:}
\CommentTok{#>  -0.1310858  2.3310858}
\CommentTok{#> sample estimates:}
\CommentTok{#> mean in group X mean in group Y }
\CommentTok{#>            11.1            10.0}
\end{Highlighting}
\end{Shaded}

This long version of the data is also more easily used for calculating
confidence intervals of the mean for each treatment, and for plotting as
illustrated bloew

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ci.by.treatment <-}
\StringTok{  }\NormalTok{mice.long }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(treatment) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(expression),}
            \DataTypeTok{se =} \KeywordTok{sd}\NormalTok{(expression)}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{n}\NormalTok{()),}
            \DataTypeTok{tcrit =} \KeywordTok{abs}\NormalTok{(}\KeywordTok{qt}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\DataTypeTok{df =} \KeywordTok{n}\NormalTok{() }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)),}
            \DataTypeTok{ci.low =}\NormalTok{ mean }\OperatorTok{-}\StringTok{ }\NormalTok{tcrit }\OperatorTok{*}\StringTok{ }\NormalTok{se,}
            \DataTypeTok{ci.hi =}\NormalTok{ mean }\OperatorTok{+}\StringTok{ }\NormalTok{tcrit }\OperatorTok{*}\StringTok{ }\NormalTok{se)}

\NormalTok{ci.by.treatment}
\CommentTok{#> # A tibble: 2 x 6}
\CommentTok{#>   treatment  mean     se tcrit ci.low ci.hi}
\CommentTok{#>   <chr>     <dbl>  <dbl> <dbl>  <dbl> <dbl>}
\CommentTok{#> 1 X          11.1 0.3758 2.776 10.06  12.14}
\CommentTok{#> 2 Y          10   0.3791 2.776  8.947 11.05}
\end{Highlighting}
\end{Shaded}

Here I combine the raw expression measurements and mean and confidence
intervals into a single plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mice.long }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ treatment, }\DataTypeTok{y =}\NormalTok{ expression, }\DataTypeTok{color=}\NormalTok{treatment)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.35}\NormalTok{, }\DataTypeTok{shape=}\DecValTok{17}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_pointrange}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ ci.by.treatment,}
                  \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ treatment, }\DataTypeTok{y =}\NormalTok{ mean,}
                      \DataTypeTok{ymin =}\NormalTok{ ci.low, }\DataTypeTok{ymax=}\NormalTok{ ci.hi)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Drug Treatment"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Expression"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_classic}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{plot.caption =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{size=}\DecValTok{8}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-447-1.pdf}
\caption{\label{fig:unnamed-chunk-447}Expression of YFG1 for different drug
treatments. Triangles are individual measurements. Circles and lines
indicate group means and 95\% CIs of means.}
\end{figure}

\hypertarget{paired-t-test}{%
\section{Paired t-test}\label{paired-t-test}}

In a paired t-test there are two groups/treatments, but the samples in
the two groups are paired or matched. This typically arises in
``before-after'' studies where the same individual/object is measured at
different time points, before and after application of a treatment. The
repeated measurement of the same individual/object means that we can't
treat the two sets of observations as independent. Null and alternative
hypotheses are thus typically framed in terms of a mean difference
between time points/conditions

\begin{itemize}
\item
  \(H_0\): The mean difference of variable \(X\) in the paired
  measurements is zero, i.e., \(\overline{D} = 0\) where
  \(D = X_\text{after} - X_\text{before}\)
\item
  \(H_A\): The mean difference of variable \(X\) in the paired
  measurements is not zero, i.e., \(\overline{D} \neq 0\)
\end{itemize}

\hypertarget{paired-t-test-test-statistic}{%
\subsection{Paired t-test, test
statistic}\label{paired-t-test-test-statistic}}

\begin{itemize}
\tightlist
\item
  Let the variable of interest for individual \(i\) in the paired
  conditions be designated \(x_{i,\text{before}}\) and
  \(x_{i, \text{after}}\)
\item
  Let \(D_i = x_{i, \text{after}} - x_{i, \text{before}}\) be the paired
  difference for individual \(i\)
\item
  Let \(\overline{D}\) be the mean difference and \(s_D\) be the
  standard deviation of the differences
\item
  The standard error of the mean difference is
  \(SE(\overline{D}) = \frac{s_D}{\sqrt{n}}\)
\end{itemize}

The test statistic is thus: \[
t^\star = \frac{\overline{D}}{SE(\overline{D})}
\]

Under the null hypothesis, this statistic follows a t-distribution with
\(n-1\) degrees of freedom.

\hypertarget{assumptions-of-paired-t-test}{%
\subsection{Assumptions of paired
t-test}\label{assumptions-of-paired-t-test}}

\begin{itemize}
\tightlist
\item
  Data are randomly sampled from the population
\item
  Paired differences are normally distributed
\end{itemize}

\hypertarget{paired-t-test-example}{%
\subsection{Paired t-test, example}\label{paired-t-test-example}}

You measure the expression of gene \emph{YFG1} in five mice. You then
treat those five mice with drug Z and measure gene expression again.

\begin{itemize}
\tightlist
\item
  \emph{YFG1} expression before treatment = \{12, 11.75, 11.25, 10.5,
  10\}
\item
  \emph{YFG1} expression after treatment = \{11, 10, 10.50, 8.75, 9.75\}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mice.paired <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{YFG1.before =} \KeywordTok{c}\NormalTok{(}\DecValTok{12}\NormalTok{, }\FloatTok{11.75}\NormalTok{, }\FloatTok{11.25}\NormalTok{, }\FloatTok{10.5}\NormalTok{, }\DecValTok{10}\NormalTok{),}
                          \DataTypeTok{YFG1.after =} \KeywordTok{c}\NormalTok{(}\DecValTok{11}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FloatTok{10.50}\NormalTok{, }\FloatTok{8.75}\NormalTok{, }\FloatTok{9.75}\NormalTok{))}

\KeywordTok{t.test}\NormalTok{(mice.paired}\OperatorTok{$}\NormalTok{YFG1.before, mice.paired}\OperatorTok{$}\NormalTok{YFG1.after,}
       \DataTypeTok{paired =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{#> }
\CommentTok{#>  Paired t-test}
\CommentTok{#> }
\CommentTok{#> data:  mice.paired$YFG1.before and mice.paired$YFG1.after}
\CommentTok{#> t = 3.773, df = 4, p-value = 0.01955}
\CommentTok{#> alternative hypothesis: true difference in means is not equal to 0}
\CommentTok{#> 95 percent confidence interval:}
\CommentTok{#>  0.2905341 1.9094659}
\CommentTok{#> sample estimates:}
\CommentTok{#> mean of the differences }
\CommentTok{#>                     1.1}
\end{Highlighting}
\end{Shaded}

Using a type I error cutoff of \(\alpha = 0.05\), we reject the null
hypothesis of no difference in the average expression of \emph{YFG1}
before and after treatment with Drug Z.

\hypertarget{the-fallacy-of-indirect-comparison}{%
\section{The fallacy of indirect
comparison}\label{the-fallacy-of-indirect-comparison}}

WS 12.5 considers an example where baby photos were compared to photos
of their mother, father, and several unrelated pictures. Volunteers were
asked to identify the mother and father of each baby, and the accuracy
of their choices was compared between mothers and fathers. In Fig.
12.5-1 (below), the horizontal line shows the null hypotheses expected
for random guessing, while means and 95\% CIs are shown for mothers and
fathers. The success rate for picking fathers was significantly better
than random expectation, while the CI for mothers overlapped the null
expected value. Given these CIs, the authors of the study concluded that
babies resemble their fathers more than their mothers.

\includegraphics[width=0.75\linewidth]{./figures/whitlock_12.5-1}

This is an example of the fallacy of indirect comparison: ``Comparisons
between two groups should always be made directly, not indirectly by
comparing both to the same null hypothesis'' WS 12.5.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{interpreting-confidence-intervals-in-light-of-two-sample-t-tests}{%
\subsection{Interpreting confidence intervals in light of two sample
t-tests}\label{interpreting-confidence-intervals-in-light-of-two-sample-t-tests}}

Figure 12.6-1 from WS (below) considers the relationship between overlap
of confidence intervals and significant difference between groups
(\(H_0\): group means do not differ). Shown are group means and their
95\% confidence intervals in three cases. (a) When 95\% CIs do not
overlap, then group means will be significantly different. (b) When the
confidence interval of one group overlaps the mean value for the other
group, then the groups are not significantly different. Finally, (c)
when the confidence intervals overlap each other, but they do not
overlap the mean of the other group, then the result of the hypothesis
test is unclear.

In each case, figures with confidence intervals are helpful, but it is
the P-value from our test of \(H_0\) that provides clear indication for
our statistical conclusions.

\begin{figure}
\includegraphics[width=0.9\linewidth]{./figures/whitlock_12.6-1} \caption{Figure from Whitlock and Schluter, Chapter 12.}\label{fig:unnamed-chunk-450}
\end{figure}

\hypertarget{summary-table-for-different-t-tests}{%
\section{Summary table for different
t-tests}\label{summary-table-for-different-t-tests}}

Here is a summary table giving the test statistic and degrees of freedom
for each of the different types of t-tests described above. Notice that
they all boil down to a difference of two means, expressed in units of
standard error. The associated P-value associated with each test is thus
a measure of how surprising that scaled difference in means is under the
null model.

\begin{longtable}[]{@{}lcc@{}}
\toprule
\begin{minipage}[b]{0.29\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.47\columnwidth}\centering
test statistic\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\centering
df\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.29\columnwidth}\raggedright
one-sample\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\centering
\(\frac{\overline{x}-\mu_0}{SE_{\overline{x}}}\)\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
\(n-1\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
two-sample\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\centering
\(\frac{\overline{x}_1-\overline{x}_2}{SE_{(\overline{x}_1-\overline{x}_2})}\)\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
\(n_1 + n_2 - 2\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
paired\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\centering
\(\frac{\overline{D}-0}{SE_{\overline{D}}}\)\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\centering
\(n-1\)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{analysis-of-variance}{%
\chapter{Analysis of Variance}\label{analysis-of-variance}}

\(t\)-tests are the standard approach for comparing means between two
groups. When you want to compare means between more than two groups a
technique called ``Analysis of Variance'' (ANOVA) is used.

\hypertarget{hypotheses-for-anova}{%
\section{Hypotheses for ANOVA}\label{hypotheses-for-anova}}

When using ANOVA to compare means, the null and alternative hypotheses
are:

\begin{itemize}
\tightlist
\item
  \(H_0\): The means of all the groups are equal
\item
  \(H_A\): At least one of the means is different from the others
\end{itemize}

\hypertarget{anova-assumptions}{%
\section{ANOVA, assumptions}\label{anova-assumptions}}

ANOVA assumes:

\begin{itemize}
\tightlist
\item
  The measurements in every group represent a random sample from the
  corresponding population
\item
  The varaible of interest is normally distributed
\item
  The variance is approximately the same in all the groups
\end{itemize}

\hypertarget{anova-key-idea}{%
\section{ANOVA, key idea}\label{anova-key-idea}}

The key idea behind ANOVA is that:

\begin{itemize}
\tightlist
\item
  If the observations in each group are drawn from populations with
  equal means (and variances) then the variation \emph{between} group
  means should be similar to the inter-individual variation \emph{within
  groups}.
\end{itemize}

\hypertarget{partioning-of-sum-of-squares}{%
\section{Partioning of sum of
squares}\label{partioning-of-sum-of-squares}}

Another way to think about ANOVA is as a ``partitioning of variance''.
The total variance among all the individuals across groups can be
decomposed into:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  variance of the group means around the ``grand mean'';
\item
  variance of individuals around the group means.
\end{enumerate}

However, rather than using variance we use sums of square deviations
around the respectives means (usually shortened to ``sums of squares'').

This decomposition is represented visually in the figure below:

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./figures/whitlock_15.1-2} 

}

\caption{Whitock and Schluter, Fig 15.1.2 -- Illustrating the partitioning of sum of squares into $MS_{group}$ and $MS_{error}$ components. }\label{fig:unnamed-chunk-451}
\end{figure}

\hypertarget{mathematical-partitioning-of-sums-of-squares}{%
\section{Mathematical partitioning of sums of
squares}\label{mathematical-partitioning-of-sums-of-squares}}

Variable \(X\) with a total sample of \(N\) observations, partitioned
ito \(k\) groups. The sample size of the g-th group is \(n_g\), and thus
\(N = \sum_{g=1}^{k} n_g\). Let \(\overline{X}\) indicate the grand mean
of \(X\) and \(\overline{X}_g\) indicate the mean of \(X\) in the g-th
group.

\textbf{Total sums of squares}

We call the sum of the squared deviations around the grand mean the
``total sum of sqaures'' (\(SS_\text{total}\)).

\[
SS_\text{total} = \sum_{i=1}^N (x_i-\overline{X})^2
\]

\begin{itemize}
\tightlist
\item
  The total degrees of freedom is: \(df_\text{total} = N - 1\)
\end{itemize}

\textbf{Group sum of squares and group mean square deviation}

The sum of squared deviations of the group means around the grand mean
is called the ``group sum of squares'': \[
SS_\text{group} = \sum_{g=1}^kn_g(\overline{X}_g - \overline{X})^2
\]

\begin{itemize}
\item
  The degrees of freedom associated with the group sum of squares is:
  \(df_\text{group} = k - 1\)
\item
  Define the ``group mean squared deviation'' as: \[
  MS_\text{group} = \frac{SS_\text{group}}{k-1}
  \]
\end{itemize}

\textbf{Error sum of squares and error mean square deviation}

The sum of squared deviations of the individual observations about their
respective group means is called the ``error sum of squares'': \[
SS_\text{error} = \sum_{g=1}^k\sum_{i=1}^{n_g} (x_{i,g} - \overline{X}_g)^2
\]

\begin{itemize}
\item
  The degrees of freedom associated with the error sum of squares is:
  \(df_\text{error} = N - k\)
\item
  Define the ``error mean squared deviation'' as: \[
  MS_\text{error} = \frac{SS_\text{error}}{N-k}
  \]
\end{itemize}

\textbf{Variation explained: \(R^2\)}

We can summarize the contribution of the group differences to the total
variation in the data, using the \(R^2\) \textbf{value}.

To do this we note that the total sum of squares is the sum of the group
and error sum of squares: \[
SS_\text{total} = SS_\text{group} + SS_\text{error}
\]

The \(R^2\)-value is thus defined as: \[
R^2 = \frac{SS_\text{groups}}{SS_\text{total}}
\]

\hypertarget{anova-test-statistic-and-sampling-distribution}{%
\section{ANOVA test statistic and sampling
distribution}\label{anova-test-statistic-and-sampling-distribution}}

\textbf{F-statistic}

The test statistic used in ANOVA is designated \(F\), and is defined as
follows:

\[
F = \frac{\text{group mean square}}{\text{error mean square}} = \frac{\text{MS}_\text{group}}{\text{MS}_\text{error}}
\]

\begin{itemize}
\item
  Under the null hypothesis, the between group and within group
  variances are similar and thus the \(F\) statistic should be
  approximately 1.
\item
  Large values of the \(F\)-statistic means that the between group
  variance exceeds the within group variance, indicating that at least
  one of the means is different from the others
\end{itemize}

\textbf{The F-distribution}

The sampling distribution of the \(F\)-statistic is called the
\(F\)-distribution.

The \(F\)-distribution depends on two parameters:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  the degrees of freedom associated with the group sum of squares,
  \(df_\text{group} = k - 1\);
\item
  the degrees of freedom associated with the error sum of squares,
  \(df_\text{error} = N - k\);
\end{enumerate}

We designate a particular \(F\)-distribution as \(F_{k-1,N-k}\). We will
illustrate what an F-distribution looks like for particular parameters
below.

\hypertarget{anova-tables}{%
\section{ANOVA tables}\label{anova-tables}}

The results of an analysis of variance test are often presented in the
form of a table organized as follows:

\begin{longtable}[]{@{}lcccc@{}}
\toprule
Source & \(SS\) & \(df\) & \(MS\) & \(F\)\tabularnewline
\midrule
\endhead
Group & \(SS_\text{group}\) & \(k-1\) & \(MS_\text{group}\) &
\(MS_\text{group}/MS_\text{error}\)\tabularnewline
Error & \(SS_\text{error}\) & \(N-k\) & \(MS_\text{error}\)
&\tabularnewline
Total & \(SS_\text{total}\) & \(N-1\) & &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{the-aov-function}{%
\section{\texorpdfstring{The \texttt{aov()}
function}{The aov() function}}\label{the-aov-function}}

As you would suspect, there is a built in R function to carry out ANOVA.
This function is designated \texttt{aov()}. \texttt{aov} takes a formula
style argument where the variable of interest is on the left, and the
grouping variable indicated on the right.

\begin{verbatim}
aov(variable.of.interest ~ grouping.variable, data = df)
\end{verbatim}

\hypertarget{example-circadian-rythm-data}{%
\section{Example, circadian rythm
data}\label{example-circadian-rythm-data}}

Your textbook describes an examplar data set from a study designed to
test the effects of light treatment on circadian rhythms (see Whitlock
\& Schluter, Example 15.1).

\begin{itemize}
\tightlist
\item
  The investigators randomly assigned 22 individuals to one of three
  treatment groups and measured phase shifts in melatonin production.
  The treatment groups were:

  \begin{itemize}
  \tightlist
  \item
    control group (8 indiviuals)
  \item
    light applied on the back of the knee (7 individuals)
  \item
    light applied to the eyes (7 individuals)
  \end{itemize}
\end{itemize}

These data are available at:
\href{https://raw.githubusercontent.com/bio304-class/bio304-course-notes/master/datasets/ABD-circadian-rythms.csv}{ABD-circadian-rythms.csv}

The null and alternative hypotheses associated with the ANOVA of these
data are:

\begin{itemize}
\tightlist
\item
  \(H_0\): the means of the treatments groups are the same
\item
  \(H_1\): the mean of at least one of the treatment groups is different
  from the others
\end{itemize}

\textbf{Libraries}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(magrittr)}
\KeywordTok{library}\NormalTok{(cowplot)}
\KeywordTok{library}\NormalTok{(broom)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{20180113}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Load the data}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{circadian <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://raw.githubusercontent.com/bio304-class/bio304-course-notes/master/datasets/ABD-circadian-rythms.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The data is very simple: just two columns indicating treatment group and
the variable of interest:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(circadian, }\DataTypeTok{n=}\DecValTok{3}\NormalTok{)}
\CommentTok{#> # A tibble: 3 x 2}
\CommentTok{#>   treatment shift}
\CommentTok{#>   <chr>     <dbl>}
\CommentTok{#> 1 control    0.53}
\CommentTok{#> 2 control    0.36}
\CommentTok{#> 3 control    0.2}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualizing-the-data}{%
\subsection{Visualizing the data}\label{visualizing-the-data}}

As is our standard practice, let's start by visualizing the data. We'll
create a point plot depicting the observations colored by treatment
group.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# we're going to re-use our jittering across plots so}
\CommentTok{# assign it to a variable}
\NormalTok{pd <-}\StringTok{ }\KeywordTok{position_jitter}\NormalTok{(}\DataTypeTok{width=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{height=}\DecValTok{0}\NormalTok{)}

\NormalTok{point.plot <-}
\StringTok{  }\NormalTok{circadian }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{treatment, }\DataTypeTok{y=}\NormalTok{shift, }
             \DataTypeTok{color=}\NormalTok{treatment, }\DataTypeTok{group=}\KeywordTok{row.names}\NormalTok{(circadian))) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{position =}\NormalTok{ pd) }\OperatorTok{+}
\StringTok{    }\KeywordTok{ylim}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{)}\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Treatment"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Phase shift (h)"}\NormalTok{)}

\NormalTok{point.plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-455-1.pdf}

\hypertarget{carrying-out-the-anova}{%
\subsection{Carrying out the ANOVA}\label{carrying-out-the-anova}}

From our visualization it certainly seems like there may be differences
among the group (treatment) means. Let's test this formally using the
\texttt{aov()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{circadian.aov <-}\StringTok{ }\KeywordTok{aov}\NormalTok{(shift }\OperatorTok{~}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{data =}\NormalTok{ circadian)}
\end{Highlighting}
\end{Shaded}

The \texttt{summary} function applied to the \texttt{aov} fit will print
out a typical ANOVA table and calculate the associated P-value for the
\(F\) test statistic:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(circadian.aov)}
\CommentTok{#>             Df Sum Sq Mean Sq F value  Pr(>F)   }
\CommentTok{#> treatment    2  7.224   3.612   7.289 0.00447 **}
\CommentTok{#> Residuals   19  9.415   0.496                   }
\CommentTok{#> ---}
\CommentTok{#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1}
\end{Highlighting}
\end{Shaded}

If you want the ANOVA table in a form you can compute with, the
\texttt{broom::tidy} function we explored previously comes in handy:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{circadian.aov.table <-}\StringTok{ }\KeywordTok{tidy}\NormalTok{(circadian.aov)}
\NormalTok{circadian.aov.table}
\CommentTok{#> # A tibble: 2 x 6}
\CommentTok{#>   term         df sumsq meansq statistic   p.value}
\CommentTok{#>   <chr>     <dbl> <dbl>  <dbl>     <dbl>     <dbl>}
\CommentTok{#> 1 treatment     2 7.224 3.612      7.289  0.004472}
\CommentTok{#> 2 Residuals    19 9.415 0.4955    NA     NA}
\end{Highlighting}
\end{Shaded}

The table above tells us that the \(F\)-statistic for this ANOVA is
\textasciitilde{}7.29. The table also tells us that the P-value
associated with this F-statistic, is quite small, P-value \textless{}
0.005.

The P-value can be calculated explicitly using the \texttt{pf()}
function (similar to the \texttt{pnorm()} and \texttt{pt()} functions
we've seen previously):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{circadian.F.stat <-}\StringTok{ }\NormalTok{circadian.aov.table}\OperatorTok{$}\NormalTok{statistic[}\DecValTok{1}\NormalTok{]}
\KeywordTok{pf}\NormalTok{(circadian.F.stat, }\DataTypeTok{df1 =} \DecValTok{2}\NormalTok{, }\DataTypeTok{df2 =} \DecValTok{19}\NormalTok{, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{)}
\CommentTok{#> [1] 0.004472271}
\end{Highlighting}
\end{Shaded}

Note that we set \texttt{lower.tail\ =\ FALSE} to calculate the
probability of getting an F-statistic this large or greater.

\textbf{Visualizing the F-distribution}

Let's draw the corresponding F-distribution, \(F_{2,19}\), using the
\texttt{df()} function (parallel to \texttt{dnorm()} and \texttt{dt()},
with the region corresponding to an F-statistic greater than 7.29 shaded
red. Because the area in the right tail we're interested in is quite
small, in a second plot we've zoomed in on this region.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fdist <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{f =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DataTypeTok{length.out =} \DecValTok{250}\NormalTok{),}
                    \DataTypeTok{density =} \KeywordTok{df}\NormalTok{(f, }\DataTypeTok{df1=}\DecValTok{2}\NormalTok{, }\DataTypeTok{df2=}\DecValTok{19}\NormalTok{))}

\NormalTok{plot.a <-}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(fdist, }\KeywordTok{aes}\NormalTok{(f, density)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_area}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{filter}\NormalTok{(fdist, f }\OperatorTok{>=}\StringTok{ }\FloatTok{7.29}\NormalTok{), }\DataTypeTok{fill=}\StringTok{'red'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.25}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"F"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Density"}\NormalTok{, }\DataTypeTok{title=}\StringTok{"F(2,19)"}\NormalTok{)}

\NormalTok{plot.b <-}\StringTok{ }
\StringTok{  }\NormalTok{plot.a }\OperatorTok{+}\StringTok{ }\KeywordTok{xlim}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.02}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Zoomed in view of right tail of F(2,19)"}\NormalTok{)}

\KeywordTok{plot_grid}\NormalTok{(plot.a, plot.b, }\DataTypeTok{labels=}\StringTok{"AUTO"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-460-1} \end{center}

\textbf{Critical values of the F-distribution}

If we wanted to know what the critical F value is for a corresponding
type I error rate we can use the \texttt{qf()} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# the critical value of F for alpha = 0.05}
\KeywordTok{qf}\NormalTok{(}\FloatTok{0.05}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{)}
\CommentTok{#> [1] 3.521893}
\end{Highlighting}
\end{Shaded}

\hypertarget{anova-calculations-step-by-step}{%
\section{ANOVA calculations:
Step-by-step}\label{anova-calculations-step-by-step}}

The \texttt{aov()} function carries out all the ANOVA calculations
behind the scenes. It's useful to pull back the curtain and see how the
various quantities are calculated.

\textbf{Total SS}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grand.mean <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(circadian}\OperatorTok{$}\NormalTok{shift)}

\CommentTok{# total sum of squares}
\NormalTok{total.table <-}\StringTok{ }
\StringTok{  }\NormalTok{circadian }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{SS =} \KeywordTok{sum}\NormalTok{((shift }\OperatorTok{-}\StringTok{ }\NormalTok{grand.mean)}\OperatorTok{**}\DecValTok{2}\NormalTok{),}
            \DataTypeTok{df =} \KeywordTok{n}\NormalTok{() }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}

\NormalTok{total.table}
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>      SS    df}
\CommentTok{#>   <dbl> <dbl>}
\CommentTok{#> 1 16.64    21}
\end{Highlighting}
\end{Shaded}

\textbf{Group SS and MS}

We use \texttt{group\_by} and \texttt{summarize} to calculates group
means and the group deviates (the difference between the group means and
the grand mean):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{group.df <-}
\StringTok{  }\NormalTok{circadian }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(treatment) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{(), }
            \DataTypeTok{group.mean =} \KeywordTok{mean}\NormalTok{(shift), }
            \DataTypeTok{grand.mean =}\NormalTok{ grand.mean,}
            \DataTypeTok{group.deviates =}\NormalTok{ group.mean }\OperatorTok{-}\StringTok{ }\NormalTok{grand.mean)}

\NormalTok{group.df}
\CommentTok{#> # A tibble: 3 x 5}
\CommentTok{#>   treatment     n group.mean grand.mean group.deviates}
\CommentTok{#>   <chr>     <int>      <dbl>      <dbl>          <dbl>}
\CommentTok{#> 1 control       8    -0.3088    -0.7127         0.4040}
\CommentTok{#> 2 eyes          7    -1.551     -0.7127        -0.8387}
\CommentTok{#> 3 knee          7    -0.3357    -0.7127         0.3770}
\end{Highlighting}
\end{Shaded}

Having calculated the group deviates, we calculate the group sum of
squares and related quantities:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{group.table <-}
\StringTok{  }\NormalTok{group.df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{SS =} \KeywordTok{sum}\NormalTok{(n }\OperatorTok{*}\StringTok{ }\NormalTok{group.deviates}\OperatorTok{**}\DecValTok{2}\NormalTok{),}
            \DataTypeTok{k =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{df =}\NormalTok{ k}\DecValTok{-1}\NormalTok{,}
            \DataTypeTok{MS =}\NormalTok{ SS}\OperatorTok{/}\NormalTok{df)}

\NormalTok{group.table}
\CommentTok{#> # A tibble: 1 x 4}
\CommentTok{#>      SS     k    df    MS}
\CommentTok{#>   <dbl> <int> <dbl> <dbl>}
\CommentTok{#> 1 7.224     3     2 3.612}
\end{Highlighting}
\end{Shaded}

\textbf{Error SS and MS}

Next we turn to variation of the individual observations around the
group means, which is the basis of the error sum of squares and mean
square. Again we calculate this in two steps:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{error.df <-}
\StringTok{  }\NormalTok{circadian }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(treatment) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{group.mean =} \KeywordTok{mean}\NormalTok{(shift),}
         \DataTypeTok{error.deviates =}\NormalTok{ shift }\OperatorTok{-}\StringTok{ }\NormalTok{group.mean) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{SS =} \KeywordTok{sum}\NormalTok{(error.deviates}\OperatorTok{**}\DecValTok{2}\NormalTok{),}
            \DataTypeTok{n =} \KeywordTok{n}\NormalTok{())}

\NormalTok{error.df}
\CommentTok{#> # A tibble: 3 x 3}
\CommentTok{#>   treatment    SS     n}
\CommentTok{#>   <chr>     <dbl> <int>}
\CommentTok{#> 1 control   2.670     8}
\CommentTok{#> 2 eyes      2.993     7}
\CommentTok{#> 3 knee      3.752     7}
\end{Highlighting}
\end{Shaded}

Now we calculate the error sum of squares and related quantities:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{error.table <-}
\StringTok{  }\NormalTok{error.df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{SS =} \KeywordTok{sum}\NormalTok{(SS),}
            \DataTypeTok{k =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{N =} \KeywordTok{sum}\NormalTok{(n),}
            \DataTypeTok{df =}\NormalTok{ N }\OperatorTok{-}\StringTok{ }\NormalTok{k,}
            \DataTypeTok{MS =}\NormalTok{ SS}\OperatorTok{/}\NormalTok{df)}

\NormalTok{error.table}
\CommentTok{#> # A tibble: 1 x 5}
\CommentTok{#>      SS     k     N    df     MS}
\CommentTok{#>   <dbl> <int> <int> <int>  <dbl>}
\CommentTok{#> 1 9.415     3    22    19 0.4955}
\end{Highlighting}
\end{Shaded}

\textbf{Calculating the F-statistic and \(R^2\)}

Having calculated our estimates of between group variance and within
group variance (\(MS_\text{group}\) and \$MS\_\text{error}) we're now
ready to calculate the \(F\) test statistic.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{F.stat <-}\StringTok{ }\NormalTok{group.table}\OperatorTok{$}\NormalTok{MS}\OperatorTok{/}\NormalTok{error.table}\OperatorTok{$}\NormalTok{MS}
\NormalTok{F.stat}
\CommentTok{#> [1] 7.289449}
\end{Highlighting}
\end{Shaded}

The variation ``explained'' by the group is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R2 <-}\StringTok{ }\NormalTok{group.table}\OperatorTok{$}\NormalTok{SS}\OperatorTok{/}\NormalTok{total.table}\OperatorTok{$}\NormalTok{SS}
\NormalTok{R2}
\CommentTok{#> [1] 0.4341684}
\end{Highlighting}
\end{Shaded}

Thus about 43\% of the total sum of squared deviation among subjects,
with respect to the phase shift variable, is explained by differences in
light treatment.

\hypertarget{visualizing-the-partitioning-of-sum-of-squares}{%
\section{Visualizing the partitioning of
sum-of-squares}\label{visualizing-the-partitioning-of-sum-of-squares}}

\textbf{Total SS}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{total.plot <-}
\StringTok{  }\NormalTok{circadian }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{treatment, }\DataTypeTok{y=}\NormalTok{shift, }
             \DataTypeTok{color=}\NormalTok{treatment, }\DataTypeTok{group=}\KeywordTok{row.names}\NormalTok{(circadian))) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_linerange}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ grand.mean, }\DataTypeTok{ymax =}\NormalTok{ shift), }\DataTypeTok{position =}\NormalTok{ pd) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =}\NormalTok{ grand.mean, }\DataTypeTok{linetype=}\StringTok{'dashed'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{ylim}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{)}\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Treatment"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Phase shift (h)"}\NormalTok{,}
         \DataTypeTok{title =} \StringTok{"Deviation of observations around the grand mean (dashed line)"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{plot.title =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{size=}\DecValTok{9}\NormalTok{))}

\NormalTok{total.plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-469-1.pdf}

\textbf{Group SS}

Let's visualize the difference of the group means from the grand mean:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{group.plot <-}
\StringTok{  }\NormalTok{group.df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ treatment, }\DataTypeTok{y =}\NormalTok{ group.mean, }\DataTypeTok{color=}\NormalTok{treatment)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_linerange}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ grand.mean, }\DataTypeTok{ymax =}\NormalTok{ group.mean), }\DataTypeTok{size=}\DecValTok{2}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \DecValTok{3}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.25}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =}\NormalTok{ grand.mean, }\DataTypeTok{linetype=}\StringTok{'dashed'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{ylim}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Treatment"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Phase shift (h)"}\NormalTok{,}
         \DataTypeTok{title =} \StringTok{"Deviation of group means around the grand mean"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{plot.title =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{size=}\DecValTok{9}\NormalTok{))}

\NormalTok{group.plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-470-1.pdf}

\textbf{Error SS}

We can visualize the individual deviates around the group means as so:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{error.plot <-}
\StringTok{  }\NormalTok{circadian }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(treatment) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{group.mean =} \KeywordTok{mean}\NormalTok{(shift)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ treatment, }\DataTypeTok{y =}\NormalTok{ shift, }\DataTypeTok{color =}\NormalTok{ treatment)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ group.mean),}\DataTypeTok{size=}\DecValTok{3}\NormalTok{,}\DataTypeTok{alpha=}\FloatTok{0.1}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_linerange}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ group.mean, }\DataTypeTok{ymax =}\NormalTok{ shift), }\DataTypeTok{position =}\NormalTok{ pd) }\OperatorTok{+}
\StringTok{    }\KeywordTok{ylim}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Treatment"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Phase shift (h)"}\NormalTok{,}
         \DataTypeTok{title =} \StringTok{"Deviation of observations around the groups means"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{plot.title =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{size=}\DecValTok{9}\NormalTok{))}

\NormalTok{error.plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-471-1.pdf}

\textbf{Combined visualization}

We can combine our three plots created above into a single figure using
\texttt{cowplot::plot\_grid}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{combined.plot <-}\KeywordTok{plot_grid}\NormalTok{(total.plot, group.plot, error.plot, }
                          \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{), }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{)}
\NormalTok{combined.plot}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-472-1.pdf}

\hypertarget{which-pairs-of-group-means-are-different}{%
\section{Which pairs of group means are
different?}\label{which-pairs-of-group-means-are-different}}

If an ANOVA indicates that at least one of the group means is different
than the others, the next question is usually ``which pairs are
different?''. There are slighly different tests for what are called
``planned'' versus ``unplanned'' comparisons. Your textbook discusses
the differences between these two types

Here we focus on a common test for unplanned comparisons, called the
Tukey Honest Significant Differences test (referred to as the
Tukey-Kramer test in your textbook). The Tukey HSD test controls for the
``family-wise error rate'', meaning it tries to keep the overall false
positive (Type I error) rate at a specified value.

\hypertarget{tukey-kramer-test}{%
\subsection{Tukey-Kramer test}\label{tukey-kramer-test}}

The function \texttt{TukeyHSD} implements the Tukey-Kramer test. The
input to \texttt{TukeyHSD} is the fit from \texttt{aov}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{TukeyHSD}\NormalTok{(circadian.aov)}
\CommentTok{#>   Tukey multiple comparisons of means}
\CommentTok{#>     95% family-wise confidence level}
\CommentTok{#> }
\CommentTok{#> Fit: aov(formula = shift ~ treatment, data = circadian)}
\CommentTok{#> }
\CommentTok{#> $treatment}
\CommentTok{#>                     diff        lwr        upr     p adj}
\CommentTok{#> eyes-control -1.24267857 -2.1682364 -0.3171207 0.0078656}
\CommentTok{#> knee-control -0.02696429 -0.9525222  0.8985936 0.9969851}
\CommentTok{#> knee-eyes     1.21571429  0.2598022  2.1716263 0.0116776}
\end{Highlighting}
\end{Shaded}

Here again, the \texttt{broom::tidy} function comes in handy:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(}\KeywordTok{TukeyHSD}\NormalTok{(circadian.aov))}
\CommentTok{#> # A tibble: 3 x 6}
\CommentTok{#>   term      comparison   estimate conf.low conf.high adj.p.value}
\CommentTok{#>   <chr>     <chr>           <dbl>    <dbl>     <dbl>       <dbl>}
\CommentTok{#> 1 treatment eyes-control -1.243    -2.168    -0.3171    0.007866}
\CommentTok{#> 2 treatment knee-control -0.02696  -0.9525    0.8986    0.9970  }
\CommentTok{#> 3 treatment knee-eyes     1.216     0.2598    2.172     0.01168}
\end{Highlighting}
\end{Shaded}

The Tukey HSD test by default give us 95\% confidence intervals for the
differences in means between each pair of groups, and an associated
P-value for the null hypothesis of equal means between pairs.
Interpretting the results above, we see that we fail to reject the null
hypothesis of equal means for the knee and control treatment groups
(i.e.~we have no statistical support to conclude they are different).
However, we reject the null hypothesis for equality of means between
control and eye treatments and between knee and eye treatements. We have
evidence that light treatments applied to the eye cause a mean negative
shift in the phase of melatonin production relative to control and knee
treatment groups.

\hypertarget{repeatability}{%
\section{Repeatability}\label{repeatability}}

\begin{itemize}
\item
  Nearly every measure of a continuous measurement or assay we apply in
  biology (and other sicences) has associated with it some
  \textbf{measurement error}.
\item
  Measurement error is usually not ``biological variation'' of interest,
  but rather ``technical variation'' associated with our ability to
  measure quantities of interest precisely

  \begin{itemize}
  \tightlist
  \item
    \textbf{Example}: Have three people independently measure the length
    of a human femur to the nearest millimeter. Unless the values are
    aggressively rounded, there is a high likelihood that you'll get
    three different values.
  \end{itemize}
\end{itemize}

\hypertarget{estimating-repeatability-using-anova}{%
\subsection*{Estimating Repeatability using
ANOVA}\label{estimating-repeatability-using-anova}}
\addcontentsline{toc}{subsection}{Estimating Repeatability using ANOVA}

ANOVA can be used to estimate the \textbf{Repeatability} of a measure,
which provides a way to quantify how much of the variance we observe
between individuals is due to measurement error.

\textbf{Estimating Repeatability: Experimental steps}

\begin{itemize}
\tightlist
\item
  Repeatedly, but independently, measure the same variable in the same
  individual or other unit of observation
\item
  Carry out the same repeated measurements across individuals
\end{itemize}

\textbf{Estimating Repeatability: Statistical steps}

\begin{itemize}
\tightlist
\item
  Calculate \(MS_\text{groups}\) and \(MS_\text{error}\) where
  individuals are the grouping unit.
\item
  Estimate the variance among groups, \(s_A^2\) as: \[
  s_A^2 = \frac{MS_\text{groups} - MS_\text{error}}{n}
  \]
\end{itemize}

where \(n\) is the number of replicate measures per individual.

\begin{itemize}
\item
  Estimate the repeatability as: \[
  \text{Repeatability} = \frac{s_A^2}{s_A^2 + MS_\text{error}}
  \]
\item
  \(0 \leq \text{Repeatability} \leq 1\); values near zero indicate
  nearly all variance is due to measurement error, values near one
  indicate small fraction of variance due to measurement error
\end{itemize}

\hypertarget{repeatability-walking-stick-example}{%
\subsection*{Repeatability: Walking stick
example}\label{repeatability-walking-stick-example}}
\addcontentsline{toc}{subsection}{Repeatability: Walking stick example}

Nosil and Crespi measured various morphological features of walking
stick insects from digital photographs. For each specimen they took two
independent photographs and measured femur length (in cm) on each
photograph.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{walking.sticks <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/ABD-walking-sticks.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{by.specimen <-}
\StringTok{  }\NormalTok{walking.sticks }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(specimen) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{min.fl =} \KeywordTok{min}\NormalTok{(femurLength), }\DataTypeTok{max.fl =} \KeywordTok{max}\NormalTok{(femurLength), }\DataTypeTok{avg.fl =} \FloatTok{0.5}\OperatorTok{*}\NormalTok{(min.fl }\OperatorTok{+}\StringTok{ }\NormalTok{max.fl)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(avg.fl) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{rank.fl =} \KeywordTok{rank}\NormalTok{(avg.fl, }\DataTypeTok{ties.method =} \StringTok{"first"}\NormalTok{))}

\KeywordTok{ggplot}\NormalTok{(by.specimen, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ rank.fl)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ min.fl), }\DataTypeTok{color=}\StringTok{"firebrick"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ max.fl }\OperatorTok{+}\StringTok{ }\FloatTok{0.0025}\NormalTok{), }\DataTypeTok{color=}\StringTok{"firebrick"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_linerange}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ min.fl, }\DataTypeTok{ymax =}\NormalTok{ max.fl }\OperatorTok{+}\StringTok{ }\FloatTok{0.0025}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Individual walking sticks"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Femur length (cm)"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_classic}\NormalTok{()}\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.text.x=}\KeywordTok{element_blank}\NormalTok{(),}
        \DataTypeTok{axis.ticks.x=}\KeywordTok{element_blank}\NormalTok{())  }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-476-1} \end{center}

First we carry out the ANOVA in the standard way, using the specimen
variable as the grouping variable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sticks.aov <-}\StringTok{ }\KeywordTok{aov}\NormalTok{(femurLength }\OperatorTok{~}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(specimen), }
                  \DataTypeTok{data =}\NormalTok{ walking.sticks)}
\NormalTok{sticks.table <-}\StringTok{ }\KeywordTok{tidy}\NormalTok{(sticks.aov)}
\NormalTok{sticks.table}
\CommentTok{#> # A tibble: 2 x 6}
\CommentTok{#>   term                   df    sumsq    meansq statistic      p.value}
\CommentTok{#>   <chr>               <dbl>    <dbl>     <dbl>     <dbl>        <dbl>}
\CommentTok{#> 1 as.factor(specimen)    24 0.05913  0.002464      6.921  0.000004077}
\CommentTok{#> 2 Residuals              25 0.008900 0.0003560    NA     NA}
\end{Highlighting}
\end{Shaded}

From the ANOVA table, use \(MS_\text{group}\) and \(MS_\text{error}\) to
calculate \(s_A\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{repeatability.table <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}
  \DataTypeTok{MS.groups =}\NormalTok{ sticks.table}\OperatorTok{$}\NormalTok{meansq[}\DecValTok{1}\NormalTok{],}
  \DataTypeTok{MS.error =}\NormalTok{ sticks.table}\OperatorTok{$}\NormalTok{meansq[}\DecValTok{2}\NormalTok{],}
  \DataTypeTok{sA =}\NormalTok{ (MS.groups }\OperatorTok{-}\StringTok{ }\NormalTok{MS.error)}\OperatorTok{/}\DecValTok{2}\NormalTok{,}
  \DataTypeTok{repeatability =}\NormalTok{ sA}\OperatorTok{/}\NormalTok{(sA }\OperatorTok{+}\StringTok{ }\NormalTok{MS.error))}

\NormalTok{repeatability.table}
\CommentTok{#> # A tibble: 1 x 4}
\CommentTok{#>   MS.groups  MS.error       sA repeatability}
\CommentTok{#>       <dbl>     <dbl>    <dbl>         <dbl>}
\CommentTok{#> 1  0.002464 0.0003560 0.001054        0.7475}
\end{Highlighting}
\end{Shaded}

From the table we calculated:

\begin{itemize}
\tightlist
\item
  \(s_A^2 =\) 0.0010539
\item
  \(\text{Repeatability} =\) 0.7475028
\end{itemize}

A repeatability of 0.75 indicates that we would estimate that
\textasciitilde{}75\% of the total variance in femure length
measurements in our population of walking stick insects is the result of
true differences in femur length between individuals, while roughly 25\%
of the variance is attributable to measurement error.

\hypertarget{violations-of-assumptions}{%
\chapter{Violations of Assumptions}\label{violations-of-assumptions}}

Both t-tests and ANOVA make assumptions about the variable of interest.
Namely, both assume:

\begin{itemize}
\tightlist
\item
  The variable of interest approximately normally distributed
\item
  The variance of the variable is approximately the same in the groups
  being compared
\end{itemize}

When our data violate the assumptions of standard statistical tests, we
have several options:

\begin{itemize}
\tightlist
\item
  Ignore violations of the assumptions, especially with large sample
  sizes and modest violations
\item
  Transform the data (e.g., log transformation)
\item
  Nonparametric methods
\item
  Permutation tests
\end{itemize}

\textbf{Libraries}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(magrittr)}
\KeywordTok{library}\NormalTok{(cowplot)}
\KeywordTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

\hypertarget{graphical-methods-for-detecting-deviations-from-normality}{%
\section{Graphical methods for detecting deviations from
normality}\label{graphical-methods-for-detecting-deviations-from-normality}}

As we have seen, histogram and density plot can highlight distributions
that deviate from normality.

Look for: * distinctly non-symmetric spread -- long tails, data up
against a lower or upper limit * multiple modes * Varying bin widths
(histograms) and the degree of smoothing (density plots) can both be
useful.

\hypertarget{example-data-marine-reserves}{%
\subsubsection*{Example data: Marine
reserves}\label{example-data-marine-reserves}}
\addcontentsline{toc}{subsubsection}{Example data: Marine reserves}

Example 13.1 in your text book describes a study aimed at understanding
whether marine reserves are effective at preserving marine life. The
data provided are ``biomass ratios'' between reserves and similar
unprotected sites nearby. A ratio of one means the reserve and the
nearby unprotected site had equal biomass; values greater than one
indicate greater biomass in the rserve while values less than one
indicate greater biomass in the unprotected site.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(magrittr)}
\KeywordTok{library}\NormalTok{(cowplot)}

\NormalTok{marine.reserves <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/ABD-marine-reserves.csv"}\NormalTok{)}

\KeywordTok{ggplot}\NormalTok{(marine.reserves, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ biomassRatio, }\DataTypeTok{y =}\NormalTok{ ..density..)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{8}\NormalTok{, }\DataTypeTok{color=}\StringTok{'gray'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_density}\NormalTok{(}\DataTypeTok{geom=}\StringTok{"line"}\NormalTok{,}
               \DataTypeTok{adjust =} \FloatTok{1.25}\NormalTok{,   }\CommentTok{# adjust is in multiples of smoothing bandwidth}
               \DataTypeTok{color =} \StringTok{'firebrick'}\NormalTok{, }\DataTypeTok{size=}\FloatTok{1.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Biomass ratio"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Probability density"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-480-1.pdf}

Both the histogram and the density plot suggest the biomass ratio
distribution is strongly right skewed.

\hypertarget{normal-probability-plots}{%
\subsection*{Normal probability plots}\label{normal-probability-plots}}
\addcontentsline{toc}{subsection}{Normal probability plots}

Normal probability plots are another visualization tools we saw
previously for judging deviations from normality. If the observed data
are approximately normally distributed, the scatter of points should
fall roughly along a straight line with slope equal to the standard
deviation of the data and intercept equal to the mean of the data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(marine.reserves, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =}\NormalTok{ biomassRatio)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_qq}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_qq_line}\NormalTok{(}\DataTypeTok{color =} \StringTok{'firebrick'}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.5}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-481-1.pdf}

\hypertarget{formal-test-of-normality}{%
\section{Formal test of normality}\label{formal-test-of-normality}}

There are number of formal tests of normality, with the ``Shapiro-Wilk''
test being among the most common. The Shapiro-Wilk test is essentially a
formalization of the procedure we do by eye when judging a QQ-plot.

The null hypothesis for the Shapiro-Wilk test is that the data are drawn
from a normal distribution. The test statistic for the Shapiro-Wilks
tests is called \(W\), and it measures the ratio of sumed deviations
from the mean for a theoretical normal relative to the observed data.
Small values of W are evidence of departure from normality. As in all
other cases we've examined, the observed \(W\) is compared to the
expected sampling distribution of \(W\) under the null hypothesis to
estimate a P-value. Small P-values reject the null hypothesis of
normality.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(marine.reserves}\OperatorTok{$}\NormalTok{biomassRatio)}
\CommentTok{#> }
\CommentTok{#>  Shapiro-Wilk normality test}
\CommentTok{#> }
\CommentTok{#> data:  marine.reserves$biomassRatio}
\CommentTok{#> W = 0.81751, p-value = 8.851e-05}
\end{Highlighting}
\end{Shaded}

\hypertarget{when-to-ignore-violations-of-assumptions}{%
\section{When to ignore violations of
assumptions}\label{when-to-ignore-violations-of-assumptions}}

Estimation and testing of means tends to be robust to violation of
assumptions of normality and homogeneity of variance. This robustness is
a consequence of the Central Limit Theorem.

However, if ``two groups are being compared and both differ from
normality in different ways, then even subtle deviations from normality
can cause errors in the analysis (even with fairly large sample sizes)''
(W\&S Ch 13).

\hypertarget{data-transformations}{%
\section{Data transformations}\label{data-transformations}}

A common approach to dealing with non-normal variables is to apply a
mathematical function that transforms the data to more nearly normal
distribution. Analyses and inferences are then done on the transformed
data.

\textbf{Log transformation}: This widely-used transformation can only be
applied to positive numbers, since \texttt{log(x)} is undefined when
\texttt{x} is negative or zero. However, addition of a small positive
constant can be used to ensure that all data are positive. For example,
if a vector \texttt{x} includes negative numbers, then
\texttt{x\ +\ abs(min(x))\ +\ 1} results in positive numbers that can be
log transformed.

\textbf{Arcsine square root transformation}: \(p' = arcsin[\sqrt{p}]\)
is often used when the data are proportions. If the original data are
percentages, first divide by 100 to convert to proportions.

\textbf{Square root transformation}: \(Y' = \sqrt{Y + K}\), where \(K\)
is a constant to ensure that no data points are negative. Results from
the square root transformation are often very similar to log
transformation.

\textbf{Square transformation}: \(Y' = Y^2\). This may be helpful when
the data are skewed left. .

\textbf{Antilog transformation}: \(Y' = e^Y\) may be helpful if the
square transformation does not resolve the problem. Only usable when all
data points have the same sign. If all data points are less than zero,
take the absolute value before applying the antilog transformation.

\textbf{Reciprocal transformation}: \(Y' = {\frac{1}{Y}}\) When data are
right skewed, this transformation may be helpful. If all data points are
less than zero, take the absolute value before applying the reciprocal
transformation.

\hypertarget{example-log-transformation-to-deal-with-skew}{%
\subsection*{Example: log transformation to deal with
skew}\label{example-log-transformation-to-deal-with-skew}}
\addcontentsline{toc}{subsection}{Example: log transformation to deal
with skew}

The biomass ratio variable in the marine reserves data is strongly right
skewed. Let's see how well a log transformation does in terms of
normalizing this data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ln.biomass.hist <-}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(marine.reserves, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{log}\NormalTok{(biomassRatio), }\DataTypeTok{y =}\NormalTok{ ..density..)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{8}\NormalTok{, }\DataTypeTok{color=}\StringTok{'gray'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_density}\NormalTok{(}\DataTypeTok{geom=}\StringTok{"line"}\NormalTok{,}
               \DataTypeTok{adjust =} \FloatTok{1.25}\NormalTok{,   }\CommentTok{# adjust is in multiples of smoothing bandwidth}
               \DataTypeTok{color =} \StringTok{'firebrick'}\NormalTok{, }\DataTypeTok{size=}\FloatTok{1.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"ln[Biomass ratio]"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Probability density"}\NormalTok{)}

\NormalTok{ln.biomass.qq <-}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(marine.reserves, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =} \KeywordTok{log}\NormalTok{(biomassRatio))) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_qq}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_qq_line}\NormalTok{(}\DataTypeTok{color =} \StringTok{'firebrick'}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.5}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"ln[Biomass ratio]"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Theoretical quantiles"}\NormalTok{)}

\KeywordTok{plot_grid}\NormalTok{(ln.biomass.hist, ln.biomass.qq)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-483-1.pdf}

The log-transformed biomass ratio data is still a bit right skewed
though not nearly as much as before. Applying the Shapiro-Wilk test to
this transformed data, we fail to reject the null hypothesis of
normality at \(\alpha = 0.05\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(}\KeywordTok{log}\NormalTok{(marine.reserves}\OperatorTok{$}\NormalTok{biomassRatio))}
\CommentTok{#> }
\CommentTok{#>  Shapiro-Wilk normality test}
\CommentTok{#> }
\CommentTok{#> data:  log(marine.reserves$biomassRatio)}
\CommentTok{#> W = 0.93795, p-value = 0.06551}
\end{Highlighting}
\end{Shaded}

\hypertarget{confidence-intervals-and-data-transformations}{%
\subsection{Confidence intervals and data
transformations}\label{confidence-intervals-and-data-transformations}}

Sometimes we need to transform our data before analysis, and then we
want to know the confidence intervals on the original scale. In such
cases, we back-transform the upper and lower CIs to the original scale
of measurement.

Let's calculate 95\% CIs for the log-transformed biomass ratio data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log.biomass.CI <-}\StringTok{ }
\StringTok{  }\NormalTok{marine.reserves }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{log.biomassRatio =} \KeywordTok{log}\NormalTok{(biomassRatio)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(log.biomassRatio),}
            \DataTypeTok{sd =} \KeywordTok{sd}\NormalTok{(log.biomassRatio),}
            \DataTypeTok{n =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{SE =}\NormalTok{ sd}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n),}
            \DataTypeTok{CI.low.log =}\NormalTok{ mean }\OperatorTok{-}\StringTok{ }\KeywordTok{abs}\NormalTok{(}\KeywordTok{qt}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\DataTypeTok{df =}\NormalTok{ n}\DecValTok{-1}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\NormalTok{SE,}
            \DataTypeTok{CI.high.log =}\NormalTok{ mean }\OperatorTok{+}\StringTok{ }\KeywordTok{abs}\NormalTok{(}\KeywordTok{qt}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\DataTypeTok{df =}\NormalTok{ n}\DecValTok{-1}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\NormalTok{SE) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(CI.low.log, CI.high.log)}

\NormalTok{log.biomass.CI }
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>   CI.low.log CI.high.log}
\CommentTok{#>        <dbl>       <dbl>}
\CommentTok{#> 1     0.3470      0.6112}
\end{Highlighting}
\end{Shaded}

This analysis finds the 95\% CI around the mean of the log transformed
data ranges is 0.347018, 0.6112365.

To understand the biological implications of this analysis, we
back-transform the log data results to the original scale, computing the
\emph{antilog} by using function \texttt{exp}. After this, the
back-transformed CI is now on the scale of \(e^{\log X} = X\).

Letting \(\mu'\) = \texttt{mean(log.X)}, we have
\(0.347 < \mu' < 0.611\) on the log scale.

On the original scale:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log.biomass.CI }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# back-transform CI to original scale}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{CI.low.original  =} \KeywordTok{exp}\NormalTok{(CI.low.log),}
         \DataTypeTok{CI.high.original =} \KeywordTok{exp}\NormalTok{(CI.high.log))}
\CommentTok{#> # A tibble: 1 x 4}
\CommentTok{#>   CI.low.log CI.high.log CI.low.original CI.high.original}
\CommentTok{#>        <dbl>       <dbl>           <dbl>            <dbl>}
\CommentTok{#> 1     0.3470      0.6112           1.415            1.843}
\end{Highlighting}
\end{Shaded}

Hence, 1.41 \textless{} geometric mean \textless{} 1.84.

The \emph{geometric mean} equals \(\sqrt[n]{x_1 x_2 \cdots x_n}\),
computed by multiplying all these \emph{n} numbers together, then taking
the \(n^{th}\) root.

Biologically, ``this 95\% confidence interval indicates that marine
reserves have 1.41 to 1.84 times more biomass on average than the
control sites do'' (W\&S 13.3)

\hypertarget{nonparametric-tests}{%
\section{Nonparametric tests}\label{nonparametric-tests}}

Non-parametric tests are ones that make no (or fewer) assumptions about
the particular distributions from which the data of interest are drawn.
Nonparametric tests are helpful for non-normal data distributions,
especially with outliers. Typically, these tests use the ranks of the
data points rather than the actual values of the data. Because they are
not using all available data, nonparametric tests have lower statistical
power than parametric tests. Nonparametric approaches still assume that
the data are a random sample from the population.

We present here two common non-parametric alternatives to t-tests and
ANOVA.

\hypertarget{mann-whitney-u-test-non-parametric-alternative-to-t-test}{%
\subsection{Mann-Whitney U-test: non-parametric alternative to
t-test}\label{mann-whitney-u-test-non-parametric-alternative-to-t-test}}

When the normality assumption is not met, and none of the the standard
mathematical transformations are suitable (or desirable), the
\textbf{Mann-Whitney U-test} can be used in place of a two-sample
\(t\)-test to compare the \emph{distribution} of two groups. The
Mann-Whitney U-test compares the data distribution of two groups,
without requiring the normality assumptions of the two-sample t-test.
The null hypothesis of this test is that the within-group data
\emph{distributions} are the same. Therefore, it is possible to reject
the null hypothesis because the distributions differ, \emph{even if the
means are the same}. The Mann-Whitney U-test is sensitive to unequal
variances or different patterns of skew. Therefore, this test should be
used to compare distributions, not to compare means.

Confusingly, the Mann-Whitney U-test is also called the
Mann--Whitney--Wilcoxon test. Do not confuse this with another test
called the Wilcoxon signed-rank test.

Your textbook details the calculations involved, here we simply
demonstrate the appropriate R function.

\hypertarget{example-data-sexual-cannibalism-in-crickets}{%
\subsubsection*{Example data: Sexual cannibalism in
crickets}\label{example-data-sexual-cannibalism-in-crickets}}
\addcontentsline{toc}{subsubsection}{Example data: Sexual cannibalism in
crickets}

Example 13.5 in your textbook demonstrates the Mann-Whitney U-test with
an application to a study of sexual cannabilism in sage crickets. During
mating, male sage crickets offer their fleshy hind wings to females to
eat. Johnson et al. (1999) studied whether female sage crickets are more
likely to mate if they are hungry. They measured the time to mating (in
hours) for female crickets that had be starved or fed. The null and
alternative hypotheses for this comparison are:

\begin{itemize}
\tightlist
\item
  \(H_0\): The distribution of time to mating is the same for starved
  and fed female crickets
\item
  \(H_A\): The distribution of time to mating differs between starved
  and fed female crickets
\end{itemize}

Here's what the data look like:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{crickets <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/ABD-cricket-cannibalism.csv"}\NormalTok{)}
\CommentTok{#> Parsed with column specification:}
\CommentTok{#> cols(}
\CommentTok{#>   feedingStatus = col_character(),}
\CommentTok{#>   timeToMating = col_double()}
\CommentTok{#> )}

\KeywordTok{ggplot}\NormalTok{(crickets, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ timeToMating)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{20}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.75}\NormalTok{, }\DataTypeTok{fill =} \StringTok{'firebrick'}\NormalTok{, }\DataTypeTok{color=}\StringTok{'black'}\NormalTok{, }\DataTypeTok{center=}\DecValTok{10}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{feedingStatus, }\DataTypeTok{nrow=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-487-1} \end{center}

As is apparent from the histograms, these data are decidedly non-normal.
None of the standard mathematical transforms appear to work well in
normalizing these data either.

To perform the Mann-Whitney U text, we use function \texttt{wilcox.test}
(\href{https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html}{details
here}). This can take a data frame as input:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{wilcox.test}\NormalTok{(timeToMating }\OperatorTok{~}\StringTok{ }\NormalTok{feedingStatus, }
            \DataTypeTok{alternative =} \StringTok{"two.sided"}\NormalTok{, }\DataTypeTok{paired =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ crickets)}
\CommentTok{#> }
\CommentTok{#>  Wilcoxon rank sum test}
\CommentTok{#> }
\CommentTok{#> data:  timeToMating by feedingStatus}
\CommentTok{#> W = 88, p-value = 0.3607}
\CommentTok{#> alternative hypothesis: true location shift is not equal to 0}
\end{Highlighting}
\end{Shaded}

The test statistic \(W\) is the equivalent to the \(U\) test statistic
of the Mann Whitney U-test. In this case, our observed value of \(U\)
(\(W\)) is quite probable (\(p\) = 0.4) under the null hypothesis of no
difference in the distributions between the two groups, therefore we
fail to reject the null hypothesis.

\hypertarget{kruskal-wallis-test-non-parametric-alternative-to-anova}{%
\subsection{Kruskal-Wallis test: non-parametric alternative to
ANOVA}\label{kruskal-wallis-test-non-parametric-alternative-to-anova}}

When there are more than two groups to compare, the non-parametric
alternative to ANOVA is the Kruskal-Wallis Test. Like the Mann-Whitney
U-test, the Kruskal-Wallis test is based on ranks rather than observed
values. While the Kruskal-Wallis test does not assume the data are
normally distributed, it still assumes the distributions of the variable
of interest have similar shapes across the groups. The test statistic
for the Kruskal-Wallis test is designated \(H\).

\hypertarget{example-data-daphnia-resistance-to-cyanobacteria}{%
\subsubsection*{Example data: Daphnia resistance to
cyanobacteria}\label{example-data-daphnia-resistance-to-cyanobacteria}}
\addcontentsline{toc}{subsubsection}{Example data: Daphnia resistance to
cyanobacteria}

This is from Assignment Problem 13.17 in Whitlock \& Schluter.

Daphnia is a freshwater planktonic crustacean. Hairson et al. (1999)
were interested in local adaptation of Daphnia populations in Lake
Constance (bordering Germany, Austria, and Switzerland). Cyanobacteria,
is a toxic food type that has increased in density in Lake Constance
since the 1960s in response to increased nutrients. The investigators
collected Daphnia eggs from sediments laid down during years of low,
medium, and high cyanobacteria density and measured resistance to
cyanobacteria in each group. Visual inspection of these data suggest
they violate the normality assumptions of standard ANOVA.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{daphnia <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/ABD-daphnia-resistance.csv"}\NormalTok{)}
\CommentTok{#> Parsed with column specification:}
\CommentTok{#> cols(}
\CommentTok{#>   cyandensity = col_character(),}
\CommentTok{#>   resistance = col_double()}
\CommentTok{#> )}

\KeywordTok{ggplot}\NormalTok{(daphnia, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ resistance)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{8}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.75}\NormalTok{, }\DataTypeTok{fill =} \StringTok{'firebrick'}\NormalTok{, }\DataTypeTok{color=}\StringTok{'black'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{cyandensity)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-489-1} \end{center}

To carry out the Kruskal-Wallis test, and summarize the output in a data
frame using \texttt{broom::tidy} we do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kw.results <-}\StringTok{ }\KeywordTok{kruskal.test}\NormalTok{(resistance }\OperatorTok{~}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(cyandensity), daphnia)}
\KeywordTok{tidy}\NormalTok{(kw.results)}
\CommentTok{#> # A tibble: 1 x 4}
\CommentTok{#>   statistic p.value parameter method                      }
\CommentTok{#>       <dbl>   <dbl>     <int> <chr>                       }
\CommentTok{#> 1     8.200 0.01658         2 Kruskal-Wallis rank sum test}
\end{Highlighting}
\end{Shaded}

Based on a the estimated P-value, we have evidence upon which to reject
the null hypothesis of equal means at a Type I error rate of
\(\alpha = 0.5\). However some caution is warranted as the shape of the
distributions appear to be somewhat different among the groups.

\hypertarget{acknowledgements}{%
\section*{Acknowledgements}\label{acknowledgements}}
\addcontentsline{toc}{section}{Acknowledgements}

Figures and examples from W\&S Chap 13; lecture notes from T.
Mitchell-Olds.

\hypertarget{bivariate-linear-regression}{%
\chapter{Bivariate Linear
Regression}\label{bivariate-linear-regression}}

Statistical models are quantitative statements about how we think
variables are related to each other.

Linear models are among the simplest statistical models. In a linear
model relating two variables \(X\) and \(Y\), the general form of the
model can be stated as ``I assume that \(Y\) can be expressed as a
linear function of \(X\)''. The process of \emph{model fitting} is then
the task of finding the coefficients (parameters) of the linear model
which best fit the observed data.

Linear functions are those whose graphs are straight lines. A linear
function of a variable \(X\) is usually written as:

\[
 \hat{Y} = f(X) = a + bX
\]

where \(a\) and \(b\) are constants. In geometric terms \(b\) is the
\emph{slope of the line} and \(a\) is the value of the function when
\(X\) is zero (usually the referred to as the ``Y-intercept''). The
slope tells you have much \(Y\) changes per unit change of \(X\).

There are infinitely many such linear functions of \(X\) we could
define. Which linear function provides the best fit given our observed
values of \(X\) and \(Y\)?

\hypertarget{regression-terminology}{%
\section{Regression terminology}\label{regression-terminology}}

\begin{itemize}
\item
  \textbf{Predictors, explanatory, or independent variable} -- the
  variables from which we want to make our prediction.
\item
  \textbf{Outcomes, dependent, or response variable} -- the variable we
  are trying to predict in our regression.
\end{itemize}

\hypertarget{the-optimality-criterion-for-least-squares-regression}{%
\section{The optimality criterion for least-squares
regression}\label{the-optimality-criterion-for-least-squares-regression}}

In order to fit a model to data, we have to specify some criterion for
judging how well alternate models perform.

In linear regression, the optimality criterion can be expressed as
``Find the linear function, \(f(X)\), that minimizes the following
quantity:''

\[
\sum (y_i - f(x_i))^2
\] That is, our goal is to find the linear function of \(X\) that
minimizes the squared deviations in the \(Y\) direction.

\begin{figure}

{\centering \includegraphics[width=0.4\linewidth]{./figures/fig-regression-minimization} 

}

\caption{A graphical representation of the optimality criterion in bivariate least squares linear regression.}\label{fig:unnamed-chunk-491}
\end{figure}

\hypertarget{solution-for-the-least-squares-criterion}{%
\section{Solution for the least-squares
criterion}\label{solution-for-the-least-squares-criterion}}

With a little calculus and linear algebra one can show that the values
of \(b\) (slope) and \(a\) (intercept) that minimize the sum of squared
deviations described above are:

\begin{align}
b &= \frac{s_{xy}}{s^2_x} = r_{xy}\frac{s_y}{s_x}\\
\\
a &= \overline{Y} - b\overline{X}
\end{align}

where \(r_{xy}\) is the correlation coefficient between \(X\) and \(Y\),
and \(s_x\) and \(s_y\) are the standard deviations of \(X\) and \(Y\)
respectively.

\hypertarget{libraries-7}{%
\section{Libraries}\label{libraries-7}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(ggExtra)  }\CommentTok{# a new library, provides ggMarginal plot (see below)}
                  \CommentTok{# install if you don't already have it}
\end{Highlighting}
\end{Shaded}

\hypertarget{illustrating-linear-regression-with-simulated-data}{%
\section{Illustrating linear regression with simulated
data}\label{illustrating-linear-regression-with-simulated-data}}

To illustrate how regression works, we'll use a simulated data set where
we specify the relationship between two variables, \(X\) and \(Y\).
Using a simulation is desirable because it allows us to know what the
``true'' underlying model that relates \(X\) and \(Y\) is, so we can
evaluate how well we do in terms of recovering the model.

Let's generate two vectors representing the variable, \(X\) and \(Y\),
where \(Y\) is a function of \(X\) plus some independent noise. As
specified below, the ``true'' model is \(Y = 1.5X + 1.0 + \epsilon_y\)
where \(\epsilon_y\) is a noise term.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# this seeds our random number generator}
\CommentTok{# by setting a seed, we can make random number generation reproducible}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{20160921}\NormalTok{)  }

\NormalTok{npts <-}\StringTok{ }\DecValTok{50}
\NormalTok{X <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DataTypeTok{length.out =}\NormalTok{ npts) }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(npts)}
\NormalTok{a <-}\StringTok{ }\FloatTok{1.0}
\NormalTok{b <-}\StringTok{ }\FloatTok{1.5}
\NormalTok{Y <-}\StringTok{ }\NormalTok{b}\OperatorTok{*}\NormalTok{X }\OperatorTok{+}\StringTok{ }\NormalTok{a }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(npts, }\DataTypeTok{sd =} \DecValTok{2}\NormalTok{)  }\CommentTok{# Y = 1.5X + 1.0 + noise}

\NormalTok{df.xy <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{X =}\NormalTok{ X, }\DataTypeTok{Y =}\NormalTok{ Y)}
\end{Highlighting}
\end{Shaded}

Having generated some simulated data, let's visualize it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(df.xy, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ X, }\DataTypeTok{y =}\NormalTok{ Y)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{()}
\KeywordTok{ggMarginal}\NormalTok{(p, }\DataTypeTok{type =} \StringTok{"histogram"}\NormalTok{, }\DataTypeTok{bins =} \DecValTok{11}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-494-1.pdf}

\hypertarget{specifying-regression-models-in-r}{%
\section{Specifying Regression Models in
R}\label{specifying-regression-models-in-r}}

As one would expect, R has a built-in function for fitting linear
regression models. The function \texttt{lm()} can be used not only to
carry out bivariate linear regression but a wide range of linear models,
including multiple regression, analysis of variance, analysis of
covariance, and others.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.xy <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Y }\OperatorTok{~}\StringTok{ }\NormalTok{X, df.xy)}
\end{Highlighting}
\end{Shaded}

The first argument to \texttt{lm} is an R ``formula'', the second
argument is a data frame.

Recall that formulas are R's way of specifying models, though they find
other uses as well (e.g.~we saw the formula syntax when we introduced
the \texttt{facet\_wrap} and \texttt{facet\_grid} functions from ggplot,
and in the context of ANOVA). The general form of a formula in R is
\texttt{response\ variable\ \textasciitilde{}\ explanatory\ variables}.
In the code example above, we have only a single explanatory variable,
and thus our response variable is Y and our explanatory variable is X.

The \texttt{lm} function returns a list with a number of different
components. The ones of most interest to us are \texttt{fitted.values},
\texttt{coefficients}, \texttt{residuals}, and (see the \texttt{lm}
documentation for full details.)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.xy}
\CommentTok{#> }
\CommentTok{#> Call:}
\CommentTok{#> lm(formula = Y ~ X, data = df.xy)}
\CommentTok{#> }
\CommentTok{#> Coefficients:}
\CommentTok{#> (Intercept)            X  }
\CommentTok{#>      0.7688       1.5511}
\end{Highlighting}
\end{Shaded}

Calling \texttt{summary} on a fit model provides more detailed output:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(fit.xy)}
\CommentTok{#> }
\CommentTok{#> Call:}
\CommentTok{#> lm(formula = Y ~ X, data = df.xy)}
\CommentTok{#> }
\CommentTok{#> Residuals:}
\CommentTok{#>     Min      1Q  Median      3Q     Max }
\CommentTok{#> -4.3723 -1.2391 -0.1677  1.4593  3.1808 }
\CommentTok{#> }
\CommentTok{#> Coefficients:}
\CommentTok{#>             Estimate Std. Error t value Pr(>|t|)    }
\CommentTok{#> (Intercept)   0.7688     0.5755   1.336    0.188    }
\CommentTok{#> X             1.5511     0.1699   9.129 4.58e-12 ***}
\CommentTok{#> ---}
\CommentTok{#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1}
\CommentTok{#> }
\CommentTok{#> Residual standard error: 1.772 on 48 degrees of freedom}
\CommentTok{#> Multiple R-squared:  0.6345, Adjusted R-squared:  0.6269 }
\CommentTok{#> F-statistic: 83.34 on 1 and 48 DF,  p-value: 4.581e-12}
\end{Highlighting}
\end{Shaded}

As we saw in previous R functions for implementing statistical test, the
model object is actually a list-like object with multiple fields:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typeof}\NormalTok{(fit.xy)}
\CommentTok{#> [1] "list"}

\KeywordTok{names}\NormalTok{(fit.xy)}
\CommentTok{#>  [1] "coefficients"  "residuals"     "effects"       "rank"         }
\CommentTok{#>  [5] "fitted.values" "assign"        "qr"            "df.residual"  }
\CommentTok{#>  [9] "xlevels"       "call"          "terms"         "model"}
\end{Highlighting}
\end{Shaded}

\hypertarget{fitted-values}{%
\subsection{Fitted values}\label{fitted-values}}

The component \texttt{fitted.values} gives the predicted values of \(Y\)
(\(\hat{Y}\) in the equations above) for each observed value of \(X\).
We can plot these predicted values of \(Y\), as shown below. Notice how
the predicted values all fall on a line (the regression line itself!)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.xy, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ X, }\DataTypeTok{y =}\NormalTok{ Y)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha=}\FloatTok{0.7}\NormalTok{) }\OperatorTok{+}\StringTok{                           }\CommentTok{# observed data}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ X, }\DataTypeTok{y =}\NormalTok{ fit.xy}\OperatorTok{$}\NormalTok{fitted.values),  }\CommentTok{# predicted data}
             \DataTypeTok{color=}\StringTok{'red'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_segment}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{xend =}\NormalTok{ X, }\DataTypeTok{yend =}\NormalTok{ fit.xy}\OperatorTok{$}\NormalTok{fitted.values),}
               \DataTypeTok{color=}\StringTok{'red'}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{'dashed'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{bio304-book_files/figure-latex/unnamed-chunk-499-1} 

}

\caption{Observed (black) and predicted (red) values in a linear regression of Y on X.  Dashed lines indicate the residuals from the regression.}\label{fig:unnamed-chunk-499}
\end{figure}

\hypertarget{getting-the-model-coefficients}{%
\subsection{Getting the model
coefficients}\label{getting-the-model-coefficients}}

The \texttt{coefficients} components gives the value of the model
parameters, namely the intercept and slope.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{fit.xy}\OperatorTok{$}\NormalTok{coefficients}
\CommentTok{#> (Intercept)           X }
\CommentTok{#>   0.7687897   1.5510691}
\end{Highlighting}
\end{Shaded}

As shown above, the estimated slope is 1.5510691 and the estimated
intercept is 0.7687897. The model estimated by our linear regression is
thus \(\widehat{Y} = 0.769 + 1.55X\).

Recall that because this is a synthetic example, we know the ``true''
underlying model, which is \(Y = 1.5X + 1.0 + \epsilon_x\). On the face
of it, it appears our regression model is doing a decent job of
estimating the true model.

With this information in hand we can draw the regression line as so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.xy, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ X, }\DataTypeTok{y =}\NormalTok{ Y)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha=}\FloatTok{0.7}\NormalTok{) }\OperatorTok{+}\StringTok{     }\CommentTok{# observed data}
\StringTok{  }\KeywordTok{geom_abline}\NormalTok{(}\DataTypeTok{slope =}\NormalTok{ fit.xy}\OperatorTok{$}\NormalTok{coefficients[[}\DecValTok{2}\NormalTok{]],}
              \DataTypeTok{intercept =}\NormalTok{ fit.xy}\OperatorTok{$}\NormalTok{coefficients[[}\DecValTok{1}\NormalTok{]],}
              \DataTypeTok{color=}\StringTok{'red'}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-501-1.pdf}

Since linear model fitting is a fairly common task, the ggplot library
includes a geometric mapping, \texttt{geom\_smooth}, that will fit a
linear model for us and generate the corresponding regression plot.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.xy, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ X, }\DataTypeTok{y =}\NormalTok{ Y)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.75}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"lm"}\NormalTok{, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-502-1.pdf}

By default, \texttt{geom\_smooth} draws confidence intervals for the
regression model (the shaded gray area around the regression line). Note
that confidence intervals for a linear regression model are wider far
away from the mean values of \(X\) and \(Y\).

\hypertarget{residuals}{%
\section{Residuals}\label{residuals}}

Residuals are the difference between the observed values of \(Y\) and
the predicted values. You can think of residuals as the proportion of
\(Y\) unaccounted for by the model.

\[
\mbox{residuals} = Y - \hat{Y}
\]

The previous figure showed the residuals as dashed lines connected the
observed and predicted values. A common way to depict the residuals, is
to plot the predictor values versus the corresponding residual value,
like so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.xy, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ X)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ fit.xy}\OperatorTok{$}\NormalTok{residuals)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"X"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Residuals"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-503-1.pdf}

When the linear regression model is appropriate, residuals should be
normally distributed, centered around zero and should show no strong
trends or extreme differences in spread (variance) for different values
of \(X\).

\hypertarget{regression-as-sum-of-squares-decomposition}{%
\section{Regression as sum-of-squares
decomposition}\label{regression-as-sum-of-squares-decomposition}}

Regression can be viewed as a decomposition of the sum-of-squared
deviations..

\[
ss(Y) = ss(\hat{Y}) + ss(\mbox{residuals})
\]

Let's check this for our example:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{ss.Y <-}\StringTok{ }\KeywordTok{sum}\NormalTok{((Y }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(Y))}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{ss.Yhat <-}\StringTok{ }\KeywordTok{sum}\NormalTok{((fit.xy}\OperatorTok{$}\NormalTok{fitted.values }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(Y))}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{ss.residuals <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(fit.xy}\OperatorTok{$}\NormalTok{residuals}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{ss.Y}
\CommentTok{#> [1] 412.6367}
\OperatorTok{>}\StringTok{ }\NormalTok{ss.Yhat }\OperatorTok{+}\StringTok{ }\NormalTok{ss.residuals}
\CommentTok{#> [1] 412.6367}
\end{Highlighting}
\end{Shaded}

\hypertarget{variance-explained-by-a-regression-model}{%
\section{Variance ``explained'' by a regression
model}\label{variance-explained-by-a-regression-model}}

We can use the sum-of-square decomposition to understand the relative
proportion of variance ``explained'' (accounted for) by the regression
model.

We call this quantity the ``Coefficient of Determination'', designated
\(R^2\).\\
\[
R^2 = \left( 1 - \frac{SS_{residuals}}{SS_{total}} \right)
\]

For this particular example we can estimate \(R^2\) as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R2 <-}\StringTok{ }\FloatTok{1.0} \OperatorTok{-}\StringTok{ }\NormalTok{(ss.residuals}\OperatorTok{/}\NormalTok{ss.Y)}
\NormalTok{R2}
\CommentTok{#> [1] 0.6345462}
\end{Highlighting}
\end{Shaded}

In this particular example, we find our linear model accounts for about
63\% of the variance in \(Y\). Note that the coefficient of
determination is also reported when you apply the \texttt{summary}
function to a linear model.

\hypertarget{broom-a-library-for-converting-model-results-into-data-frames}{%
\section{Broom: a library for converting model results into data
frames}\label{broom-a-library-for-converting-model-results-into-data-frames}}

The model fit object we got back when we used the \texttt{lm} function
to carry out linear regression, carries lots of useful information it
isn't a particularly ``tidy'' way to access the data. The R package
Broom converts "statistical analysis objects from R into tidy data
frames, so that they can more easily be combined, reshaped and otherwise
processed with tools like `dplyr', `tidyr' and `ggplot2'. The discussion
of Broom below is drawn from the
\href{https://cran.r-project.org/web/packages/broom/vignettes/broom.html}{Introduction
to Broom}

\textbf{If you haven't already done so, install the \texttt{broom}
package before proceeding.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

There are three \texttt{broom} functions that are particularly useful
for our purposes. They are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{tidy} -- constructs a data frame that summarizes the model's
  statistical findings.
\item
  \texttt{augment} -- add columns to the original data that was modeled.
  This includes predictions, residuals, and cluster assignments.
\item
  \texttt{glance} -- construct a concise one-row summary of the model.
\end{enumerate}

\hypertarget{broomtidy}{%
\subsection{\texorpdfstring{\texttt{broom::tidy}}{broom::tidy}}\label{broomtidy}}

\texttt{tidy} applied to a regression model object returns a table
giving the estimated coefficients and other information about the
uncertainty of those estimates and corresponding p-values. For now we're
just interested in the estiamtes, the other values will be described in
detail when we get to statistical inference.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(fit.xy)}
\CommentTok{#> # A tibble: 2 x 5}
\CommentTok{#>   term        estimate std.error statistic   p.value}
\CommentTok{#>   <chr>          <dbl>     <dbl>     <dbl>     <dbl>}
\CommentTok{#> 1 (Intercept)   0.7688    0.5755     1.336 1.879e- 1}
\CommentTok{#> 2 X             1.551     0.1699     9.129 4.581e-12}
\end{Highlighting}
\end{Shaded}

\hypertarget{broomaugment}{%
\subsection{\texorpdfstring{\texttt{broom::augment}}{broom::augment}}\label{broomaugment}}

\texttt{augment} creates a data frame that combines the original data
with related information from the model fit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.xy.augmented <-}\StringTok{ }\KeywordTok{augment}\NormalTok{(fit.xy, df.xy)}
\KeywordTok{head}\NormalTok{(df.xy.augmented)}
\CommentTok{#> # A tibble: 6 x 9}
\CommentTok{#>        X         Y .fitted .se.fit  .resid    .hat .sigma  .cooksd}
\CommentTok{#>    <dbl>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>  <dbl>    <dbl>}
\CommentTok{#> 1 2.086   3.026      4.005  0.2993 -0.9787 0.02851  1.785 4.606e-3}
\CommentTok{#> 2 1.120   1.810      2.506  0.4126 -0.6967 0.05418  1.788 4.679e-3}
\CommentTok{#> 3 1.808   4.985      3.573  0.3276  1.412  0.03415  1.779 1.162e-2}
\CommentTok{#> 4 1.375   3.228      2.902  0.3790  0.3255 0.04573  1.791 8.469e-4}
\CommentTok{#> 5 1.003  -0.009990   2.325  0.4285 -2.335  0.05846  1.757 5.720e-2}
\CommentTok{#> 6 0.8916 -0.9444     2.152  0.4440 -3.096  0.06276  1.729 1.090e-1}
\CommentTok{#> # ... with 1 more variable: .std.resid <dbl>}
\end{Highlighting}
\end{Shaded}

Now, in addition to the \texttt{X} and \texttt{Y} variables of the
original data, we have columns like \texttt{.fitted} (value of Y
predicted by the model for the corresponding value of X),
\texttt{.resid} (difference between the actual Y and the predicted
value), and a variety of other information for evalulating model
uncertainty.

One thing we can do with this ``augmented'' data frame is to use it to
better visualize and explore the model. For example, if we wanted to
generate a figure highlighting the deviations from the model using
vertical lines emanating from the regression line, we could do something
like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.xy.augmented, }\KeywordTok{aes}\NormalTok{(X, Y)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"lm"}\NormalTok{, }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{,}\DataTypeTok{se=}\OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_segment}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{xend =}\NormalTok{ X, }\DataTypeTok{yend =}\NormalTok{ .fitted), }\DataTypeTok{linetype=}\StringTok{"dashed"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-509-1.pdf}

An another example, we can recreate our residual plot using the
augmented data frame as so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(df.xy.augmented, }\KeywordTok{aes}\NormalTok{(X, .resid)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{'dashed'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{y =} \StringTok{"Residuals"}\NormalTok{, }\DataTypeTok{title =} \StringTok{"Residual plot for synthetic data example."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-510-1.pdf}

\hypertarget{broomglance}{%
\subsection{\texorpdfstring{\texttt{broom::glance}}{broom::glance}}\label{broomglance}}

\texttt{glance()} provides summary information about the goodness of fit
of the model. Most relevant for our current discussion is the column
giving the coefficient of determination (\texttt{r.squared}):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glance}\NormalTok{(fit.xy)}
\CommentTok{#> # A tibble: 1 x 11}
\CommentTok{#>   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC}
\CommentTok{#> *     <dbl>         <dbl> <dbl>     <dbl>     <dbl> <int>  <dbl> <dbl>}
\CommentTok{#> 1    0.6345        0.6269 1.772     83.34 4.581e-12     2 -98.55 203.1}
\CommentTok{#> # ... with 3 more variables: BIC <dbl>, deviance <dbl>, df.residual <int>}
\end{Highlighting}
\end{Shaded}

\hypertarget{example-predicting-lion-age-based-on-nose-color}{%
\section{Example: Predicting lion age based on nose
color}\label{example-predicting-lion-age-based-on-nose-color}}

Having walked through a simulation example, let's now turn to a real
world data set. A study by Whitman et al. (2004) showed that the amount
of black coloring on the nose of male lions increases with age, and
suggested that this might be used to estimate the age of unknown lions.
To establish the relationship between these variables they measured the
black coloring on the noses of male lions of known age (represented as a
proportion), giving the bivariate relationship (and fitted model) shown
below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lions <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/ABD-lion-noses.csv"}\NormalTok{)}

\KeywordTok{ggplot}\NormalTok{(lions, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ proportionBlack, }\DataTypeTok{y =}\NormalTok{ ageInYears)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"lm"}\NormalTok{, }\DataTypeTok{color =} \StringTok{'red'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-512-1.pdf}

By eye, the linear model looks like a pretty good fit. Let's take a look
at the quantitative values of the regression model, using the various
Broom functions to produce nice output.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lion.model <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(ageInYears }\OperatorTok{~}\StringTok{ }\NormalTok{proportionBlack, }\DataTypeTok{data =}\NormalTok{ lions)}
\KeywordTok{tidy}\NormalTok{(lion.model)}
\CommentTok{#> # A tibble: 2 x 5}
\CommentTok{#>   term            estimate std.error statistic       p.value}
\CommentTok{#>   <chr>              <dbl>     <dbl>     <dbl>         <dbl>}
\CommentTok{#> 1 (Intercept)       0.8790    0.5688     1.545 0.1328       }
\CommentTok{#> 2 proportionBlack  10.65      1.510      7.053 0.00000007677}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glance}\NormalTok{(lion.model)}
\CommentTok{#> # A tibble: 1 x 11}
\CommentTok{#>   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC}
\CommentTok{#> *     <dbl>         <dbl> <dbl>     <dbl>    <dbl> <int>  <dbl> <dbl> <dbl>}
\CommentTok{#> 1    0.6238        0.6113 1.669     49.75 7.677e-8     2 -60.76 127.5 131.9}
\CommentTok{#> # ... with 2 more variables: deviance <dbl>, df.residual <int>}
\end{Highlighting}
\end{Shaded}

We then augment our data set with information from the model fit and
plot a residual plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lions.augmented <-}\StringTok{ }\KeywordTok{augment}\NormalTok{(lion.model, lions)}
\KeywordTok{ggplot}\NormalTok{(lions.augmented, }\KeywordTok{aes}\NormalTok{(proportionBlack, .resid)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{color=}\StringTok{"firebrick"}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{"dashed"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-515-1.pdf}

From this plot, there may be some indication of greater variance of
residuals for larger values of the predictor variable.

Let's check how normal the residuals look using a QQ-plot. Here we
construct the QQ-plot using ``standardized residuals'' which are just
z-scores for the residuals.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(lions.augmented, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =}\NormalTok{ .std.resid)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_qq}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_qq_line}\NormalTok{(}\DataTypeTok{color=}\StringTok{"firebrick"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-516-1.pdf}

Based on the QQ-plot, the residuals seem to diverge somewhat from a
normal distirbution, as there's noticeable curvature in the QQ-plot.
When we test for the normality of the residuals using Shapiro-Wilk's
test for normality, we fail to reject the null hypothesis of normality
at a significance threshold of \(\alpha=0.05\):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(lions.augmented}\OperatorTok{$}\NormalTok{.resid)}
\CommentTok{#> }
\CommentTok{#>  Shapiro-Wilk normality test}
\CommentTok{#> }
\CommentTok{#> data:  lions.augmented$.resid}
\CommentTok{#> W = 0.93879, p-value = 0.0692}
\end{Highlighting}
\end{Shaded}

Even though we failed to reject the null hypothesis of normality for the
residuals, but the P-value is very close to significance, suggesting
some caution in applying the linear model.

\hypertarget{multiple-regression}{%
\chapter{Multiple regression}\label{multiple-regression}}

\hypertarget{libraries-to-install}{%
\section{Libraries to install}\label{libraries-to-install}}

We'll be using several new packages for this class session. Install the
following packages via one of the standard install mechanisms:

\begin{itemize}
\tightlist
\item
  \texttt{HistData} -- provides the \texttt{GaltonFamilies} example data
  sets we'll work with
\item
  \texttt{plot3D} -- for generating 3D plots
\item
  \texttt{rgl} -- NOTE: On OS X, \texttt{rgl} requires you to install a
  program called XQuartz. XQuartz can be downloaded from the
  \href{https://www.xquartz.org}{XQuartz Home Page}. If you're on a Mac,
  install XQuartz before installing \texttt{rgl}. You may have to reboot
  your computer after installing XQuartz.
\end{itemize}

\hypertarget{review-of-bivariate-regression}{%
\section{Review of bivariate
regression}\label{review-of-bivariate-regression}}

Recall the model for bivariate least-squares regression. When we regress
\(Y\) and \(X\) we're looking for a linear function, \(f(X)\), for which
the following sum-of-squared deviations is minimized:

\[
\sum_{i=1}^n (y_i - f(x_i))^2
\]

The general form a linear function of one variable is a line,

\[
\widehat{Y} = f(x)  = a + bX
\]

where \(b\) is the slope of the line and \(a\) is the intercept.

\hypertarget{multiple-regression-1}{%
\section{Multiple regression}\label{multiple-regression-1}}

The idea behind multiple regression is almost exactly the same as
bivariate regression, except now we try and fit a linear model for \(Y\)
using multiple explanatory variables, \(X_1, X_2,\ldots, X_m\). That is
we're looking for a linear function, \(f(X_1, X_2,\ldots,X_m)\) that
minimizes:

\[
\sum_{i=1}^n(y_i - f(x_1, x_2,\ldots, x_m))^2
\]

A linear function of more than one variable is written as:

\[
\widehat{Y} = f(X_1, X_2,\ldots,X_m) = a + b_1X_1 + b_2X_2 + \cdots + b_mX_m
\]

Where \(a\) is the intercept and \(b_1, b_2,\ldots,b_m\) are the
\textbf{regression coefficients}.

\hypertarget{geometrical-interpretation}{%
\subsection{Geometrical
interpretation}\label{geometrical-interpretation}}

Geometrically the regression coefficients have the same interpretation
as in the bivariate case -- slopes with respect to the corresponding
variable. When there are two predictor variables, the linear regression
is geometrically a plane in 3-space, as shown in the figure below. When
there are more than two predictor variables, the regression solution is
a hyper-plane.

\begin{figure}
\centering
\includegraphics{./figures/fig-regression-variable-space.png}
\caption{Multiple regression, two predictor variables}
\end{figure}

Mathematically, the best fitting regression coefficients,
\(b_1, b_2,\ldots,b_m\), are found using linear algebra. Since we
haven't covered linear algebra in this course, I will omit the details.
Conceptually the thing to remember is that the regression coefficients
are related to the magnitude of the standard deviations of the the
predictor variables and the covariances between the predictor and
outcome variables.

\hypertarget{coefficient-of-determination-for-multiple-regression}{%
\subsection{Coefficient of determination for multiple
regression}\label{coefficient-of-determination-for-multiple-regression}}

As in bivariate regression, the coefficient of determination (\(R^2\))
provides a measure of the proportion of variance in the outcome variable
(\(Y\)) ``explained'' by the predictor variables (\(X_1, X_2, \ldots\)).

\hypertarget{interpretting-multiple-regression}{%
\section{Interpretting Multiple
Regression}\label{interpretting-multiple-regression}}

Here are some things to keep in mind when interpretting a multple
regression:

\begin{itemize}
\item
  In most cases of regression, causal interpretation of the model is not
  justified.
\item
  Standard bivariate and multiple regression assumes that the predictor
  variables ( (\(X_1, X_2, \ldots\)) are observed without error. That
  is, uncertainty in the regression model is only associated with the
  outcome variable, not the predictors.
\item
  Comparing the size of regression coefficients only makes sense if all
  the predictor (explanatory) variables have the same scale
\item
  If the explanatory variables (\(X_1, X_2,\ldots,X_m\)) are highly
  correlated, then the regression solution can be ``unstable'' -- a
  small change in the data could lead to a large change in the
  regression model.
\end{itemize}

\hypertarget{libaries}{%
\section{Libaries}\label{libaries}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(cowplot)}
\KeywordTok{library}\NormalTok{(broom)}
\KeywordTok{library}\NormalTok{(GGally)}
\KeywordTok{library}\NormalTok{(plot3D)}
\KeywordTok{library}\NormalTok{(rgl)}
\end{Highlighting}
\end{Shaded}

\hypertarget{example-data-set-mtcars}{%
\section{\texorpdfstring{Example data set:
\texttt{mtcars}}{Example data set: mtcars}}\label{example-data-set-mtcars}}

The \texttt{mtcars} dataset contains information on fuel consumption and
ten other aspects of car design (see \texttt{?mtcars} for more info).
We'll use multiple regression to model the relationship between fuel
consumption (\texttt{mpg}) and a vehicles weight (\texttt{wt}) and
horsepower (\texttt{hp}).

\hypertarget{visualizing-and-summarizing-the-variables-of-interest}{%
\section{Visualizing and summarizing the variables of
interest}\label{visualizing-and-summarizing-the-variables-of-interest}}

Before carrying out any regression modle it's always a good idea to
start out with visualizations of the individual variables first.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hist.wt <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(mtcars, }\KeywordTok{aes}\NormalTok{(wt)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{8}\NormalTok{)}
\NormalTok{hist.hp <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(mtcars, }\KeywordTok{aes}\NormalTok{(hp)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{8}\NormalTok{)}
\NormalTok{hist.mpg <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(mtcars, }\KeywordTok{aes}\NormalTok{(mpg)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins=}\DecValTok{8}\NormalTok{)}

\KeywordTok{plot_grid}\NormalTok{(hist.wt, hist.hp, hist.mpg, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{, }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-519-1.pdf}

Let's also create some quick data summaries for our variables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.subset <-}\StringTok{ }
\StringTok{  }\NormalTok{mtcars }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(wt, hp, mpg)}

\KeywordTok{summary}\NormalTok{(mtcars.subset)}
\CommentTok{#>        wt              hp             mpg       }
\CommentTok{#>  Min.   :1.513   Min.   : 52.0   Min.   :10.40  }
\CommentTok{#>  1st Qu.:2.581   1st Qu.: 96.5   1st Qu.:15.43  }
\CommentTok{#>  Median :3.325   Median :123.0   Median :19.20  }
\CommentTok{#>  Mean   :3.217   Mean   :146.7   Mean   :20.09  }
\CommentTok{#>  3rd Qu.:3.610   3rd Qu.:180.0   3rd Qu.:22.80  }
\CommentTok{#>  Max.   :5.424   Max.   :335.0   Max.   :33.90}
\end{Highlighting}
\end{Shaded}

And a correlation matrix to summarize the bivariate associations between
the variables:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor}\NormalTok{(mtcars.subset)}
\CommentTok{#>             wt         hp        mpg}
\CommentTok{#> wt   1.0000000  0.6587479 -0.8676594}
\CommentTok{#> hp   0.6587479  1.0000000 -0.7761684}
\CommentTok{#> mpg -0.8676594 -0.7761684  1.0000000}
\end{Highlighting}
\end{Shaded}

We can use the \texttt{GGally::ggpairs()} function, which we've seen
previously, to create a visualization of the bivariate relationships:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggpairs}\NormalTok{(mtcars.subset)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-522-1.pdf}

From the scatter plots and correlation matrix we see that weight and
horsepower are positively correlated, but both are negatively correlated
with fuel economy. This jives with our intuition -- bigger cars with
more powerful engines generally get lower gas mileage.

\hypertarget{d-plots}{%
\section{3D plots}\label{d-plots}}

Since we're building a model that involves three variables, it makes
sense to look at at 3D plot. ggplot2 has no built in facilities for 3D
scatter plots so we'll use a package called
\href{http://www.rforscience.com/rpackages/visualisation/plot3d/}{\texttt{plot3D}}.
\texttt{plot3D} follows the plotting conventions of the base R-graphics
capabilities, so we can't build up figures in layers in the same way we
do in ggplot. Instead we pass all the formatting arguments to a single
function call.

To create a 3D scatter plot we can use the \texttt{plot3D::points3D}
function. The argument \texttt{pch} sets the type of plotting character
to use in the plot (for a graphical key of the available plotting
characters see
\href{https://www.statmethods.net/advgraphs/parameters.html}{this
link}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(plot3D)}

\CommentTok{# create short variable names for convenience}
\NormalTok{wt <-}\StringTok{ }\NormalTok{mtcars}\OperatorTok{$}\NormalTok{wt  }
\NormalTok{hp <-}\StringTok{ }\NormalTok{mtcars}\OperatorTok{$}\NormalTok{hp}
\NormalTok{mpg <-}\StringTok{ }\NormalTok{mtcars}\OperatorTok{$}\NormalTok{mpg}

\KeywordTok{points3D}\NormalTok{(wt, hp, mpg,}
         \DataTypeTok{xlab =} \StringTok{"Weight"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Horse Power"}\NormalTok{, }\DataTypeTok{zlab =} \StringTok{"MPG"}\NormalTok{,}
         \DataTypeTok{pch =} \DecValTok{20}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-523-1.pdf}

We can change the angle of the 3D plot using the arguments
\texttt{theta} and \texttt{phi} which change the ``azimuthal direction''
and ``colatitude'' (inclination angle). See the wikipedia page on
\href{https://en.wikipedia.org/wiki/Spherical_coordinate_system}{spherical
coordinate systems} for more explanation of this values.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{points3D}\NormalTok{(wt, hp, mpg,}
         \DataTypeTok{xlab =} \StringTok{"Weight"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Horse Power"}\NormalTok{, }\DataTypeTok{zlab =} \StringTok{"MPG"}\NormalTok{,}
         \DataTypeTok{pch =} \DecValTok{20}\NormalTok{,}
         \DataTypeTok{theta =} \DecValTok{20}\NormalTok{, }\DataTypeTok{phi =} \DecValTok{20}  \CommentTok{# these set viewing angle}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-524-1.pdf}

If you want the points to have a uniform color specify a single color in
the \texttt{col} argument. Here we also add vertical lines to the plot
using the \texttt{type} argument and show

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{points3D}\NormalTok{(wt, hp, mpg,}
         \DataTypeTok{xlab =} \StringTok{"Weight"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Horse Power"}\NormalTok{, }\DataTypeTok{zlab =} \StringTok{"MPG"}\NormalTok{,}
         \DataTypeTok{pch =} \DecValTok{20}\NormalTok{,}
         \DataTypeTok{theta =} \DecValTok{45}\NormalTok{, }\DataTypeTok{phi =} \DecValTok{25}\NormalTok{,}
         \DataTypeTok{type =} \StringTok{"h"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-525-1.pdf}

For more examples of how you can modify plots generated with the
\texttt{plot3D} package see
\href{http://www.sthda.com/english/wiki/impressive-package-for-3d-and-4d-graph-r-software-and-data-visualization}{this
web page}.

\hypertarget{fitting-a-multiple-regression-model-in-r}{%
\section{Fitting a multiple regression model in
R}\label{fitting-a-multiple-regression-model-in-r}}

Using the \texttt{lm()} function, fitting multiple regression models is
a straightforward extension of fitting a bivariate regression model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.mpg <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(mpg }\OperatorTok{~}\StringTok{ }\NormalTok{wt }\OperatorTok{+}\StringTok{ }\NormalTok{hp, }\DataTypeTok{data =}\NormalTok{ mtcars.subset)}
\KeywordTok{summary}\NormalTok{(fit.mpg)}
\CommentTok{#> }
\CommentTok{#> Call:}
\CommentTok{#> lm(formula = mpg ~ wt + hp, data = mtcars.subset)}
\CommentTok{#> }
\CommentTok{#> Residuals:}
\CommentTok{#>    Min     1Q Median     3Q    Max }
\CommentTok{#> -3.941 -1.600 -0.182  1.050  5.854 }
\CommentTok{#> }
\CommentTok{#> Coefficients:}
\CommentTok{#>             Estimate Std. Error t value Pr(>|t|)    }
\CommentTok{#> (Intercept) 37.22727    1.59879  23.285  < 2e-16 ***}
\CommentTok{#> wt          -3.87783    0.63273  -6.129 1.12e-06 ***}
\CommentTok{#> hp          -0.03177    0.00903  -3.519  0.00145 ** }
\CommentTok{#> ---}
\CommentTok{#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1}
\CommentTok{#> }
\CommentTok{#> Residual standard error: 2.593 on 29 degrees of freedom}
\CommentTok{#> Multiple R-squared:  0.8268, Adjusted R-squared:  0.8148 }
\CommentTok{#> F-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12}
\end{Highlighting}
\end{Shaded}

As was the case for bivariate regression, the \texttt{broom} package
functions \texttt{tidy}, \texttt{glance}, and \texttt{augment} can be
useful for working with the results from fitting the mode.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(fit.mpg)}
\CommentTok{#> # A tibble: 3 x 5}
\CommentTok{#>   term         estimate std.error statistic   p.value}
\CommentTok{#>   <chr>           <dbl>     <dbl>     <dbl>     <dbl>}
\CommentTok{#> 1 (Intercept)  37.23     1.599       23.28  2.565e-20}
\CommentTok{#> 2 wt           -3.878    0.6327      -6.129 1.120e- 6}
\CommentTok{#> 3 hp           -0.03177  0.009030    -3.519 1.451e- 3}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glance}\NormalTok{(fit.mpg)}
\CommentTok{#> # A tibble: 1 x 11}
\CommentTok{#>   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC}
\CommentTok{#> *     <dbl>         <dbl> <dbl>     <dbl>     <dbl> <int>  <dbl> <dbl>}
\CommentTok{#> 1    0.8268        0.8148 2.593     69.21 9.109e-12     3 -74.33 156.7}
\CommentTok{#> # ... with 3 more variables: BIC <dbl>, deviance <dbl>, df.residual <int>}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.subset.augmented <-}
\StringTok{  }\KeywordTok{augment}\NormalTok{(fit.mpg, mtcars.subset)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualizing-the-regression-plane}{%
\section{Visualizing the regression
plane}\label{visualizing-the-regression-plane}}

For multiple regression on two predictor variables we can visualize the
plane of best fit but adding it as a surface to our 3D plot.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Create a regular grid over the range of wt and hp values}
\NormalTok{grid.lines =}\StringTok{ }\DecValTok{10}

\NormalTok{wt.grid <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\KeywordTok{min}\NormalTok{(wt), }\KeywordTok{max}\NormalTok{(wt), }\DataTypeTok{length.out =}\NormalTok{ grid.lines)}
\NormalTok{hp.grid <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\KeywordTok{min}\NormalTok{(hp), }\KeywordTok{max}\NormalTok{(hp), }\DataTypeTok{length.out =}\NormalTok{ grid.lines)}
\NormalTok{wthp.grid <-}\StringTok{ }\KeywordTok{expand.grid}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ wt.grid, }\DataTypeTok{y =}\NormalTok{ hp.grid)}

\NormalTok{grid.df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{wt =}\NormalTok{ wthp.grid[,}\DecValTok{1}\NormalTok{], }\DataTypeTok{hp =}\NormalTok{ wthp.grid[,}\DecValTok{2}\NormalTok{])}

\CommentTok{# Predicted mpg at each point in grid}
\NormalTok{mpg.grid <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{predict}\NormalTok{(fit.mpg, }\DataTypeTok{newdata =}\NormalTok{ grid.df), }
                 \DataTypeTok{nrow =}\NormalTok{ grid.lines, }\DataTypeTok{ncol =}\NormalTok{ grid.lines)}

\CommentTok{# Predicted mpg at observed }
\NormalTok{mpg.predicted <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(fit.mpg)}

\CommentTok{# scatter plot with regression plane}
\KeywordTok{points3D}\NormalTok{(wt, hp, mpg, }
    \DataTypeTok{pch =} \DecValTok{16}\NormalTok{, }\DataTypeTok{theta =} \DecValTok{30}\NormalTok{, }\DataTypeTok{phi =} \DecValTok{5}\NormalTok{, }
    \DataTypeTok{col =} \StringTok{"red"}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.9}\NormalTok{,}
    \DataTypeTok{xlab =} \StringTok{"Weight"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Horsepower"}\NormalTok{, }\DataTypeTok{zlab =} \StringTok{"MPG"}\NormalTok{,  }
    \DataTypeTok{surf =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ wt.grid,}
                \DataTypeTok{y =}\NormalTok{ hp.grid, }
                \DataTypeTok{z =}\NormalTok{ mpg.grid, }
                \DataTypeTok{facets =} \OtherTok{NA}\NormalTok{, }
                \DataTypeTok{fit =}\NormalTok{ mpg.predicted,}
                \DataTypeTok{col =} \StringTok{"black"}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-530-1.pdf}

\hypertarget{interactive-3d-visualizations-using-opengl}{%
\section{Interactive 3D Visualizations Using
OpenGL}\label{interactive-3d-visualizations-using-opengl}}

The package \texttt{rgl} is another package that we can use for 3D
visualization. \texttt{rgl} is powerful because it lets us create
interactive plots we can rotate and zoom in/out on.

Once you've installed and loaded \texttt{rgl} try the following code.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# create 3D scatter, using spheres to draw points}
\KeywordTok{plot3d}\NormalTok{(wt, hp, mpg, }
       \DataTypeTok{type =} \StringTok{"s"}\NormalTok{, }
       \DataTypeTok{size =} \FloatTok{1.5}\NormalTok{,}
       \DataTypeTok{col =} \StringTok{"red"}\NormalTok{)}

\CommentTok{# only need to include this line if using in a markdown document}
\KeywordTok{rglwidget}\NormalTok{() }
\CommentTok{#> PhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.}
\end{Highlighting}
\end{Shaded}

\hypertarget{rgl61079}{}

We can add a 3d plane to our plot, representing the multiple regression
model, with the \texttt{rgl.planes()} function as shown below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coefs <-}\StringTok{ }\KeywordTok{coef}\NormalTok{(fit.mpg)}
\NormalTok{b1 <-}\StringTok{ }\NormalTok{coefs[}\StringTok{"wt"}\NormalTok{]}
\NormalTok{b2 <-}\StringTok{ }\NormalTok{coefs[}\StringTok{"hp"}\NormalTok{]}
\NormalTok{c <-}\StringTok{ }\DecValTok{-1}
\NormalTok{a <-}\StringTok{ }\NormalTok{coefs[}\StringTok{"(Intercept)"}\NormalTok{]}
\KeywordTok{plot3d}\NormalTok{(wt, hp, mpg, }
       \DataTypeTok{type =} \StringTok{"s"}\NormalTok{, }
       \DataTypeTok{size =} \FloatTok{1.5}\NormalTok{,}
       \DataTypeTok{col =} \StringTok{"red"}\NormalTok{)}
\KeywordTok{rgl.planes}\NormalTok{(b1, b2, c, a, }\DataTypeTok{alpha =} \FloatTok{0.9}\NormalTok{, }\DataTypeTok{color =} \StringTok{"gray"}\NormalTok{)}
\KeywordTok{rglwidget}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{rgl17114}{}

\hypertarget{examining-the-residuals}{%
\section{Examining the residuals}\label{examining-the-residuals}}

Residual plots are useful for multiple regression, just as they were for
bivariate regression.

First we plot the residuals versus each of the predictor variable
individually.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wt.resids <-}
\StringTok{  }\NormalTok{mtcars.subset.augmented }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ wt, }\DataTypeTok{y =}\NormalTok{ .resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{linetype =} \StringTok{'dashed'}\NormalTok{, }\DataTypeTok{color=}\StringTok{'red'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Weight"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Residuals"}\NormalTok{) }

\NormalTok{hp.resids <-}
\StringTok{  }\NormalTok{mtcars.subset.augmented }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ hp, }\DataTypeTok{y =}\NormalTok{ .resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{linetype =} \StringTok{'dashed'}\NormalTok{, }\DataTypeTok{color=}\StringTok{'red'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Horsepower"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Residuals"}\NormalTok{) }

\KeywordTok{plot_grid}\NormalTok{(wt.resids, hp.resids, }\DataTypeTok{labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-533-1.pdf}

And now we plot the residuals in 3D space, with a plane parallel to the
xy-plane (wt, hp-plane) representing the plane about which the residuals
should be homogeneously scattered if the assumptions of the linear
regression model hold.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.resid <-}\StringTok{ }\NormalTok{mtcars.subset.augmented}\OperatorTok{$}\NormalTok{.resid}

\CommentTok{# coefficients for plane perpindicular to }
\CommentTok{# xy-axis intercepting the z-axis at 0}
\NormalTok{b1 <-}\StringTok{ }\DecValTok{0}
\NormalTok{b2 <-}\StringTok{ }\DecValTok{0}
\NormalTok{c <-}\StringTok{ }\DecValTok{-1}
\NormalTok{a <-}\StringTok{ }\DecValTok{0}

\KeywordTok{plot3d}\NormalTok{(wt, hp, .resid, }
       \DataTypeTok{type =} \StringTok{"s"}\NormalTok{, }
       \DataTypeTok{size =} \FloatTok{1.5}\NormalTok{,}
       \DataTypeTok{col =} \StringTok{"red"}\NormalTok{,}
       \DataTypeTok{aspect =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\KeywordTok{rgl.planes}\NormalTok{(b1, b2, c, a, }\DataTypeTok{alpha =} \FloatTok{0.9}\NormalTok{, }\DataTypeTok{color =} \StringTok{"gray"}\NormalTok{)}
\KeywordTok{rglwidget}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{rgl41290}{}

\hypertarget{logistic-regression}{%
\chapter{Logistic regression}\label{logistic-regression}}

Logistic regression is used when the dependent variable is discrete
(often binary). The explanatory variables may be either continuous or
discrete.

Examples:

\begin{itemize}
\tightlist
\item
  Whether a gene is turned off (=0) or on (=1) as a function of levels
  of various proteins
\item
  Whether an individual is healthy (=0) or diseased (=1) as a function
  of various risk factors.
\item
  Whether an individual died (=0) or survived (=1) some selective event
  as a function of behavior, morphology, etc.
\end{itemize}

We model the binary response variable, \(Y\), as a function of the
predictor variables, \(X_1\), \(X_2\), etc as :

\[
P(Y = 1|X_1,\ldots,X_p) = f(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_p X_p)
\]

So we're modeling the \emph{probability of the state of Y as a function
of a linear combination of the predictor variables}.

For logistic regression, \(f\) is the logistic function: \[
f(z) = \frac{e^z}{1+e^z} = \frac{1}{1 + e^{-z}}
\]

Therefore, the bivariate logistic regression is given by: \[
P(Y = 1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X)}}
\]

Note that \(\beta_0\) here is akin to the intercept in our standard
linear regression.

\hypertarget{a-web-app-to-explore-the-logistic-regression-equation}{%
\section{A web app to explore the logistic regression
equation}\label{a-web-app-to-explore-the-logistic-regression-equation}}

To help you develop an intuition for the logistic regression equation,
I've developed
\href{https://magwenelab.shinyapps.io/exploring_logistic_regression/}{a
small web app}, that allows you to explore how the shape of the
regression curve responds to changes in the regression coefficients
\(\beta_0\) and \(\beta_1\). Open the app in another browser window and
play with the sliders that control the coeffients \(B_0\) and \(B_1\).
In the assignment associated with today's class you'll be asked to
answer some specific questions based on this app.

\hypertarget{titanic-data-set}{%
\section{Titanic data set}\label{titanic-data-set}}

\href{http://bit.ly/bio304-titanic-data}{\texttt{titanic.csv}} contains
information about passengers on the Titanic. Variables in this data set
include information such as sex, age, passenger class (1st, 2nd, 3rd),
and whether or not they survived the sinking of the ship (0 = died, 1 =
survived).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(broom)}
\KeywordTok{library}\NormalTok{(cowplot)}
\KeywordTok{library}\NormalTok{(ggthemes)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"http://bit.ly/bio304-titanic-data"}\NormalTok{)}
\KeywordTok{names}\NormalTok{(titanic)}
\CommentTok{#>  [1] "pclass"    "survived"  "name"      "sex"       "age"      }
\CommentTok{#>  [6] "sibsp"     "parch"     "ticket"    "fare"      "cabin"    }
\CommentTok{#> [11] "embarked"  "boat"      "body"      "home.dest"}
\end{Highlighting}
\end{Shaded}

\hypertarget{subsetting-the-data}{%
\section{Subsetting the data}\label{subsetting-the-data}}

We've all heard the phrase, ``Women and children first'', so we might
expect that the probability that a passenger survived the sinking of the
Titanic is related to their sex and/or age. Let's create separate data
subsets for male and female passengers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{male <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(titanic, sex }\OperatorTok{==}\StringTok{ "male"}\NormalTok{)}
\NormalTok{female <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(titanic, sex }\OperatorTok{==}\StringTok{ "female"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualizing-survival-as-a-function-of-age}{%
\section{Visualizing survival as a function of
age}\label{visualizing-survival-as-a-function-of-age}}

Let's create visualizations of survival as a function of age for the
male and female passengers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fcolor =}\StringTok{ "lightcoral"}
\NormalTok{mcolor =}\StringTok{ "lightsteelblue"}

\NormalTok{female.plot <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(female, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ age, }\DataTypeTok{y =}\NormalTok{ survived)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{width =} \DecValTok{0}\NormalTok{, }\DataTypeTok{height =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{color =}\NormalTok{ fcolor) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Female Passengers"}\NormalTok{)}

\NormalTok{male.plot <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(male, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ age, }\DataTypeTok{y =}\NormalTok{ survived)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{width =} \DecValTok{0}\NormalTok{, }\DataTypeTok{height =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{color =}\NormalTok{ mcolor) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Male Passengers"}\NormalTok{)}

\KeywordTok{plot_grid}\NormalTok{(female.plot, male.plot)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-538-1.pdf}

The jittered points with Y-axis value around one are passengers who
survived, the point jittered around zero are those who died.

\hypertarget{fitting-the-logistic-regression-model}{%
\section{Fitting the logistic regression
model}\label{fitting-the-logistic-regression-model}}

The function \texttt{glm} (generalized linear model) can be used to fit
the logistic regression model (as well as other models). Setting the
argument \texttt{family\ =\ binomial} gives us logistic regression. Note
that when fitting the model the dependent variable needs to be numeric,
so if the data is provided as Boolean (logical) TRUE/FALSE values, they
should be converted to integers using \texttt{as.numeric()}.

First we fit the regression for the famale passengers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.female <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(survived }\OperatorTok{~}\StringTok{ }\NormalTok{age, }\DataTypeTok{family =}\NormalTok{ binomial, female)}
\KeywordTok{tidy}\NormalTok{(fit.female)}
\CommentTok{#> # A tibble: 2 x 5}
\CommentTok{#>   term        estimate std.error statistic  p.value}
\CommentTok{#>   <chr>          <dbl>     <dbl>     <dbl>    <dbl>}
\CommentTok{#> 1 (Intercept)  0.4934   0.2542       1.941 0.05226 }
\CommentTok{#> 2 age          0.02252  0.008535     2.638 0.008342}
\end{Highlighting}
\end{Shaded}

The column ``estimate'' gives the coefficients of the model. The
``intercept''" estimate corresponds to \(B_0\) in the logistic
regression equation, the ``age'' estimate corresponds to the coefficient
\(B_1\) in the equation.

Now we repeat the same step for the male passengers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.male <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(survived }\OperatorTok{~}\StringTok{ }\NormalTok{age, }\DataTypeTok{family =}\NormalTok{ binomial, male)}
\KeywordTok{tidy}\NormalTok{(fit.male)}
\CommentTok{#> # A tibble: 2 x 5}
\CommentTok{#>   term        estimate std.error statistic  p.value}
\CommentTok{#>   <chr>          <dbl>     <dbl>     <dbl>    <dbl>}
\CommentTok{#> 1 (Intercept) -0.6608   0.2248      -2.939 0.003290}
\CommentTok{#> 2 age         -0.02376  0.007276    -3.266 0.001092}
\end{Highlighting}
\end{Shaded}

Notice that the female coefficients are both positive, while the male
coefficients are negative. We'll visualize what this means in terms of
the model below.

\hypertarget{visualizing-the-logistic-regression}{%
\section{Visualizing the logistic
regression}\label{visualizing-the-logistic-regression}}

To visualize the logistic regression fit, we first use the
\texttt{predict} function to generate the model predictions about
probability of survival as a function of age.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ages <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{75}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{# predict survival for ages 0 to 75}

\NormalTok{predicted.female <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(fit.female, }
                            \DataTypeTok{newdata =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{age =}\NormalTok{ ages),}
                            \DataTypeTok{type =} \StringTok{"response"}\NormalTok{)}

\NormalTok{predicted.male <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(fit.male,}
                          \DataTypeTok{newdata =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{age =}\NormalTok{ ages),}
                          \DataTypeTok{type =} \StringTok{"response"}\NormalTok{)}
                            
\end{Highlighting}
\end{Shaded}

Having generated the predicted probabilities of survival we can then add
these prediction lines to our previous plot using \texttt{geom\_line}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{female.logistic.plot <-}\StringTok{ }\NormalTok{female.plot }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{age =}\NormalTok{ ages, }\DataTypeTok{survived =}\NormalTok{ predicted.female),}
            \DataTypeTok{color =}\NormalTok{ fcolor, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{)}

\NormalTok{male.logistic.plot <-}\StringTok{ }\NormalTok{male.plot }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{age =}\NormalTok{ ages, }\DataTypeTok{survived =}\NormalTok{ predicted.male),}
            \DataTypeTok{color =}\NormalTok{ mcolor, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{)}

\KeywordTok{plot_grid}\NormalTok{(female.logistic.plot, male.logistic.plot)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-542-1.pdf}

We see that for the female passengers, the logistic regression predicts
that the probability of survival \emph{increases} with passenger age. In
contrast, the model fit to the male passengers suggests that the
probability of survival decreases with passenger age. For the male
passengers, the data is consistent with ``children first''; for female
passengers this model doesn't seem to hold. However, there are other
factors to consider as we'll see below.

\hypertarget{quick-and-easy-visualization}{%
\subsection{Quick and easy
visualization}\label{quick-and-easy-visualization}}

Here's an alternative ``quick and easy'' way to generate the plot above
using the awesome power of ggplot. The downside of this approach is we
don't generate the detailed information on the model, which is something
you'd certainly want to have in any real analysis.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{age, }\DataTypeTok{y=}\NormalTok{survived, }\DataTypeTok{color=}\NormalTok{sex)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{width =} \DecValTok{0}\NormalTok{, }\DataTypeTok{height =} \FloatTok{0.05}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"glm"}\NormalTok{,  }\DataTypeTok{method.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{family=}\StringTok{"binomial"}\NormalTok{))  }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Age"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"P(Survival)"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{sex) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_color_manual}\NormalTok{(}\DataTypeTok{values =} \KeywordTok{c}\NormalTok{(fcolor, mcolor))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-543-1.pdf}

\hypertarget{impact-of-sex-and-passenger-class-on-the-models}{%
\section{Impact of sex and passenger class on the
models}\label{impact-of-sex-and-passenger-class-on-the-models}}

In our previous analysis we considered the relationship between survival
and age, conditioned (facted) on passenger sex. In a complex data set
like this one, it is often useful to condition on multiple variables
simultaneously. Lets extend our visualization to look at the regression
faceted on both class and sex, using \texttt{facet\_grid}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(titanic, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{age, }\DataTypeTok{y=}\NormalTok{survived, }\DataTypeTok{color=}\NormalTok{sex)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{width =} \DecValTok{0}\NormalTok{, }\DataTypeTok{height =} \FloatTok{0.05}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{"glm"}\NormalTok{,  }\DataTypeTok{method.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{family=}\StringTok{"binomial"}\NormalTok{))  }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Age"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"P(Survival)"}\NormalTok{) }\OperatorTok{+}\StringTok{  }
\StringTok{  }\KeywordTok{facet_grid}\NormalTok{(pclass }\OperatorTok{~}\StringTok{ }\NormalTok{sex) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_color_manual}\NormalTok{(}\DataTypeTok{values =} \KeywordTok{c}\NormalTok{(fcolor, mcolor)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_few}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bio304-book_files/figure-latex/unnamed-chunk-544-1.pdf}

Having conditioned on both sex and ticket class, our figure now reveals
a much more complex relationship between age and survival. Almost all
first class female passengers survived, regardless of age. For second
calss female passengers, the logistic regression suggests a very modest
decrease in survival with increasing age. The negative relationship
between age and survival is stronger still for third class females. Male
passengers on the other hand show a negative relationship between sex
and survival, regardless of class, but the models suggest that there are
still class specific differences in this relationship.

\hypertarget{fitting-multiple-models-based-on-groupings-use-dplyrdo}{%
\section{\texorpdfstring{Fitting multiple models based on groupings use
\texttt{dplyr::do}}{Fitting multiple models based on groupings use dplyr::do}}\label{fitting-multiple-models-based-on-groupings-use-dplyrdo}}

In the figure above we used \texttt{ggplot} and \texttt{facet\_grid} to
visualize logistic regression of survival on age, conditioned on both
sex and class. What if we wanted to calculate the terms of the logistic
regressions for each combination of these two categorical variables?
There are three passenger classes and two sexes, meaning we'd have to
create six data subsets and fit the model six times if we used the same
approach we used previously. Luckily, \texttt{dplyr} provides a powerful
function called \texttt{do()} that allows us to carry out arbitrary
computations on grouped data.

There are two ways to use \texttt{do()}. The first way is to give the
expressions you evaluate in \texttt{do()} a name, in which case
\texttt{do()} will store the results in a column. The second way to use
\texttt{do()} is for the expression to return a data frame.

In this first example, the model fits are stored in the \texttt{fits}
column. When using \texttt{do()} you can refer to the groupings using a
period (\texttt{.}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grouped.models <-}
\StringTok{  }\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(sex, pclass) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{do}\NormalTok{(}\DataTypeTok{fits =} \KeywordTok{glm}\NormalTok{(survived }\OperatorTok{~}\StringTok{ }\NormalTok{age, }\DataTypeTok{family =}\NormalTok{ binomial, }\DataTypeTok{data =}\NormalTok{ .))}

\NormalTok{grouped.models}
\CommentTok{#> Source: local data frame [6 x 3]}
\CommentTok{#> Groups: <by row>}
\CommentTok{#> }
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>   sex    pclass fits     }
\CommentTok{#> * <chr>   <int> <list>   }
\CommentTok{#> 1 female      1 <S3: glm>}
\CommentTok{#> 2 female      2 <S3: glm>}
\CommentTok{#> 3 female      3 <S3: glm>}
\CommentTok{#> 4 male        1 <S3: glm>}
\CommentTok{#> 5 male        2 <S3: glm>}
\CommentTok{#> 6 male        3 <S3: glm>}
\end{Highlighting}
\end{Shaded}

Notice that the ``fits'' column doesn't explicitly print out the details
of the model. The object returned by \texttt{glm()} can't be simply
represented as text string (it's a list), so we seea place holder string
that tells us that there is data here represented a glm object. However,
we can access the the columns with the fits just like any other
variable:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# get the summary of the second logistic regression (Female, 2nd Class) }
\KeywordTok{tidy}\NormalTok{(grouped.models}\OperatorTok{$}\NormalTok{fits[[}\DecValTok{2}\NormalTok{]])}
\CommentTok{#> # A tibble: 2 x 5}
\CommentTok{#>   term        estimate std.error statistic   p.value}
\CommentTok{#>   <chr>          <dbl>     <dbl>     <dbl>     <dbl>}
\CommentTok{#> 1 (Intercept)  3.491     0.9037      3.863 0.0001119}
\CommentTok{#> 2 age         -0.04502   0.02548    -1.767 0.07730}
\end{Highlighting}
\end{Shaded}

Now we illustrate the second approach to using \texttt{do()}. When no
name is provided, \texttt{do()} expects its expression to return a
dataframe. Here we use the \texttt{broom::tidy()} function to get the
key results of each fit model into a data frame:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(sex, pclass) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{do}\NormalTok{(}\KeywordTok{tidy}\NormalTok{(}\KeywordTok{glm}\NormalTok{(survived }\OperatorTok{~}\StringTok{ }\NormalTok{age, }\DataTypeTok{family =}\NormalTok{ binomial, }\DataTypeTok{data =}\NormalTok{ .)))}
\CommentTok{#> # A tibble: 12 x 7}
\CommentTok{#> # Groups:   sex, pclass [6]}
\CommentTok{#>    sex    pclass term         estimate std.error statistic     p.value}
\CommentTok{#>    <chr>   <int> <chr>           <dbl>     <dbl>     <dbl>       <dbl>}
\CommentTok{#>  1 female      1 (Intercept)  2.896      1.238      2.339  0.01932    }
\CommentTok{#>  2 female      1 age          0.009599   0.03263    0.2942 0.7686     }
\CommentTok{#>  3 female      2 (Intercept)  3.491      0.9037     3.863  0.0001119  }
\CommentTok{#>  4 female      2 age         -0.04502    0.02548   -1.767  0.07730    }
\CommentTok{#>  5 female      3 (Intercept)  0.2887     0.3412     0.8461 0.3975     }
\CommentTok{#>  6 female      3 age         -0.01783    0.01361   -1.310  0.1901     }
\CommentTok{#>  7 male        1 (Intercept)  0.8803     0.5275     1.669  0.09514    }
\CommentTok{#>  8 male        1 age         -0.03743    0.01276   -2.934  0.003351   }
\CommentTok{#>  9 male        2 (Intercept)  1.042      0.5990     1.740  0.08181    }
\CommentTok{#> 10 male        2 age         -0.1122     0.02492   -4.502  0.000006724}
\CommentTok{#> 11 male        3 (Intercept) -0.7613     0.3418    -2.228  0.02591    }
\CommentTok{#> 12 male        3 age         -0.03392    0.01339   -2.534  0.01129}
\end{Highlighting}
\end{Shaded}

Using this approach we get a nice data frame showing the logistic
regression coefficients, and associated statistics (standard error,
P-values, etc) for the regression of survival on age, for each
combination of sex and class.


\end{document}
